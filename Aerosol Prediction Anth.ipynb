{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.utils import resample\n",
    "from hyperopt import STATUS_OK, hp, fmin, tpe, Trials, space_eval\n",
    "\n",
    "from time import time\n",
    "import operator\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "def load_data():\n",
    "    full_data = pd.read_csv(\"X.csv\")\n",
    "    train_y = pd.read_csv(\"ytr.csv\")\n",
    "    # Rename columns to something more interpretable\n",
    "    columns = ([\"reflectance_\" + str(i) for i in range(7)]\n",
    "               + [\"solar_\" + str(i) for i in range(5)] + [\"id\"])\n",
    "    full_data.columns = columns\n",
    "    # Add y to the data frame\n",
    "    split = 98000\n",
    "    y_id_dict = train_y.set_index(\"Id\")[\"y\"].to_dict()\n",
    "    full_data.loc[:(split-1), \"y\"] = full_data.loc[:(split-1), \"id\"].map(y_id_dict)\n",
    "\n",
    "    train, test = full_data[:split], full_data[split:]\n",
    "    return (train, test)\n",
    "\n",
    "columns = ([\"id\"] + [\"reflectance_\" + str(i) for i in range(7)]\n",
    "           + [\"solar_\" + str(i) for i in range(5)] + [\"y\"])\n",
    "full_data = pd.read_csv(\"MODIS.csv\", header=None, names=columns)\n",
    "split = 98000\n",
    "train, test = full_data[:split].copy(), full_data[split:].copy()\n",
    "#train = full_data.copy()\n",
    "\n",
    "#train_copy, test_copy = load_data()\n",
    "\n",
    "#train, test = load_data()\n",
    "\n",
    "# Parameters\n",
    "n_threads = -1\n",
    "random_seed = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reflectance_0</th>\n",
       "      <th>reflectance_1</th>\n",
       "      <th>reflectance_2</th>\n",
       "      <th>reflectance_3</th>\n",
       "      <th>reflectance_4</th>\n",
       "      <th>reflectance_5</th>\n",
       "      <th>reflectance_6</th>\n",
       "      <th>solar_0</th>\n",
       "      <th>solar_1</th>\n",
       "      <th>solar_2</th>\n",
       "      <th>solar_3</th>\n",
       "      <th>solar_4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.026993</td>\n",
       "      <td>0.012067</td>\n",
       "      <td>0.088535</td>\n",
       "      <td>0.050097</td>\n",
       "      <td>0.007748</td>\n",
       "      <td>0.004051</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>28.420588</td>\n",
       "      <td>146.782941</td>\n",
       "      <td>20.686471</td>\n",
       "      <td>100.594706</td>\n",
       "      <td>159.884706</td>\n",
       "      <td>0.075627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.029457</td>\n",
       "      <td>0.019613</td>\n",
       "      <td>0.087705</td>\n",
       "      <td>0.052130</td>\n",
       "      <td>0.016930</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>0.003654</td>\n",
       "      <td>28.420588</td>\n",
       "      <td>146.782941</td>\n",
       "      <td>20.686471</td>\n",
       "      <td>100.594706</td>\n",
       "      <td>159.884706</td>\n",
       "      <td>0.075627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.038491</td>\n",
       "      <td>0.150211</td>\n",
       "      <td>0.091345</td>\n",
       "      <td>0.062856</td>\n",
       "      <td>0.140568</td>\n",
       "      <td>0.076832</td>\n",
       "      <td>0.032414</td>\n",
       "      <td>28.420588</td>\n",
       "      <td>146.782941</td>\n",
       "      <td>20.686471</td>\n",
       "      <td>100.594706</td>\n",
       "      <td>159.884706</td>\n",
       "      <td>0.075627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.041447</td>\n",
       "      <td>0.276798</td>\n",
       "      <td>0.089301</td>\n",
       "      <td>0.072769</td>\n",
       "      <td>0.237950</td>\n",
       "      <td>0.109721</td>\n",
       "      <td>0.036960</td>\n",
       "      <td>28.420588</td>\n",
       "      <td>146.782941</td>\n",
       "      <td>20.686471</td>\n",
       "      <td>100.594706</td>\n",
       "      <td>159.884706</td>\n",
       "      <td>0.075627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.029073</td>\n",
       "      <td>0.027024</td>\n",
       "      <td>0.088950</td>\n",
       "      <td>0.052317</td>\n",
       "      <td>0.021162</td>\n",
       "      <td>0.011535</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>28.420588</td>\n",
       "      <td>146.782941</td>\n",
       "      <td>20.686471</td>\n",
       "      <td>100.594706</td>\n",
       "      <td>159.884706</td>\n",
       "      <td>0.075627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  reflectance_0  reflectance_1  reflectance_2  reflectance_3  \\\n",
       "0   1       0.026993       0.012067       0.088535       0.050097   \n",
       "1   1       0.029457       0.019613       0.087705       0.052130   \n",
       "2   1       0.038491       0.150211       0.091345       0.062856   \n",
       "3   1       0.041447       0.276798       0.089301       0.072769   \n",
       "4   1       0.029073       0.027024       0.088950       0.052317   \n",
       "\n",
       "   reflectance_4  reflectance_5  reflectance_6    solar_0     solar_1  \\\n",
       "0       0.007748       0.004051       0.002929  28.420588  146.782941   \n",
       "1       0.016930       0.010574       0.003654  28.420588  146.782941   \n",
       "2       0.140568       0.076832       0.032414  28.420588  146.782941   \n",
       "3       0.237950       0.109721       0.036960  28.420588  146.782941   \n",
       "4       0.021162       0.011535       0.005997  28.420588  146.782941   \n",
       "\n",
       "     solar_2     solar_3     solar_4         y  \n",
       "0  20.686471  100.594706  159.884706  0.075627  \n",
       "1  20.686471  100.594706  159.884706  0.075627  \n",
       "2  20.686471  100.594706  159.884706  0.075627  \n",
       "3  20.686471  100.594706  159.884706  0.075627  \n",
       "4  20.686471  100.594706  159.884706  0.075627  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#train, test = train_copy[19600:].copy(), train_copy[:19600].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.074550</td>\n",
       "      <td>0.124129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.247182</td>\n",
       "      <td>0.124129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.050243</td>\n",
       "      <td>0.124129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.124129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.117881</td>\n",
       "      <td>0.124129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         x         y\n",
       "0   1 -0.074550  0.124129\n",
       "1   1  0.247182  0.124129\n",
       "2   1  0.050243  0.124129\n",
       "3   1  0.007489  0.124129\n",
       "4   1  0.117881  0.124129"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outlier 1 data linear\n",
    "columns = [\"id\", \"x\", \"y\"]\n",
    "train = pd.read_csv(\"outliers_1_linear.csv\", header=None,\n",
    "                        names=columns).sort_values(by=\"id\").reset_index(drop=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cols_excl = [\"id\", \"y\"]\n",
    "cols_orig = [c for c in train.columns if c not in cols_excl]\n",
    "\n",
    "# Remove outliers\n",
    "#outliers_id = [21, 31, 72, 85, 135, 154, 165,\n",
    " #              199, 232, 252, 255, 262, 289, 387,\n",
    "  #             393, 404, 408, 434, 488, 516, 578,\n",
    "   #            615, 617, 624, 633, 647, 683, 778,\n",
    "    #           785, 792, 817, 828, 917, 946, 960]\n",
    "\n",
    "#train = train[~train[\"id\"].isin(outliers_id)].reset_index(drop=True)\n",
    "\n",
    "# Standardise data for LR\n",
    "#train[cols_orig] = scale(train[cols_orig])\n",
    "#test[cols_orig] = scale(test[cols_orig])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#feature_cols = [tf.contrib.layers.real_valued_column(k) for k in cols_orig]\n",
    "\n",
    "#regressor = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                         # hidden_units=[9, 9],\n",
    "                                         #)#model_dir=\"./temp_log\")\n",
    "\n",
    "#train, test = train_copy[19600:].copy(), train_copy[:19600].copy()\n",
    "\n",
    "#def input_fn(data_set):\n",
    " #   feature_cols = {k: tf.constant(data_set[k].values) for k in cols_orig}\n",
    "  #  labels = tf.constant(data_set[\"y\"].values)\n",
    "    \n",
    "   # return feature_cols, labels\n",
    "\n",
    "#validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    " #   input_fn=lambda: input_fn(test),\n",
    "  #  early_stopping_rounds=100)\n",
    "\n",
    "#regressor.fit(input_fn=lambda: input_fn(train), steps=10)\n",
    "              #monitors=[validation_monitor])\n",
    "\n",
    "#ev = regressor.evaluate(input_fn=lambda: input_fn(train), steps=1)\n",
    "#loss_score = ev[\"loss\"]\n",
    "#print(\"Loss: {0:f}\".format(loss_score))\n",
    "\n",
    "#y = regressor.predict(input_fn=lambda: input_fn(train))\n",
    "# .predict() returns an iterator; convert to a list and print predictions\n",
    "#predictions = np.array(list(itertools.islice(y, 0, None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pdf_weight(data):\n",
    "    cols = list(data.columns)\n",
    "    X = data.copy()\n",
    "    \n",
    "    y_mean_dict = X.groupby(\"id\")[\"y_hat\"].mean().to_dict()\n",
    "    y_std_dict = X.groupby(\"id\")[\"y_hat\"].std().to_dict()\n",
    "    X[\"y_hat_mean\"] = X[\"id\"].map(y_mean_dict)\n",
    "    X[\"y_hat_std\"] = X[\"id\"].map(y_std_dict)\n",
    "    X[\"pdf\"] = norm.pdf(X[\"y_hat\"], X[\"y_hat_mean\"], \n",
    "                        X[\"y_hat_std\"])\n",
    "    y_pdf_sum_dict = X.groupby(\"id\")[\"pdf\"].sum().to_dict()\n",
    "    X[\"pdf_sum\"] = X[\"id\"].map(y_pdf_sum_dict)\n",
    "    X[\"pdf\"] /= X[\"pdf_sum\"]\n",
    "    X[\"y_hat_weighted\"] = X[\"y_hat\"] * X[\"pdf\"]\n",
    "    \n",
    "    y_weighted_dict = X.groupby(\"id\")[\"y_hat_weighted\"].sum().to_dict()\n",
    "    X[\"y_hat_weighted_sum\"] = X[\"id\"].map(y_weighted_dict)\n",
    "    \n",
    "    return(X[cols + [\"y_hat_weighted_sum\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAFMCAYAAAAA3S/0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuVAtx3wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e715d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(train[\"x\"][train[\"id\"] < 50], train[\"y\"][train[\"id\"] < 50], s=0.5)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cols_dnn = cols_orig\n",
    "\n",
    "models_weights = {\"dnn_1\": 1}#, \"dnn_2\": 0.2, \"dnn_3\": 0.2,\n",
    "                  #\"dnn_4\": 0.2, \"dnn_5\": 0.2}\n",
    "models_cols = {\"dnn_1\": cols_dnn}\n",
    "#models_cols = {\"dnn_1\": cols_dnn, \"dnn_2\": cols_dnn, \"dnn_3\": cols_dnn,\n",
    " #              \"dnn_4\": cols_dnn, \"dnn_5\": cols_dnn}\n",
    "    \n",
    "#learning_rate = 0.1\n",
    "\n",
    "# Scoring function in the hyperopt hyperparameters tuning.\n",
    "def scoring_function(parameters):\n",
    "    print(\"Training the model with parameters: \")\n",
    "    print(parameters)\n",
    "    average_RMSE = 0.0\n",
    "    n_splits = 5\n",
    "    \n",
    "    # Generate random integer for model_dir\n",
    "    random_int = np.random.randint(1000)\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    nb_fold = 0\n",
    "    for train_index, validation_index in kf.split(train):\n",
    "        nb_fold += 1\n",
    "        train_fold, validation_fold = train.loc[train_index], train.loc[validation_index]\n",
    "        \n",
    "        # Remove outliers\n",
    "        #train_fold = train_fold[~train_fold[\"id\"].isin(outliers_id)].reset_index(drop=True)\n",
    "\n",
    "        feature_cols = [tf.contrib.layers.real_valued_column(k) for k in cols_dnn]\n",
    "        \n",
    "        count = 0\n",
    "        model_dir = (\"./log_\"\n",
    "                     + str(parameters[\"steps\"]) + \"_\"\n",
    "                     + str(parameters[\"nb_neurons_1\"]) + \"_\"\n",
    "                     #+ str(parameters[\"nb_neurons_2\"])\n",
    "                     + str(nb_fold) + \"_\"\n",
    "                     + str(count) + \"_\"\n",
    "                     + str(random_int)\n",
    "                    )\n",
    "        \n",
    "        # Tune number of layers\n",
    "        model_dnn = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                                  hidden_units=[parameters[\"nb_neurons_1\"]],\n",
    "                                                                #parameters[\"nb_neurons_2\"]],\n",
    "                                                  #optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "                                                   #   learning_rate=learning_rate,\n",
    "                                                    #  l2_regularization_strength=parameters[\"l2_reg\"]),\n",
    "                                                  #dropout=parameters[\"dropout\"],\n",
    "                                                  model_dir=model_dir)\n",
    "\n",
    "        def input_fn(data_set):\n",
    "            feature_cols = {k: tf.constant(data_set[k].values) for k in cols_dnn}\n",
    "            labels = tf.constant(data_set[\"y\"].values)\n",
    "            return feature_cols, labels\n",
    "        \n",
    "        model_dnn.fit(input_fn=lambda: input_fn(train_fold), steps=parameters[\"steps\"])\n",
    "\n",
    "        train_pred = train_fold[[\"id\"]].assign(y_hat=0)\n",
    "        #for i, m in models.items():\n",
    "        temp = model_dnn.predict(input_fn=lambda: input_fn(train_fold))\n",
    "        # .predict() returns an iterator; convert to an array\n",
    "        y_hat = np.array(list(itertools.islice(temp, 0, None)))\n",
    "        train_pred[\"y_hat\"] = y_hat\n",
    "\n",
    "        # Use median value by id\n",
    "        y_hat_med = train_pred.groupby(\"id\").median()[\"y_hat\"].to_dict()\n",
    "\n",
    "        RMSE = np.sqrt(mean_squared_error(train_pred[\"id\"].map(y_hat_med).values, train_fold[\"y\"]))\n",
    "        \n",
    "        # Prune outliers\n",
    "        RMSE_decreasing = True\n",
    "        while (RMSE_decreasing):\n",
    "            count +=1\n",
    "            train_pred[\"y_med\"] = train_pred[\"id\"].map(y_hat_med)\n",
    "\n",
    "            # Distance from the median for each bag\n",
    "            train_pred[\"score\"] = (train_pred[\"y_hat\"] - train_pred[\"y_med\"])**2\n",
    "            # Rank of each instance by bag\n",
    "            train_pred[\"rank\"] = train_pred.groupby(\"id\")[\"score\"].rank()\n",
    "            bag_size_dict = train_pred.groupby(\"id\")[\"score\"].count().to_dict()\n",
    "            train_pred[\"bag_size\"] = train_pred[\"id\"].map(bag_size_dict)\n",
    "            train_pred[\"rank\"] = train_pred[\"rank\"] / train_pred[\"bag_size\"]\n",
    "\n",
    "            # Remove outliers\n",
    "            outliers_index = train_pred[\"rank\"] > (1 - parameters[\"outliers_threshold\"])\n",
    "            train_fold = train_fold.loc[~outliers_index, :].reset_index(drop=True)\n",
    "            \n",
    "            model_dir = (\"./log_\"\n",
    "                         + str(parameters[\"steps\"]) + \"_\"\n",
    "                         + str(parameters[\"nb_neurons_1\"]) + \"_\"\n",
    "                         #+ str(parameters[\"nb_neurons_2\"])\n",
    "                         + str(nb_fold) + \"_\"\n",
    "                         + str(count) + \"_\"\n",
    "                         + str(random_int)\n",
    "                        )\n",
    "\n",
    "            model_dnn = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                                      hidden_units=[parameters[\"nb_neurons_1\"]],\n",
    "                                                                    #parameters[\"nb_neurons_2\"]],\n",
    "                                                      #optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "                                                       #   learning_rate=learning_rate,\n",
    "                                                        #  l2_regularization_strength=parameters[\"l2_reg\"]),\n",
    "                                                      #dropout=parameters[\"dropout\"],\n",
    "                                                      model_dir=model_dir)\n",
    "\n",
    "            model_dnn.fit(input_fn=lambda: input_fn(train_fold), steps=parameters[\"steps\"])\n",
    "\n",
    "            # Compute new RMSE\n",
    "            train_pred = train_fold[[\"id\"]].assign(y_hat=0)\n",
    "            \n",
    "            #for i, m in models.items():\n",
    "            temp = model_dnn.predict(input_fn=lambda: input_fn(train_fold))\n",
    "            # .predict() returns an iterator; convert to an array\n",
    "            y_hat = np.array(list(itertools.islice(temp, 0, None)))\n",
    "            train_pred[\"y_hat\"] = y_hat\n",
    "\n",
    "            # Use median value by id\n",
    "            y_hat_med = train_pred.groupby(\"id\").median()[\"y_hat\"].to_dict()\n",
    "\n",
    "            new_RMSE = np.sqrt(mean_squared_error(train_pred[\"id\"].map(y_hat_med), train_fold[\"y\"]))\n",
    "            print(\"Pruning {0} RMSE: {1}\".format(count, new_RMSE))\n",
    "            \n",
    "            #if (abs(new_RMSE - RMSE) > parameters[\"gain_threshold\"]):\n",
    "            # 5 iterations of pruning\n",
    "            if (count < 5):\n",
    "                RMSE = new_RMSE\n",
    "            else:\n",
    "                RMSE_decreasing = False\n",
    "        \n",
    "        # Bagging of RNN\n",
    "        # Bootstrap 1\n",
    "        train_fold_1 = train_fold\n",
    "        model_dnn_1 = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                                    hidden_units=[parameters[\"nb_neurons_1\"]])\n",
    "                                                    #optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "                                                     #   learning_rate=learning_rate,\n",
    "                                                      #  l2_regularization_strength=parameters[\"l2_reg\"]),\n",
    "                                                    #dropout=parameters[\"dropout\"])\n",
    "        model_dnn_1.fit(input_fn=lambda: input_fn(train_fold_1), steps=parameters[\"steps\"])\n",
    "        \n",
    "        # Boostrap 2\n",
    "        #train_fold_2 = resample(train_fold, random_state=random_seed).sort_values(by=[\"id\"]).reset_index(drop=True)\n",
    "        #model_dnn_2 = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "         #                                           hidden_units=[parameters[\"nb_neurons_1\"]])\n",
    "                                                    #model_dir=model_dir)\n",
    "        #model_dnn_2.fit(input_fn=lambda: input_fn(train_fold_2), steps=parameters[\"steps\"])\n",
    "            \n",
    "        # Bootstrap 3\n",
    "        #train_fold_3 = resample(train_fold, random_state=(random_seed+1)).sort_values(by=[\"id\"]).reset_index(drop=True)\n",
    "        #model_dnn_3 = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "         #                                           hidden_units=[parameters[\"nb_neurons_1\"]])\n",
    "                                                    #model_dir=model_dir)\n",
    "        #model_dnn_3.fit(input_fn=lambda: input_fn(train_fold_3), steps=parameters[\"steps\"])\n",
    "        \n",
    "        # Bootstrap 4\n",
    "        #train_fold_4 = resample(train_fold, random_state=(random_seed+2)).sort_values(by=[\"id\"]).reset_index(drop=True)\n",
    "        #model_dnn_4 = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "         #                                           hidden_units=[parameters[\"nb_neurons_1\"]])\n",
    "                                                    #model_dir=model_dir)\n",
    "        #model_dnn_4.fit(input_fn=lambda: input_fn(train_fold_4), steps=parameters[\"steps\"])\n",
    "        \n",
    "        # Bootstrap 5\n",
    "        #train_fold_5 = resample(train_fold, random_state=(random_seed+3)).sort_values(by=[\"id\"]).reset_index(drop=True)\n",
    "        #model_dnn_5 = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "         #                                           hidden_units=[parameters[\"nb_neurons_1\"]])\n",
    "                                                    #model_dir=model_dir)\n",
    "        #model_dnn_5.fit(input_fn=lambda: input_fn(train_fold_5), steps=parameters[\"steps\"])\n",
    "        \n",
    "        # Changed to model_dnn instead of model_dnn_1\n",
    "        models = {\"dnn_1\": model_dnn_1}#, \"dnn_2\": model_dnn_2, \"dnn_3\": model_dnn_3,\n",
    "                  #\"dnn_4\": model_dnn_4, \"dnn_5\": model_dnn_5}\n",
    "        \n",
    "        # Compute RMSE on validation set\n",
    "        validation_pred = validation_fold[[\"id\"]].assign(y_hat=0).reset_index(drop=True)\n",
    "        for i, m in models.items():\n",
    "            temp = m.predict(input_fn=lambda: input_fn(validation_fold))\n",
    "            # .predict() returns an iterator; convert to an array\n",
    "            y_hat = np.array(list(itertools.islice(temp, 0, None)))\n",
    "            validation_pred[\"y_hat\"] += models_weights[i] * y_hat\n",
    "            \n",
    "        # Weight each instance by gaussian pdf\n",
    "        #validation_pred = pdf_weight(validation_pred)\n",
    "        # Use median value by id\n",
    "        y_hat_med = validation_pred.groupby(\"id\").median()[\"y_hat\"].to_dict()\n",
    "        \n",
    "        #validation_pred[\"y_hat_weighted_sum\"]\n",
    "        #validation_fold[\"id\"].map(y_hat_med).values\n",
    "        RMSE = np.sqrt(mean_squared_error(validation_fold[\"id\"].map(y_hat_med).values, validation_fold[\"y\"]))\n",
    "        average_RMSE += RMSE\n",
    "        print(\"Validation fold {0} RMSE: {1}\".format(nb_fold, RMSE))\n",
    "\n",
    "    average_RMSE /= n_splits\n",
    "\n",
    "    print(\"Cross-validation score: {0}\\n\".format(average_RMSE))\n",
    "    \n",
    "    return {\"loss\": average_RMSE, \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model with parameters: \n",
      "{'gain_threshold': 0.015, 'steps': 200, 'nb_neurons_1': 5, 'outliers_threshold': 0.05}\n",
      "Pruning 1 RMSE: 0.0886810443581\n",
      "Pruning 2 RMSE: 0.0722942114824\n",
      "Pruning 3 RMSE: 0.0648974855781\n",
      "Pruning 4 RMSE: 0.0605885717853\n",
      "Pruning 5 RMSE: 0.0576981808583\n",
      "Validation fold 1 RMSE: 0.120492707218\n",
      "Pruning 1 RMSE: 0.108541808739\n",
      "Pruning 2 RMSE: 0.0971209489784\n",
      "Pruning 3 RMSE: 0.0758067694882\n",
      "Pruning 4 RMSE: 0.0622620046642\n",
      "Pruning 5 RMSE: 0.0598145599841\n",
      "Validation fold 2 RMSE: 0.0685860297627\n",
      "Pruning 1 RMSE: 0.102133976829\n",
      "Pruning 2 RMSE: 0.123614904986\n",
      "Pruning 3 RMSE: 0.0701570350651\n",
      "Pruning 4 RMSE: 0.0642020665995\n",
      "Pruning 5 RMSE: 0.12123422232\n",
      "Validation fold 3 RMSE: 0.0824906125714\n",
      "Pruning 1 RMSE: 0.127372874343\n",
      "Pruning 2 RMSE: 0.0726832843682\n",
      "Pruning 3 RMSE: 0.0710290845374\n",
      "Pruning 4 RMSE: 0.0875016379983\n",
      "Pruning 5 RMSE: 0.0580327295165\n",
      "Validation fold 4 RMSE: 0.0651261402836\n",
      "Pruning 1 RMSE: 0.0900104792587\n",
      "Pruning 2 RMSE: 0.0784343131342\n",
      "Pruning 3 RMSE: 0.0728808282397\n",
      "Pruning 4 RMSE: 0.0639207495541\n",
      "Pruning 5 RMSE: 0.0774678185392\n",
      "Validation fold 5 RMSE: 0.0609521098316\n",
      "Cross-validation score: 0.0795295199334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Grid to pick parameters from.\n",
    "parameters_grid = {\"steps\"             : hp.choice(\"steps\", np.arange(200, 300, 100, dtype=int)),\n",
    "                   \"nb_neurons_1\"      : hp.choice(\"nb_neurons_1\", np.arange(5, 6, 1, dtype=int)),\n",
    "                   \"outliers_threshold\": hp.quniform(\"outliers_threshold\", 0.05, 0.051, 0.01),\n",
    "                   \"gain_threshold\"    : hp.quniform(\"gain_threshold\", 0.01, 0.015, 0.005)\n",
    "                   #\"dropout\": hp.quniform(\"dropout\", 0.2, 0.4, 0.1)\n",
    "                   #\"l2_reg\": hp.quniform(\"l2_reg\", 0.00, 0.005, 0.01)\n",
    "                   #\"nb_neurons_2\": hp.choice(\"nb_neurons_2\", np.arange(5, 10, 1, dtype=int))\n",
    "                  }\n",
    "# Record the information about the cross-validation.\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(scoring_function, parameters_grid, algo=tpe.suggest, max_evals=1, \n",
    "            trials=trials)\n",
    "\n",
    "computing_time = time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Outlinear linear\n",
    "Training the model with parameters: \n",
    "{'gain_threshold': 0.015, 'steps': 1000, 'nb_neurons_1': 11, 'outliers_threshold': 0.05}\n",
    "Pruning 1 RMSE: 0.0804155030185\n",
    "Pruning 2 RMSE: 0.0794809993989\n",
    "Pruning 3 RMSE: 0.065860152061\n",
    "Pruning 4 RMSE: 0.061603047503\n",
    "Pruning 5 RMSE: 0.0586138764275\n",
    "Validation fold 1 RMSE: 0.0617678059642\n",
    "Pruning 1 RMSE: 0.0843172240725\n",
    "Pruning 2 RMSE: 0.0748873140784\n",
    "Pruning 3 RMSE: 0.065482659712\n",
    "Pruning 4 RMSE: 0.0613644908284\n",
    "Pruning 5 RMSE: 0.0609045015971\n",
    "Validation fold 2 RMSE: 0.0673808018742\n",
    "Pruning 1 RMSE: 0.0811678935522\n",
    "Pruning 2 RMSE: 0.0772371483952\n",
    "Pruning 3 RMSE: 0.0660389858725\n",
    "Pruning 4 RMSE: 0.0614534539826\n",
    "Pruning 5 RMSE: 0.059306412431\n",
    "Validation fold 3 RMSE: 0.0600865575504\n",
    "Pruning 1 RMSE: 0.0814326476057\n",
    "Pruning 2 RMSE: 0.0719821617032\n",
    "Pruning 3 RMSE: 0.0645202690828\n",
    "Pruning 4 RMSE: 0.0598876604168\n",
    "Pruning 5 RMSE: 0.0593301500914\n",
    "Validation fold 4 RMSE: 0.0648812016439\n",
    "Pruning 1 RMSE: 0.0810715252891\n",
    "Pruning 2 RMSE: 0.0745169133733\n",
    "Pruning 3 RMSE: 0.064487828201\n",
    "Pruning 4 RMSE: 0.0617649969488\n",
    "Pruning 5 RMSE: 0.0601317270497\n",
    "Validation fold 5 RMSE: 0.0624430532392\n",
    "Cross-validation score: 0.0633118840544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODIS train: 980 bags\n",
    "Training the model with parameters: \n",
    "{'gain_threshold': 0.01, 'steps': 900, 'nb_neurons_1': 9, 'outliers_threshold': 0.05}\n",
    "Pruning 1 RMSE: 0.105343361018\n",
    "Validation fold 1 RMSE: 0.0987015791108\n",
    "Pruning 1 RMSE: 0.100121169819\n",
    "Pruning 2 RMSE: 0.0939525682587\n",
    "Validation fold 2 RMSE: 0.139847916988\n",
    "Pruning 1 RMSE: 0.121320922084\n",
    "Pruning 2 RMSE: 0.111532420256\n",
    "Validation fold 3 RMSE: 0.13168961676\n",
    "Pruning 1 RMSE: 0.10949595882\n",
    "Pruning 2 RMSE: 0.103120828612\n",
    "Validation fold 4 RMSE: 0.107883013046\n",
    "Pruning 1 RMSE: 0.112995428702\n",
    "Validation fold 5 RMSE: 0.188379683693\n",
    "Cross-validation score: 0.13330036192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODIS train: 1364 bags\n",
    "    \n",
    "Training the model with parameters: \n",
    "{'gain_threshold': 0.015, 'steps': 900, 'nb_neurons_1': 11, 'outliers_threshold': 0.05}\n",
    "Pruning 1 RMSE: 0.119817931796\n",
    "Validation fold 1 RMSE: 0.111377722376\n",
    "Pruning 1 RMSE: 0.112396098948\n",
    "Pruning 2 RMSE: 0.101808581135\n",
    "Validation fold 2 RMSE: 0.148817162914\n",
    "Pruning 1 RMSE: 0.115222994126\n",
    "Pruning 2 RMSE: 0.108615616905\n",
    "Validation fold 3 RMSE: 0.110455499827\n",
    "Pruning 1 RMSE: 0.111609881409\n",
    "Validation fold 4 RMSE: 0.158362010857\n",
    "Pruning 1 RMSE: 0.108284906653\n",
    "Validation fold 5 RMSE: 0.120915922243\n",
    "Cross-validation score: 0.129985663643\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "1 DNN\n",
    "\n",
    "Training the model with parameters: \n",
    "{'gain_threshold': 0.01, 'steps': 900, 'nb_neurons_1': 11, 'outliers_threshold': 0.05}\n",
    "Pruning 1 RMSE: 0.720018452178\n",
    "Pruning 2 RMSE: 0.694637808863\n",
    "Pruning 3 RMSE: 0.682604548885\n",
    "Pruning 4 RMSE: 0.675240927353\n",
    "Validation fold 1 RMSE: 0.657330001629\n",
    "Pruning 1 RMSE: 0.67466681128\n",
    "Pruning 2 RMSE: 0.65951277037\n",
    "Pruning 3 RMSE: 0.649785148888\n",
    "Validation fold 2 RMSE: 0.748604123648\n",
    "Pruning 1 RMSE: 0.68920733019\n",
    "Pruning 2 RMSE: 0.673928761686\n",
    "Pruning 3 RMSE: 0.663794898173\n",
    "Pruning 4 RMSE: 0.656852425765\n",
    "Validation fold 3 RMSE: 0.75238232566\n",
    "Pruning 1 RMSE: 0.695945822399\n",
    "Pruning 2 RMSE: 0.677436347483\n",
    "Pruning 3 RMSE: 0.667360192164\n",
    "Pruning 4 RMSE: 0.661270048569\n",
    "Validation fold 4 RMSE: 0.703611985649\n",
    "Pruning 1 RMSE: 0.675491954494\n",
    "Pruning 2 RMSE: 0.654833366872\n",
    "Pruning 3 RMSE: 0.641692836958\n",
    "Pruning 4 RMSE: 0.633366415513\n",
    "Validation fold 5 RMSE: 0.784596896669\n",
    "Cross-validation score: 0.729305066651\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6523287945244072"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(trials.losses())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gain_threshold</th>\n",
       "      <th>nb_neurons_1</th>\n",
       "      <th>outliers_threshold</th>\n",
       "      <th>steps</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0075</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>900</td>\n",
       "      <td>0.652329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gain_threshold  nb_neurons_1  outliers_threshold  steps     score\n",
       "0          0.0075            10                0.05    900  0.652329"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the best parameters as a csv.\n",
    "best_parameters = pd.DataFrame({key: [value] for (key, value) in \n",
    "                                zip(space_eval(parameters_grid, best).keys(),\n",
    "                                    space_eval(parameters_grid, best).values())})\n",
    "# Add the corresponding score.\n",
    "best_parameters[\"score\"] = min(trials.losses())\n",
    "best_parameters.to_csv(\"best_parameters_7.csv\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 1 RMSE: 0.623854414971\n",
      "Pruning 2 RMSE: 0.612112933147\n",
      "Pruning 3 RMSE: 0.605667733108\n"
     ]
    }
   ],
   "source": [
    "cols_dnn = cols_orig\n",
    "models_weights = {\"dnn_1\": 1.0}\n",
    "models_cols = {\"dnn_1\": cols_dnn}\n",
    "best_parameters = pd.read_csv(\"best_parameters_6.csv\", encoding=\"utf-8\")\n",
    "model_dir = \"./log_submit_6\"\n",
    "\n",
    "feature_cols = [tf.contrib.layers.real_valued_column(k) for k in cols_dnn]\n",
    "        \n",
    "# Tune number of layers\n",
    "model_dnn = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                          hidden_units=[best_parameters[\"nb_neurons_1\"][0]],\n",
    "                                          model_dir=model_dir)\n",
    "\n",
    "def input_fn(data_set):\n",
    "    feature_cols = {k: tf.constant(data_set[k].values) for k in cols_dnn}\n",
    "    labels = tf.constant(data_set[\"y\"].values)\n",
    "    return feature_cols, labels\n",
    "\n",
    "model_dnn.fit(input_fn=lambda: input_fn(train), steps=best_parameters[\"steps\"][0])\n",
    "        \n",
    "train_pred = train[[\"id\"]].assign(y_hat=0)\n",
    "temp = model_dnn.predict(input_fn=lambda: input_fn(train))\n",
    "# .predict() returns an iterator; convert to an array\n",
    "y_hat = np.array(list(itertools.islice(temp, 0, None)))\n",
    "train_pred[\"y_hat\"] = y_hat\n",
    "\n",
    "# Use median value by id\n",
    "y_hat_med = train_pred.groupby(\"id\").median()[\"y_hat\"].to_dict()\n",
    "\n",
    "RMSE = np.sqrt(mean_squared_error(train_pred[\"id\"].map(y_hat_med).values, train[\"y\"]))\n",
    "        \n",
    "# Prune outliers\n",
    "RMSE_decreasing = True\n",
    "count = 0\n",
    "while (RMSE_decreasing):\n",
    "    count += 1\n",
    "    train_pred[\"y_med\"] = train_pred[\"id\"].map(y_hat_med)\n",
    "\n",
    "    # Distance from the median for each bag\n",
    "    train_pred[\"score\"] = (train_pred[\"y_hat\"] - train_pred[\"y_med\"])**2\n",
    "    # Rank of each instance by bag\n",
    "    train_pred[\"rank\"] = train_pred.groupby(\"id\")[\"score\"].rank()\n",
    "    bag_size_dict = train_pred.groupby(\"id\")[\"score\"].count().to_dict()\n",
    "    train_pred[\"bag_size\"] = train_pred[\"id\"].map(bag_size_dict)\n",
    "    train_pred[\"rank\"] = train_pred[\"rank\"] / train_pred[\"bag_size\"]\n",
    "\n",
    "    # Remove outliers\n",
    "    outliers_index = train_pred[\"rank\"] > (1 - best_parameters[\"outliers_threshold\"][0])\n",
    "    train = train.loc[~outliers_index, :].reset_index(drop=True)\n",
    "\n",
    "    model_dnn = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                              hidden_units=[best_parameters[\"nb_neurons_1\"][0]],\n",
    "                                              model_dir=model_dir)\n",
    "\n",
    "    model_dnn.fit(input_fn=lambda: input_fn(train), steps=best_parameters[\"steps\"][0])\n",
    "\n",
    "    # Compute new RMSE\n",
    "    train_pred = train[[\"id\"]].assign(y_hat=0)\n",
    "            \n",
    "    temp = model_dnn.predict(input_fn=lambda: input_fn(train))\n",
    "    # .predict() returns an iterator; convert to an array\n",
    "    y_hat = np.array(list(itertools.islice(temp, 0, None)))\n",
    "    train_pred[\"y_hat\"] = y_hat\n",
    "\n",
    "    # Use median value by id\n",
    "    y_hat_med = train_pred.groupby(\"id\").median()[\"y_hat\"].to_dict()\n",
    "\n",
    "    new_RMSE = np.sqrt(mean_squared_error(train_pred[\"id\"].map(y_hat_med), train[\"y\"]))\n",
    "    print(\"Pruning {0} RMSE: {1}\".format(count, new_RMSE))\n",
    "\n",
    "    if (abs(new_RMSE - RMSE) > best_parameters[\"gain_threshold\"][0]):\n",
    "        RMSE = new_RMSE\n",
    "    else:\n",
    "        RMSE_decreasing = False\n",
    "        \n",
    "# Training model\n",
    "model_dnn_1 = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                            hidden_units=[best_parameters[\"nb_neurons_1\"][0]])\n",
    "model_dnn_1.fit(input_fn=lambda: input_fn(train), steps=best_parameters[\"steps\"][0])\n",
    "\n",
    "models = {\"dnn_1\": model_dnn_1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Predicting on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_pred = test[[\"id\"]].assign(y_hat=0).reset_index(drop=True)\n",
    "for i, m in models.items():\n",
    "    temp = m.predict(input_fn=lambda: input_fn(test))\n",
    "    # .predict() returns an iterator; convert to an array\n",
    "    y_hat = np.array(list(itertools.islice(temp, 0, None)))\n",
    "    test_pred[\"y_hat\"] += models_weights[i] * y_hat\n",
    "\n",
    "# Use median value by id\n",
    "y_hat_med = test_pred.groupby(\"id\").median()[\"y_hat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71423164615804291"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE = np.sqrt(mean_squared_error(test_pred[\"id\"].map(y_hat_med).values, test[\"y\"]))\n",
    "RMSE\n",
    "#0.65725435012348465 for Pred 4\n",
    "#0.65362864377856866 for Pred 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "kaggle_pred = pd.DataFrame({\"Id\": y_hat_med.index, \"y\": y_hat_med.values})\n",
    "kaggle_pred.to_csv(\"Prediction_6.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Benchmark:\n",
    "* Submit 1 (ensemble of xgboost + 2 ridge with instances model)\n",
    "eta\teval_metric\tgamma\tlambda\tmax_depth\tmin_child_weight\tnthread\tobjective\tseed\tsilent\tsubsample\tscore\n",
    "0.91834 Public LB 300 trees 0.09\trmse\t0.2\t0.8\t4\t4.0\t-1\treg:linear\t22\t0\t0.7\t0.883339 (cross-val)\n",
    "    \n",
    "* Submit 2\n",
    "\n",
    "Pruning with linear regression\n",
    "then add contributions of aggregated xgboost + linear model\n",
    "\n",
    "0.78181 Public LB  0.779345 CV\n",
    "\n",
    "* Submit 3\n",
    "DNN pruning\n",
    "(wrong CV)\n",
    "0.73270 Public LB 0.663128 CV with DNN 10 neurons 900 steps gain_threshold = 0.01 outliers_threshold = 0.05\n",
    "\n",
    "* Prediction 4\n",
    "LB 0.74713\n",
    "Ensemble of 5 DNN\n",
    "{'gain_threshold': 0.015, 'steps': 3800, 'nb_neurons_1': 10, 'outliers_threshold': 0.05} CV 0.701658836521\n",
    "using fist pruning DNN\n",
    "* Prediction 5\n",
    "LB 0.74453\n",
    "Ensemble of 5 DNN\n",
    "{'gain_threshold': 0.01, 'steps': 2400, 'nb_neurons_1': 10, 'outliers_threshold': 0.05} CV 0.707300896236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Dropout\n",
    "L2 regu\n",
    "Validation set instead of cross val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### EM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gamma_i_j(j, pi_i, X_i, y_i, delta):\n",
    "    out = 0.0\n",
    "    out = pi_i[j] * norm.pdf(y_i, X_i[j], delta)\n",
    "    out /= sum(pi_i * norm.pdf(y_i, X_i, delta))\n",
    "    return(out)\n",
    "\n",
    "def EM_Q(pi, X, y, delta):\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "cols_dnn = cols_orig\n",
    "\n",
    "best_parameters = pd.read_csv(\"best_parameters_6.csv\", encoding=\"utf-8\")\n",
    "\n",
    "feature_cols = [tf.contrib.layers.real_valued_column(k) for k in cols_dnn]\n",
    "\n",
    "model_dir_f = \"./log_submit_6\"\n",
    "\n",
    "# Fit DNN regressor\n",
    "model_dnn_f = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                            hidden_units=[best_parameters[\"nb_neurons_f\"][0]],\n",
    "                                            model_dir=model_dir_f)\n",
    "\n",
    "def input_fn(data_set):\n",
    "    feature_cols = {k: tf.constant(data_set[k].values) for k in cols_dnn}\n",
    "    labels = tf.constant(data_set[\"y\"].values)\n",
    "    return feature_cols, labels\n",
    "\n",
    "model_dnn_f.fit(input_fn=lambda: input_fn(train), steps=best_parameters[\"steps_f\"][0])\n",
    "\n",
    "# Train prediction\n",
    "train_pred = train[[\"id\"]].assign(y_hat=0, pi_hat=0)\n",
    "temp = model_dnn_f.predict(input_fn=lambda: input_fn(train))\n",
    "y_hat = np.array(list(itertools.islice(temp, 0, None)))\n",
    "train_pred[\"y_hat\"] = y_hat\n",
    "\n",
    "# Fit DNN softmax\n",
    "model_dir_g = \"./g_log_EM\"\n",
    "model_dnn_g = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                            hidden_units=[best_parameters[\"nb_neurons_g\"][0]],\n",
    "                                            model_dir=model_dir_g)\n",
    "\n",
    "model_dnn_g.fit(input_fn=lambda: input_fn(train), steps=best_parameters[\"steps_g\"][0])\n",
    "temp = model_dnn_g.predict(input_fn=lambda: input_fn(train))\n",
    "pi_hat = np.array(list(itertools.islice(temp, 0, None)))\n",
    "\n",
    "# Compute softmax\n",
    "train_pred[\"pi_hat\"] = np.exp(pi_hat)\n",
    "pi_hat_sum_dict = train_pred.groupby(\"id\")[\"pi_hat\"].sum().to_dict()\n",
    "# \"map\" is actually much faster than \"replace\"\n",
    "train_pred[\"pi_hat_sum\"] = train_pred[\"id\"].map(pi_hat_sum_dict)\n",
    "train_pred[\"pi_hat\"] /= train_pred[\"pi_hat_sum\"]\n",
    "\n",
    "# EM algorithm\n",
    "# Change to Q\n",
    "EM_decreasing = True\n",
    "nb_iteration = 0\n",
    "while (EM_decreasing):\n",
    "    nb_iteration +=1\n",
    "\n",
    "    model_dnn = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                              hidden_units=[best_parameters[\"nb_neurons_f\"][0]],\n",
    "                                              model_dir=model_dir)\n",
    "\n",
    "    model_dnn.fit(input_fn=lambda: input_fn(train), steps=best_parameters[\"steps_f\"][0])\n",
    "\n",
    "    # Compute new RMSE\n",
    "    train_pred = train[[\"id\"]].assign(y_hat=0)\n",
    "            \n",
    "    temp = model_dnn.predict(input_fn=lambda: input_fn(train))\n",
    "    # .predict() returns an iterator; convert to an array\n",
    "    y_hat = np.array(list(itertools.islice(temp, 0, None)))\n",
    "    train_pred[\"y_hat\"] = y_hat\n",
    "\n",
    "\n",
    "    print(\"Iteration {0} EM: {1}\".format(nb_iteration, new_RMSE))\n",
    "\n",
    "    if (abs(new_RMSE - RMSE) > 0.1):\n",
    "        RMSE = new_RMSE\n",
    "    else:\n",
    "        EM_decreasing = False\n",
    "\n",
    "models = {\"dnn_1\": model_dnn}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
