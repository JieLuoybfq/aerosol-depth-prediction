{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.utils import resample\n",
    "from hyperopt import STATUS_OK, hp, fmin, tpe, Trials, space_eval\n",
    "\n",
    "from time import time\n",
    "import operator\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "def load_data():\n",
    "    full_data = pd.read_csv(\"X.csv\")\n",
    "    train_y = pd.read_csv(\"ytr.csv\")\n",
    "    # Rename columns to something more interpretable\n",
    "    columns = ([\"reflectance_\" + str(i) for i in range(7)]\n",
    "               + [\"solar_\" + str(i) for i in range(5)] + [\"id\"])\n",
    "    full_data.columns = columns\n",
    "    # Add y to the data frame\n",
    "    split = 98000\n",
    "    y_id_dict = train_y.set_index(\"Id\")[\"y\"].to_dict()\n",
    "    full_data.loc[:(split-1), \"y\"] = full_data.loc[:(split-1), \"id\"].replace(y_id_dict)\n",
    "\n",
    "    train, test = full_data[:split], full_data[split:]\n",
    "    return (train, test)\n",
    "\n",
    "#columns = ([\"id\"] + [\"reflectance_\" + str(i) for i in range(7)]\n",
    "#           + [\"solar_\" + str(i) for i in range(5)] + [\"y\"])\n",
    "#full_data = pd.read_csv(\"MODIS.csv\", header=None, names=columns)\n",
    "#split = 98000\n",
    "#train, test = full_data[:split].copy(), full_data[split:].copy()\n",
    "#train_copy, test_copy = load_data()\n",
    "train, test = load_data()\n",
    "\n",
    "# Parameters\n",
    "n_threads = -1\n",
    "random_seed = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reflectance_0</th>\n",
       "      <th>reflectance_1</th>\n",
       "      <th>reflectance_2</th>\n",
       "      <th>reflectance_3</th>\n",
       "      <th>reflectance_4</th>\n",
       "      <th>reflectance_5</th>\n",
       "      <th>reflectance_6</th>\n",
       "      <th>solar_0</th>\n",
       "      <th>solar_1</th>\n",
       "      <th>solar_2</th>\n",
       "      <th>solar_3</th>\n",
       "      <th>solar_4</th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.580642</td>\n",
       "      <td>2.482233</td>\n",
       "      <td>5.887092</td>\n",
       "      <td>4.732722</td>\n",
       "      <td>4.408482</td>\n",
       "      <td>3.830171</td>\n",
       "      <td>4.388508</td>\n",
       "      <td>22.572888</td>\n",
       "      <td>63.58724</td>\n",
       "      <td>88.05048</td>\n",
       "      <td>4.495216</td>\n",
       "      <td>-50.699904</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.998082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.338455</td>\n",
       "      <td>3.627796</td>\n",
       "      <td>4.723716</td>\n",
       "      <td>3.324726</td>\n",
       "      <td>2.743442</td>\n",
       "      <td>4.727652</td>\n",
       "      <td>2.810193</td>\n",
       "      <td>22.572888</td>\n",
       "      <td>63.58724</td>\n",
       "      <td>88.05048</td>\n",
       "      <td>4.495216</td>\n",
       "      <td>-50.699904</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.998082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.224569</td>\n",
       "      <td>3.522241</td>\n",
       "      <td>6.188831</td>\n",
       "      <td>4.389783</td>\n",
       "      <td>4.177616</td>\n",
       "      <td>4.945918</td>\n",
       "      <td>4.122848</td>\n",
       "      <td>22.572888</td>\n",
       "      <td>63.58724</td>\n",
       "      <td>88.05048</td>\n",
       "      <td>4.495216</td>\n",
       "      <td>-50.699904</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.998082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.717218</td>\n",
       "      <td>2.712012</td>\n",
       "      <td>5.024211</td>\n",
       "      <td>3.944907</td>\n",
       "      <td>3.393424</td>\n",
       "      <td>3.931973</td>\n",
       "      <td>3.489578</td>\n",
       "      <td>22.572888</td>\n",
       "      <td>63.58724</td>\n",
       "      <td>88.05048</td>\n",
       "      <td>4.495216</td>\n",
       "      <td>-50.699904</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.998082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.378857</td>\n",
       "      <td>3.644976</td>\n",
       "      <td>4.515292</td>\n",
       "      <td>3.223825</td>\n",
       "      <td>2.739952</td>\n",
       "      <td>4.599662</td>\n",
       "      <td>2.781574</td>\n",
       "      <td>22.572888</td>\n",
       "      <td>63.58724</td>\n",
       "      <td>88.05048</td>\n",
       "      <td>4.495216</td>\n",
       "      <td>-50.699904</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.998082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reflectance_0  reflectance_1  reflectance_2  reflectance_3  reflectance_4  \\\n",
       "0       1.580642       2.482233       5.887092       4.732722       4.408482   \n",
       "1       2.338455       3.627796       4.723716       3.324726       2.743442   \n",
       "2       2.224569       3.522241       6.188831       4.389783       4.177616   \n",
       "3       1.717218       2.712012       5.024211       3.944907       3.393424   \n",
       "4       2.378857       3.644976       4.515292       3.223825       2.739952   \n",
       "\n",
       "   reflectance_5  reflectance_6    solar_0   solar_1   solar_2   solar_3  \\\n",
       "0       3.830171       4.388508  22.572888  63.58724  88.05048  4.495216   \n",
       "1       4.727652       2.810193  22.572888  63.58724  88.05048  4.495216   \n",
       "2       4.945918       4.122848  22.572888  63.58724  88.05048  4.495216   \n",
       "3       3.931973       3.489578  22.572888  63.58724  88.05048  4.495216   \n",
       "4       4.599662       2.781574  22.572888  63.58724  88.05048  4.495216   \n",
       "\n",
       "     solar_4  id         y  \n",
       "0 -50.699904   1 -3.998082  \n",
       "1 -50.699904   1 -3.998082  \n",
       "2 -50.699904   1 -3.998082  \n",
       "3 -50.699904   1 -3.998082  \n",
       "4 -50.699904   1 -3.998082  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#train, test = train_copy[19600:].copy(), train_copy[:19600].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cols_excl = [\"id\", \"y\"]\n",
    "cols_orig = [c for c in train.columns if c not in cols_excl]\n",
    "\n",
    "# Standardise data for LR\n",
    "train[cols_orig] = scale(train[cols_orig])\n",
    "test[cols_orig] = scale(test[cols_orig])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#feature_cols = [tf.contrib.layers.real_valued_column(k) for k in cols_orig]\n",
    "\n",
    "#regressor = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                         # hidden_units=[9, 9],\n",
    "                                         #)#model_dir=\"./temp_log\")\n",
    "\n",
    "#train, test = train_copy[19600:].copy(), train_copy[:19600].copy()\n",
    "\n",
    "#def input_fn(data_set):\n",
    " #   feature_cols = {k: tf.constant(data_set[k].values) for k in cols_orig}\n",
    "  #  labels = tf.constant(data_set[\"y\"].values)\n",
    "    \n",
    "   # return feature_cols, labels\n",
    "\n",
    "#validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    " #   input_fn=lambda: input_fn(test),\n",
    "  #  early_stopping_rounds=100)\n",
    "\n",
    "#regressor.fit(input_fn=lambda: input_fn(train), steps=10)\n",
    "              #monitors=[validation_monitor])\n",
    "\n",
    "#ev = regressor.evaluate(input_fn=lambda: input_fn(train), steps=1)\n",
    "#loss_score = ev[\"loss\"]\n",
    "#print(\"Loss: {0:f}\".format(loss_score))\n",
    "\n",
    "#y = regressor.predict(input_fn=lambda: input_fn(train))\n",
    "# .predict() returns an iterator; convert to a list and print predictions\n",
    "#predictions = np.array(list(itertools.islice(y, 0, None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cols_dnn = cols_orig\n",
    "\n",
    "models_weights = {\"dnn_1\": 0.2, \"dnn_2\": 0.2, \"dnn_3\": 0.2,\n",
    "                  \"dnn_4\": 0.2, \"dnn_5\": 0.2}\n",
    "#models_cols = {\"dnn_1\": cols_dnn}\n",
    "models_cols = {\"dnn_1\": cols_dnn, \"dnn_2\": cols_dnn, \"dnn_3\": cols_dnn,\n",
    "               \"dnn_4\": cols_dnn, \"dnn_5\": cols_dnn}\n",
    "\n",
    "# Scoring function in the hyperopt hyperparameters tuning.\n",
    "def scoring_function(parameters):\n",
    "    print(\"Training the model with parameters: \")\n",
    "    print(parameters)\n",
    "    average_RMSE = 0.0\n",
    "    n_splits = 5\n",
    "    \n",
    "    # Generate random integer for model_dir\n",
    "    random_int = np.random.randint(1000)\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    nb_fold = 0\n",
    "    for train_index, validation_index in kf.split(train):\n",
    "        nb_fold += 1\n",
    "        train_fold, validation_fold = train.loc[train_index], train.loc[validation_index] \n",
    "\n",
    "        feature_cols = [tf.contrib.layers.real_valued_column(k) for k in cols_dnn]\n",
    "        \n",
    "        model_dir = (\"./log_\"\n",
    "                     + str(parameters[\"steps\"]) + \"_\"\n",
    "                     + str(parameters[\"nb_neurons_1\"]) + \"_\"\n",
    "                     #+ str(parameters[\"nb_neurons_2\"])\n",
    "                     + str(nb_fold) + \"_\"\n",
    "                     + str(random_int)\n",
    "                    )\n",
    "        \n",
    "        # Tune number of layers\n",
    "        model_dnn = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                                    hidden_units=[parameters[\"nb_neurons_1\"]],\n",
    "                                                                #parameters[\"nb_neurons_2\"]],\n",
    "                                                  #optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "                                                   #   learning_rate=0.1,\n",
    "                                                    #  l1_regularization_strength=0.001),\n",
    "                                                  model_dir=model_dir)\n",
    "\n",
    "        def input_fn(data_set):\n",
    "            feature_cols = {k: tf.constant(data_set[k].values) for k in cols_dnn}\n",
    "            labels = tf.constant(data_set[\"y\"].values)\n",
    "            return feature_cols, labels\n",
    "        \n",
    "        model_dnn.fit(input_fn=lambda: input_fn(train_fold), steps=parameters[\"steps\"])\n",
    "\n",
    "        train_pred = train_fold[[\"id\"]].assign(y_hat=0)\n",
    "        #for i, m in models.items():\n",
    "        temp = model_dnn.predict(input_fn=lambda: input_fn(train_fold))\n",
    "        # .predict() returns an iterator; convert to an array\n",
    "        y_hat = np.array(list(itertools.islice(temp, 0, None)))\n",
    "        train_pred[\"y_hat\"] = y_hat\n",
    "\n",
    "        # Use median value by id\n",
    "        y_hat_med = train_pred.groupby(\"id\").median()[\"y_hat\"].to_dict()\n",
    "\n",
    "        RMSE = np.sqrt(mean_squared_error(train_pred[\"id\"].replace(y_hat_med).values, train_fold[\"y\"]))\n",
    "        \n",
    "        # Prune outliers\n",
    "        RMSE_decreasing = True\n",
    "        count = 0\n",
    "        while (RMSE_decreasing):\n",
    "            count +=1\n",
    "            train_pred[\"y_med\"] = train_pred[\"id\"].replace(y_hat_med)\n",
    "\n",
    "            # Distance from the median for each bag\n",
    "            train_pred[\"score\"] = (train_pred[\"y_hat\"] - train_pred[\"y_med\"])**2\n",
    "            # Rank of each instance by bag\n",
    "            train_pred[\"rank\"] = train_pred.groupby(\"id\")[\"score\"].rank()\n",
    "            bag_size_dict = train_pred.groupby(\"id\")[\"score\"].count().to_dict()\n",
    "            train_pred[\"bag_size\"] = train_pred[\"id\"].replace(bag_size_dict)\n",
    "            train_pred[\"rank\"] = train_pred[\"rank\"] / train_pred[\"bag_size\"]\n",
    "\n",
    "            # Remove outliers\n",
    "            outliers_index = train_pred[\"rank\"] > (1 - parameters[\"outliers_threshold\"])\n",
    "            train_fold = train_fold.loc[~outliers_index, :].reset_index(drop=True)\n",
    "\n",
    "            model_dnn = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                                      hidden_units=[parameters[\"nb_neurons_1\"]],\n",
    "                                                                    #parameters[\"nb_neurons_2\"]],\n",
    "                                                      #optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "                                                       #   learning_rate=0.1,\n",
    "                                                        #  l1_regularization_strength=0.001),\n",
    "                                                      model_dir=model_dir)\n",
    "\n",
    "            model_dnn.fit(input_fn=lambda: input_fn(train_fold), steps=parameters[\"steps\"])\n",
    "\n",
    "            # Compute new RMSE\n",
    "            train_pred = train_fold[[\"id\"]].assign(y_hat=0)\n",
    "            \n",
    "            #for i, m in models.items():\n",
    "            temp = model_dnn.predict(input_fn=lambda: input_fn(train_fold))\n",
    "            # .predict() returns an iterator; convert to an array\n",
    "            y_hat = np.array(list(itertools.islice(temp, 0, None)))\n",
    "            train_pred[\"y_hat\"] = y_hat\n",
    "\n",
    "            # Use median value by id\n",
    "            y_hat_med = train_pred.groupby(\"id\").median()[\"y_hat\"].to_dict()\n",
    "\n",
    "            new_RMSE = np.sqrt(mean_squared_error(train_pred[\"id\"].replace(y_hat_med), train_fold[\"y\"]))\n",
    "            print(\"Pruning {0} RMSE: {1}\".format(count, new_RMSE))\n",
    "\n",
    "            if (abs(new_RMSE - RMSE) > parameters[\"gain_threshold\"]):\n",
    "                RMSE = new_RMSE\n",
    "            else:\n",
    "                RMSE_decreasing = False\n",
    "        \n",
    "        # Bagging of RNN\n",
    "        # Bootstrap 1\n",
    "        #train_fold_1 = train_fold\n",
    "        #model_dnn_1 = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "         #                                           hidden_units=[parameters[\"nb_neurons_1\"]])\n",
    "                                                    #model_dir=model_dir)\n",
    "        #model_dnn_1.fit(input_fn=lambda: input_fn(train_fold_1), steps=parameters[\"steps\"])\n",
    "        \n",
    "        # Boostrap 2\n",
    "        train_fold_2 = resample(train_fold, random_state=random_seed).sort_values(by=[\"id\"]).reset_index(drop=True)\n",
    "        model_dnn_2 = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                                    hidden_units=[parameters[\"nb_neurons_1\"]])\n",
    "                                                    #model_dir=model_dir)\n",
    "        model_dnn_2.fit(input_fn=lambda: input_fn(train_fold_2), steps=parameters[\"steps\"])\n",
    "            \n",
    "        # Bootstrap 3\n",
    "        train_fold_3 = resample(train_fold, random_state=(random_seed+1)).sort_values(by=[\"id\"]).reset_index(drop=True)\n",
    "        model_dnn_3 = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                                    hidden_units=[parameters[\"nb_neurons_1\"]])\n",
    "                                                    #model_dir=model_dir)\n",
    "        model_dnn_3.fit(input_fn=lambda: input_fn(train_fold_3), steps=parameters[\"steps\"])\n",
    "        \n",
    "        # Bootstrap 4\n",
    "        train_fold_4 = resample(train_fold, random_state=(random_seed+2)).sort_values(by=[\"id\"]).reset_index(drop=True)\n",
    "        model_dnn_4 = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                                    hidden_units=[parameters[\"nb_neurons_1\"]])\n",
    "                                                    #model_dir=model_dir)\n",
    "        model_dnn_4.fit(input_fn=lambda: input_fn(train_fold_4), steps=parameters[\"steps\"])\n",
    "        \n",
    "        # Bootstrap 5\n",
    "        train_fold_5 = resample(train_fold, random_state=(random_seed+3)).sort_values(by=[\"id\"]).reset_index(drop=True)\n",
    "        model_dnn_5 = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                                    hidden_units=[parameters[\"nb_neurons_1\"]])\n",
    "                                                    #model_dir=model_dir)\n",
    "        model_dnn_5.fit(input_fn=lambda: input_fn(train_fold_5), steps=parameters[\"steps\"])\n",
    "        \n",
    "        # Changed to model_dnn instead of model_dnn_1\n",
    "        models = {\"dnn_1\": model_dnn, \"dnn_2\": model_dnn_2, \"dnn_3\": model_dnn_3,\n",
    "                  \"dnn_4\": model_dnn_4, \"dnn_5\": model_dnn_5}\n",
    "        \n",
    "        # Compute RMSE on validation set\n",
    "        validation_pred = validation_fold[[\"id\"]].assign(y_hat=0).reset_index(drop=True)\n",
    "        for i, m in models.items():\n",
    "            temp = m.predict(input_fn=lambda: input_fn(validation_fold))\n",
    "            # .predict() returns an iterator; convert to an array\n",
    "            y_hat = np.array(list(itertools.islice(temp, 0, None)))\n",
    "            validation_pred[\"y_hat\"] += models_weights[i] * y_hat\n",
    "            \n",
    "        # Use median value by id\n",
    "        y_hat_med = validation_pred.groupby(\"id\").median()[\"y_hat\"].to_dict()\n",
    "        \n",
    "        RMSE = np.sqrt(mean_squared_error(validation_pred[\"id\"].replace(y_hat_med).values, validation_fold[\"y\"]))\n",
    "        average_RMSE += RMSE\n",
    "        print(\"Validation fold {0} RMSE: {1}\".format(nb_fold, RMSE))\n",
    "\n",
    "    average_RMSE /= n_splits\n",
    "\n",
    "    print(\"Cross-validation score: {0}\\n\".format(average_RMSE))\n",
    "    \n",
    "    return {\"loss\": average_RMSE, \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model with parameters: \n",
      "{'gain_threshold': 0.015, 'steps': 3800, 'nb_neurons_1': 10, 'outliers_threshold': 0.05}\n",
      "Pruning 1 RMSE: 0.674073882641\n",
      "Pruning 2 RMSE: 0.662346176042\n",
      "Validation fold 1 RMSE: 0.641617979853\n",
      "Pruning 1 RMSE: 0.635676000166\n",
      "Pruning 2 RMSE: 0.619615432596\n",
      "Pruning 3 RMSE: 0.610423043833\n",
      "Validation fold 2 RMSE: 0.73246715849\n",
      "Pruning 1 RMSE: 0.643307566169\n",
      "Pruning 2 RMSE: 0.62938122591\n",
      "Validation fold 3 RMSE: 0.710291994342\n",
      "Pruning 1 RMSE: 0.659927208941\n",
      "Pruning 2 RMSE: 0.647666579446\n",
      "Validation fold 4 RMSE: 0.670328953596\n",
      "Pruning 1 RMSE: 0.632532403066\n",
      "Pruning 2 RMSE: 0.614925033513\n",
      "Pruning 3 RMSE: 0.605334750968\n",
      "Validation fold 5 RMSE: 0.753588096326\n",
      "Cross-validation score: 0.701658836521\n",
      "\n",
      "Training the model with parameters: \n",
      "{'gain_threshold': 0.015, 'steps': 4800, 'nb_neurons_1': 10, 'outliers_threshold': 0.05}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-170c9c69181e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m best = fmin(scoring_function, parameters_grid, algo=tpe.suggest, max_evals=2, \n\u001b[0;32m---> 14\u001b[0;31m             trials=trials)\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcomputing_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         )\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/hyperopt/base.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             return_argmin=return_argmin)\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     verbose=verbose)\n\u001b[1;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/hyperopt/base.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-63bf0be825ba>\u001b[0m in \u001b[0;36mscoring_function\u001b[0;34m(parameters)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfeature_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mmodel_dnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"steps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/util/deprecation.pyc\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0m_call_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qualified_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             func.__module__, arg_name, date, instructions)\n\u001b[0;32m--> 280\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m     new_func.__doc__ = _add_deprecated_arg_notice_to_docstring(\n\u001b[1;32m    282\u001b[0m         func.__doc__, date, instructions)\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    424\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_session_run_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks)\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_fn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m       \u001b[0msummary_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSummaryWriterCache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    460\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    784\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    787\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAbortedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         logging.info('An AbortedError was raised. Closing the current session. '\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    889\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Grid to pick parameters from.\n",
    "parameters_grid = {\"steps\"             : hp.choice(\"steps\", np.arange(3000, 5000, 200, dtype=int)),\n",
    "                   \"nb_neurons_1\"      : hp.choice(\"nb_neurons_1\", np.arange(9, 12, 1, dtype=int)),\n",
    "                   \"outliers_threshold\": hp.quniform(\"outliers_threshold\", 0.03, 0.06, 0.01),\n",
    "                   \"gain_threshold\"    : hp.quniform(\"gain_threshold\", 0.005, 0.02, 0.005)\n",
    "                   #\"nb_neurons_2\": hp.choice(\"nb_neurons_2\", np.arange(5, 10, 1, dtype=int))\n",
    "                  }\n",
    "# Record the information about the cross-validation.\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(scoring_function, parameters_grid, algo=tpe.suggest, max_evals=2, \n",
    "            trials=trials)\n",
    "\n",
    "computing_time = time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "5 DNN and use the pruning DNN\n",
    "Training the model with parameters: \n",
    "{'gain_threshold': 0.015, 'steps': 3800, 'nb_neurons_1': 10, 'outliers_threshold': 0.05}\n",
    "Pruning 1 RMSE: 0.674073882641\n",
    "Pruning 2 RMSE: 0.662346176042\n",
    "Validation fold 1 RMSE: 0.641617979853\n",
    "Pruning 1 RMSE: 0.635676000166\n",
    "Pruning 2 RMSE: 0.619615432596\n",
    "Pruning 3 RMSE: 0.610423043833\n",
    "Validation fold 2 RMSE: 0.73246715849\n",
    "Pruning 1 RMSE: 0.643307566169\n",
    "Pruning 2 RMSE: 0.62938122591\n",
    "Validation fold 3 RMSE: 0.710291994342\n",
    "Pruning 1 RMSE: 0.659927208941\n",
    "Pruning 2 RMSE: 0.647666579446\n",
    "Validation fold 4 RMSE: 0.670328953596\n",
    "Pruning 1 RMSE: 0.632532403066\n",
    "Pruning 2 RMSE: 0.614925033513\n",
    "Pruning 3 RMSE: 0.605334750968\n",
    "Validation fold 5 RMSE: 0.753588096326\n",
    "Cross-validation score: 0.701658836521"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "5 DNN pruning with a first DNN then train 5 0.2 weighted DNN\n",
    "Training the model with parameters: \n",
    "{'gain_threshold': 0.015, 'steps': 2200, 'nb_neurons_1': 9, 'outliers_threshold': 0.05}\n",
    "Pruning 1 RMSE: 0.694068399998\n",
    "Pruning 2 RMSE: 0.68319691192\n",
    "Validation fold 1 RMSE: 0.657984789376\n",
    "Pruning 1 RMSE: 0.665720056564\n",
    "Pruning 2 RMSE: 0.652525762923\n",
    "Validation fold 2 RMSE: 0.746126089816\n",
    "Pruning 1 RMSE: 0.670865372689\n",
    "Pruning 2 RMSE: 0.657049715495\n",
    "Validation fold 3 RMSE: 0.715898563369\n",
    "Pruning 1 RMSE: 0.674144585081\n",
    "Pruning 2 RMSE: 0.655254059805\n",
    "Pruning 3 RMSE: 0.645841747765\n",
    "Validation fold 4 RMSE: 0.686994886197\n",
    "Pruning 1 RMSE: 0.640782640919\n",
    "Pruning 2 RMSE: 0.62576629908\n",
    "Pruning 3 RMSE: 0.6191962246\n",
    "Validation fold 5 RMSE: 0.757705397434\n",
    "Cross-validation score: 0.712941945239\n",
    "\n",
    "Training the model with parameters: \n",
    "{'gain_threshold': 0.01, 'steps': 3400, 'nb_neurons_1': 11, 'outliers_threshold': 0.05}\n",
    "Pruning 1 RMSE: 0.672635757823\n",
    "Pruning 2 RMSE: 0.661982328413\n",
    "Pruning 3 RMSE: 0.655412024265\n",
    "Validation fold 1 RMSE: 0.632837032519\n",
    "Pruning 1 RMSE: 0.642811068713\n",
    "Pruning 2 RMSE: 0.632067871794\n",
    "Pruning 3 RMSE: 0.624793548264\n",
    "Validation fold 2 RMSE: 0.727289064772\n",
    "Pruning 1 RMSE: 0.658106411403\n",
    "Pruning 2 RMSE: 0.635442263112\n",
    "Pruning 3 RMSE: 0.618591227467\n",
    "Pruning 4 RMSE: 0.609851324476\n",
    "Validation fold 3 RMSE: 0.717622664993\n",
    "Pruning 1 RMSE: 0.655587115002\n",
    "Pruning 2 RMSE: 0.64177101986\n",
    "Pruning 3 RMSE: 0.634889111319\n",
    "Validation fold 4 RMSE: 0.67796187099\n",
    "Pruning 1 RMSE: 0.635166511006\n",
    "Pruning 2 RMSE: 0.612866670615\n",
    "Pruning 3 RMSE: 0.602643711575\n",
    "Pruning 4 RMSE: 0.590786436001\n",
    "Pruning 5 RMSE: 0.585929889116\n",
    "Validation fold 5 RMSE: 0.745885863766\n",
    "Cross-validation score: 0.700319299408\n",
    "\n",
    "Training the model with parameters: \n",
    "{'gain_threshold': 0.01, 'steps': 3200, 'nb_neurons_1': 9, 'outliers_threshold': 0.05}\n",
    "Pruning 1 RMSE: 0.673878243224\n",
    "Pruning 2 RMSE: 0.657360188279\n",
    "Pruning 3 RMSE: 0.642604850865\n",
    "Pruning 4 RMSE: 0.635441991907\n",
    "Validation fold 1 RMSE: 0.639493686463\n",
    "Pruning 1 RMSE: 0.650316328335\n",
    "Pruning 2 RMSE: 0.635764740628\n",
    "Pruning 3 RMSE: 0.625281288299\n",
    "Pruning 4 RMSE: 0.618857759816\n",
    "Validation fold 2 RMSE: 0.732526425149\n",
    "Pruning 1 RMSE: 0.663290232475\n",
    "Pruning 2 RMSE: 0.651664810483\n",
    "Pruning 3 RMSE: 0.638306582562\n",
    "Pruning 4 RMSE: 0.625389960277\n",
    "Pruning 5 RMSE: 0.619638207743\n",
    "Validation fold 3 RMSE: 0.709389594885\n",
    "Pruning 1 RMSE: 0.665109073757\n",
    "Pruning 2 RMSE: 0.655310627332\n",
    "Validation fold 4 RMSE: 0.684705184081\n",
    "Pruning 1 RMSE: 0.639195545405\n",
    "Pruning 2 RMSE: 0.624107169148\n",
    "Pruning 3 RMSE: 0.614627025796\n",
    "Validation fold 5 RMSE: 0.751663827286\n",
    "Cross-validation score: 0.703555743573\n",
    "\n",
    "Training the model with parameters: \n",
    "{'gain_threshold': 0.01, 'steps': 2400, 'nb_neurons_1': 9, 'outliers_threshold': 0.06}\n",
    "Pruning 1 RMSE: 0.672027783277\n",
    "Pruning 2 RMSE: 0.658416156325\n",
    "Pruning 3 RMSE: 0.650714100529\n",
    "Validation fold 1 RMSE: 0.64726858528\n",
    "Pruning 1 RMSE: 0.67959968961\n",
    "Pruning 2 RMSE: 0.663599458586\n",
    "Pruning 3 RMSE: 0.653446512383\n",
    "Pruning 4 RMSE: 0.647451596973\n",
    "Validation fold 2 RMSE: 0.73745400766\n",
    "Pruning 1 RMSE: 0.671306058337\n",
    "Pruning 2 RMSE: 0.652840696921\n",
    "Pruning 3 RMSE: 0.641901681627\n",
    "Pruning 4 RMSE: 0.634831914775\n",
    "Validation fold 3 RMSE: 0.711275356156\n",
    "Pruning 1 RMSE: 0.672597980531\n",
    "Pruning 2 RMSE: 0.660307287653\n",
    "Pruning 3 RMSE: 0.655366412873\n",
    "Validation fold 4 RMSE: 0.682952884798\n",
    "Pruning 1 RMSE: 0.652781515031\n",
    "Pruning 2 RMSE: 0.638197522441\n",
    "Pruning 3 RMSE: 0.628958394346\n",
    "Validation fold 5 RMSE: 0.768046027259\n",
    "Cross-validation score: 0.70939937223\n",
    "    \n",
    "    \n",
    "Training the model with parameters: \n",
    "{'gain_threshold': 0.01, 'steps': 2400, 'nb_neurons_1': 10, 'outliers_threshold': 0.05}\n",
    "Pruning 1 RMSE: 0.686858771359\n",
    "Pruning 2 RMSE: 0.672878467855\n",
    "Pruning 3 RMSE: 0.665149234767\n",
    "Validation fold 1 RMSE: 0.642083994677\n",
    "Pruning 1 RMSE: 0.652773718198\n",
    "Pruning 2 RMSE: 0.641075258377\n",
    "Pruning 3 RMSE: 0.63371016034\n",
    "Validation fold 2 RMSE: 0.738007531296\n",
    "Pruning 1 RMSE: 0.663196334567\n",
    "Pruning 2 RMSE: 0.643597311854\n",
    "Pruning 3 RMSE: 0.630428357205\n",
    "Pruning 4 RMSE: 0.623077216084\n",
    "Validation fold 3 RMSE: 0.71170883265\n",
    "Pruning 1 RMSE: 0.689810676757\n",
    "Pruning 2 RMSE: 0.677621845341\n",
    "Pruning 3 RMSE: 0.669599938078\n",
    "Validation fold 4 RMSE: 0.690884317575\n",
    "Pruning 1 RMSE: 0.651690464316\n",
    "Pruning 2 RMSE: 0.639165758066\n",
    "Pruning 3 RMSE: 0.630737742502\n",
    "Validation fold 5 RMSE: 0.753819804982\n",
    "Cross-validation score: 0.707300896236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "5 DNN model_dir for pruning {\"dnn_1\": 0.4, \"dnn_2\": 0.15, \"dnn_3\": 0.15,\n",
    "                  \"dnn_4\": 0.15, \"dnn_5\": 0.15}\n",
    "Training the model with parameters: \n",
    "{'gain_threshold': 0.01, 'steps': 2100, 'nb_neurons_1': 9, 'outliers_threshold': 0.05}\n",
    "Pruning 1 RMSE: 0.676416816474\n",
    "Pruning 2 RMSE: 0.663520827885\n",
    "Pruning 3 RMSE: 0.655253952782\n",
    "Validation fold 1 RMSE: 0.638520567696\n",
    "Pruning 1 RMSE: 0.664297149376\n",
    "Pruning 2 RMSE: 0.651764716202\n",
    "Pruning 3 RMSE: 0.643706111477\n",
    "Validation fold 2 RMSE: 0.739466649119\n",
    "Pruning 1 RMSE: 0.664528195881\n",
    "Pruning 2 RMSE: 0.651617243289\n",
    "Pruning 3 RMSE: 0.644582271931\n",
    "Validation fold 3 RMSE: 0.718805738469\n",
    "Pruning 1 RMSE: 0.687431994827\n",
    "Pruning 2 RMSE: 0.673373446494\n",
    "Pruning 3 RMSE: 0.665013005853\n",
    "Validation fold 4 RMSE: 0.67264303545\n",
    "Pruning 1 RMSE: 0.659725291472\n",
    "Pruning 2 RMSE: 0.647505977336\n",
    "Pruning 3 RMSE: 0.640364412581\n",
    "Validation fold 5 RMSE: 0.756788708091\n",
    "Cross-validation score: 0.705244939765\n",
    "\n",
    "    \n",
    "Training the model with parameters: (same coefs)\n",
    "{'gain_threshold': 0.01, 'steps': 2100, 'nb_neurons_1': 11, 'outliers_threshold': 0.05}\n",
    "Pruning 1 RMSE: 0.671783958403\n",
    "Pruning 2 RMSE: 0.659132942345\n",
    "Pruning 3 RMSE: 0.65087802989\n",
    "Validation fold 1 RMSE: 0.642550227753\n",
    "Pruning 1 RMSE: 0.653374572234\n",
    "Pruning 2 RMSE: 0.63645978204\n",
    "Pruning 3 RMSE: 0.624386509142\n",
    "Pruning 4 RMSE: 0.6140196058\n",
    "Pruning 5 RMSE: 0.609660735924\n",
    "Validation fold 2 RMSE: 0.725755962849\n",
    "Pruning 1 RMSE: 0.664299289878\n",
    "Pruning 2 RMSE: 0.648366505728\n",
    "Pruning 3 RMSE: 0.640081573857\n",
    "Validation fold 3 RMSE: 0.714825658397\n",
    "Pruning 1 RMSE: 0.66744880357\n",
    "Pruning 2 RMSE: 0.651428349357\n",
    "Pruning 3 RMSE: 0.639399741055\n",
    "Pruning 4 RMSE: 0.631543676175\n",
    "Validation fold 4 RMSE: 0.670998448018\n",
    "Pruning 1 RMSE: 0.659382834695\n",
    "Pruning 2 RMSE: 0.639853733358\n",
    "Pruning 3 RMSE: 0.630634884058\n",
    "Validation fold 5 RMSE: 0.757291856953\n",
    "Cross-validation score: 0.702284430794\n",
    "    \n",
    "Training the model with parameters: (same coefs)\n",
    "{'gain_threshold': 0.01, 'steps': 1100, 'nb_neurons_1': 9, 'outliers_threshold': 0.05}\n",
    "Pruning 1 RMSE: 0.687293470623\n",
    "Pruning 2 RMSE: 0.673543089191\n",
    "Pruning 3 RMSE: 0.665733359442\n",
    "Validation fold 1 RMSE: 0.649368530503\n",
    "Pruning 1 RMSE: 0.679928297676\n",
    "Pruning 2 RMSE: 0.668609243864\n",
    "Pruning 3 RMSE: 0.662262044876\n",
    "Validation fold 2 RMSE: 0.744633907485\n",
    "Pruning 1 RMSE: 0.669438977141\n",
    "Pruning 2 RMSE: 0.658915490238\n",
    "Pruning 3 RMSE: 0.649607975009\n",
    "Validation fold 3 RMSE: 0.710778483402\n",
    "Pruning 1 RMSE: 0.708289420438\n",
    "Pruning 2 RMSE: 0.696308353637\n",
    "Pruning 3 RMSE: 0.689003339174\n",
    "Validation fold 4 RMSE: 0.710196884293\n",
    "Pruning 1 RMSE: 0.682813446172\n",
    "Pruning 2 RMSE: 0.670210695852\n",
    "Pruning 3 RMSE: 0.661776509643\n",
    "Validation fold 5 RMSE: 0.76190366844\n",
    "Cross-validation score: 0.715376294825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 1 DNN with model_dir corrected\n",
    "Training the model with parameters: \n",
    "{'gain_threshold': 0.005, 'steps': 1000, 'nb_neurons_1': 11, 'outliers_threshold': 0.05}\n",
    "Pruning 1 RMSE: 0.708254362329\n",
    "Pruning 2 RMSE: 0.690809364036\n",
    "Pruning 3 RMSE: 0.681259286244\n",
    "Pruning 4 RMSE: 0.675679762642\n",
    "Pruning 5 RMSE: 0.670965511179\n",
    "Validation fold 1 RMSE: 0.64861798817\n",
    "Pruning 1 RMSE: 0.658292571898\n",
    "Pruning 2 RMSE: 0.645737414652\n",
    "Pruning 3 RMSE: 0.63797501753\n",
    "Pruning 4 RMSE: 0.632583378549\n",
    "Pruning 5 RMSE: 0.627584029004\n",
    "Validation fold 2 RMSE: 0.723643911448\n",
    "Pruning 1 RMSE: 0.687961545764\n",
    "Pruning 2 RMSE: 0.672401033846\n",
    "Pruning 3 RMSE: 0.660611288466\n",
    "Pruning 4 RMSE: 0.650237174155\n",
    "Pruning 5 RMSE: 0.64198570573\n",
    "Pruning 6 RMSE: 0.636986731147\n",
    "Validation fold 3 RMSE: 0.719981056486\n",
    "Pruning 1 RMSE: 0.697781938911\n",
    "Pruning 2 RMSE: 0.681268268398\n",
    "Pruning 3 RMSE: 0.671483140797\n",
    "Pruning 4 RMSE: 0.666088232133\n",
    "Pruning 5 RMSE: 0.661858777702\n",
    "Validation fold 4 RMSE: 0.715854578144\n",
    "Pruning 1 RMSE: 0.66224449426\n",
    "Pruning 2 RMSE: 0.644538081642\n",
    "Pruning 3 RMSE: 0.634079022739\n",
    "Pruning 4 RMSE: 0.624630852786\n",
    "Pruning 5 RMSE: 0.619603795183\n",
    "Pruning 6 RMSE: 0.61598970139\n",
    "Validation fold 5 RMSE: 0.762927716346\n",
    "Cross-validation score: 0.714205050119\n",
    "\n",
    "Training the model with parameters: \n",
    "{'gain_threshold': 0.01, 'steps': 1100, 'nb_neurons_1': 10, 'outliers_threshold': 0.05}\n",
    "Pruning 1 RMSE: 0.713960264442\n",
    "Pruning 2 RMSE: 0.701637487701\n",
    "Pruning 3 RMSE: 0.69375349128\n",
    "Validation fold 1 RMSE: 0.641879797964\n",
    "Pruning 1 RMSE: 0.671532366166\n",
    "Pruning 2 RMSE: 0.656442799709\n",
    "Pruning 3 RMSE: 0.645330625403\n",
    "Pruning 4 RMSE: 0.638014896705\n",
    "Validation fold 2 RMSE: 0.741045867638\n",
    "Pruning 1 RMSE: 0.690110283558\n",
    "Pruning 2 RMSE: 0.678068607072\n",
    "Pruning 3 RMSE: 0.662923307388\n",
    "Pruning 4 RMSE: 0.654881538105\n",
    "Validation fold 3 RMSE: 0.687377107282\n",
    "Pruning 1 RMSE: 0.70616839345\n",
    "Pruning 2 RMSE: 0.692895897509\n",
    "Pruning 3 RMSE: 0.686021953655\n",
    "Validation fold 4 RMSE: 0.688327537634\n",
    "Pruning 1 RMSE: 0.66943420746\n",
    "Pruning 2 RMSE: 0.65286815522\n",
    "Pruning 3 RMSE: 0.638691155949\n",
    "Pruning 4 RMSE: 0.627600556022\n",
    "Pruning 5 RMSE: 0.622316478\n",
    "Validation fold 5 RMSE: 0.765910014041\n",
    "Cross-validation score: 0.704908064912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Ensemble of 3 DNN\n",
    "Training the model with parameters: \n",
    "{'gain_threshold': 0.005, 'steps': 1000, 'nb_neurons_1': 11, 'outliers_threshold': 0.05}\n",
    "Pruning 1 RMSE: 0.71116941007\n",
    "Pruning 2 RMSE: 0.710134244747\n",
    "Validation fold 1 RMSE: 0.67016269301\n",
    "Pruning 1 RMSE: 0.693788730369\n",
    "Pruning 2 RMSE: 0.681699022039\n",
    "Pruning 3 RMSE: 0.703264811229\n",
    "Pruning 4 RMSE: 0.671334288662\n",
    "Pruning 5 RMSE: 0.672755595177\n",
    "Validation fold 2 RMSE: 0.742960274892\n",
    "Pruning 1 RMSE: 0.693855159996\n",
    "Pruning 2 RMSE: 0.691917725258\n",
    "Validation fold 3 RMSE: 0.716453069035\n",
    "Pruning 1 RMSE: 0.698029552278\n",
    "Pruning 2 RMSE: 0.698402913616\n",
    "Validation fold 4 RMSE: 0.702381816743\n",
    "Pruning 1 RMSE: 0.669835541061\n",
    "Pruning 2 RMSE: 0.670934743074\n",
    "Validation fold 5 RMSE: 0.772065210064\n",
    "Cross-validation score: 0.720804612749\n",
    "    \n",
    "Training the model with parameters: \n",
    "{'gain_threshold': 0.005, 'steps': 1100, 'nb_neurons_1': 11, 'outliers_threshold': 0.05}\n",
    "Pruning 1 RMSE: 0.710970210115\n",
    "Pruning 2 RMSE: 0.723884803499\n",
    "Pruning 3 RMSE: 0.705558405266\n",
    "Pruning 4 RMSE: 0.69082150458\n",
    "Pruning 5 RMSE: 0.709012637324\n",
    "Pruning 6 RMSE: 0.689840083409\n",
    "Pruning 7 RMSE: 0.682960915979\n",
    "Pruning 8 RMSE: 0.689320580892\n",
    "Pruning 9 RMSE: 0.733669462986\n",
    "Pruning 10 RMSE: 0.702594016806\n",
    "Pruning 11 RMSE: 0.700092614618\n",
    "Validation fold 1 RMSE: 0.639888747346\n",
    "Pruning 1 RMSE: 0.702693117724\n",
    "Validation fold 2 RMSE: 0.756274354279\n",
    "Pruning 1 RMSE: 0.691091309155\n",
    "Pruning 2 RMSE: 0.691357233141\n",
    "Validation fold 3 RMSE: 0.73679429174\n",
    "Pruning 1 RMSE: 0.714865007836\n",
    "Pruning 2 RMSE: 0.689779608571\n",
    "Pruning 3 RMSE: 0.688207703398\n",
    "Validation fold 4 RMSE: 0.686380994175\n",
    "Pruning 1 RMSE: 0.684824585281\n",
    "Pruning 2 RMSE: 0.669877290062\n",
    "Pruning 3 RMSE: 0.686328240571\n",
    "Pruning 4 RMSE: 0.663275388897\n",
    "Pruning 5 RMSE: 0.668140496708\n",
    "Validation fold 5 RMSE: 0.768409407507\n",
    "Cross-validation score: 0.717549559009\n",
    "    \n",
    "Training the model with parameters: \n",
    "{'gain_threshold': 0.005, 'steps': 1100, 'nb_neurons_1': 11, 'outliers_threshold': 0.05}\n",
    "Pruning 1 RMSE: 0.705035094312\n",
    "Pruning 2 RMSE: 0.714659640929\n",
    "Pruning 3 RMSE: 0.712357459314\n",
    "Validation fold 1 RMSE: 0.661191916714\n",
    "Pruning 1 RMSE: 0.686965456513\n",
    "Validation fold 2 RMSE: 0.749879491243\n",
    "Pruning 1 RMSE: 0.689762043097\n",
    "Pruning 2 RMSE: 0.69232873535\n",
    "Validation fold 3 RMSE: 0.724016986696\n",
    "Pruning 1 RMSE: 0.690028220234\n",
    "Pruning 2 RMSE: 0.69337827918\n",
    "Validation fold 4 RMSE: 0.703435739334\n",
    "Pruning 1 RMSE: 0.681859928879\n",
    "Pruning 2 RMSE: 0.67091896457\n",
    "Pruning 3 RMSE: 0.677659388273\n",
    "Pruning 4 RMSE: 0.664039872409\n",
    "Pruning 5 RMSE: 0.667718583335\n",
    "Validation fold 5 RMSE: 0.757494009563\n",
    "Cross-validation score: 0.71920362871"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "min(trials.losses())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the best parameters as a csv.\n",
    "best_parameters = pd.DataFrame({key: [value] for (key, value) in \n",
    "                                zip(space_eval(parameters_grid, best).keys(),\n",
    "                                    space_eval(parameters_grid, best).values())})\n",
    "# Add the corresponding score.\n",
    "best_parameters[\"score\"] = min(trials.losses())\n",
    "best_parameters.to_csv(\"best_parameters_6.csv\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 1 RMSE: 0.682372839094\n",
      "Pruning 2 RMSE: 0.668013398984\n",
      "Pruning 3 RMSE: 0.659537802041\n"
     ]
    }
   ],
   "source": [
    "cols_dnn = cols_orig\n",
    "\n",
    "models_weights = {\"dnn_1\": 0.2, \"dnn_2\": 0.2, \"dnn_3\": 0.2,\n",
    "                  \"dnn_4\": 0.2, \"dnn_5\": 0.2}\n",
    "\n",
    "models_cols = {\"dnn_1\": cols_dnn, \"dnn_2\": cols_dnn, \"dnn_3\": cols_dnn,\n",
    "               \"dnn_4\": cols_dnn, \"dnn_5\": cols_dnn}\n",
    "\n",
    "best_parameters = pd.read_csv(\"best_parameters_5.csv\", encoding=\"utf-8\")\n",
    "#best_parameters = dict(zip(best_parameters.columns[:-1], best_parameters.iloc[0].values[:-1]))\n",
    "\n",
    "feature_cols = [tf.contrib.layers.real_valued_column(k) for k in cols_dnn]\n",
    "\n",
    "model_dir = \"./log_submit_5\"\n",
    "        \n",
    "# Tune number of layers\n",
    "model_dnn = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                          hidden_units=[best_parameters[\"nb_neurons_1\"][0]],\n",
    "                                          model_dir=model_dir)\n",
    "\n",
    "def input_fn(data_set):\n",
    "    feature_cols = {k: tf.constant(data_set[k].values) for k in cols_dnn}\n",
    "    labels = tf.constant(data_set[\"y\"].values)\n",
    "    return feature_cols, labels\n",
    "\n",
    "model_dnn.fit(input_fn=lambda: input_fn(train), steps=best_parameters[\"steps\"][0])\n",
    "        \n",
    "\n",
    "train_pred = train[[\"id\"]].assign(y_hat=0)\n",
    "temp = model_dnn.predict(input_fn=lambda: input_fn(train))\n",
    "# .predict() returns an iterator; convert to an array\n",
    "y_hat = np.array(list(itertools.islice(temp, 0, None)))\n",
    "train_pred[\"y_hat\"] = y_hat\n",
    "\n",
    "# Use median value by id\n",
    "y_hat_med = train_pred.groupby(\"id\").median()[\"y_hat\"].to_dict()\n",
    "\n",
    "RMSE = np.sqrt(mean_squared_error(train_pred[\"id\"].replace(y_hat_med).values, train[\"y\"]))\n",
    "        \n",
    "# Prune outliers\n",
    "RMSE_decreasing = True\n",
    "count = 0\n",
    "while (RMSE_decreasing):\n",
    "    count +=1\n",
    "    train_pred[\"y_med\"] = train_pred[\"id\"].replace(y_hat_med)\n",
    "\n",
    "    # Distance from the median for each bag\n",
    "    train_pred[\"score\"] = (train_pred[\"y_hat\"] - train_pred[\"y_med\"])**2\n",
    "    # Rank of each instance by bag\n",
    "    train_pred[\"rank\"] = train_pred.groupby(\"id\")[\"score\"].rank()\n",
    "    bag_size_dict = train_pred.groupby(\"id\")[\"score\"].count().to_dict()\n",
    "    train_pred[\"bag_size\"] = train_pred[\"id\"].replace(bag_size_dict)\n",
    "    train_pred[\"rank\"] = train_pred[\"rank\"] / train_pred[\"bag_size\"]\n",
    "\n",
    "    # Remove outliers\n",
    "    outliers_index = train_pred[\"rank\"] > (1 - best_parameters[\"outliers_threshold\"][0])\n",
    "    train = train.loc[~outliers_index, :].reset_index(drop=True)\n",
    "\n",
    "    model_dnn = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                              hidden_units=[best_parameters[\"nb_neurons_1\"][0]],\n",
    "                                              model_dir=model_dir)\n",
    "\n",
    "    model_dnn.fit(input_fn=lambda: input_fn(train), steps=best_parameters[\"steps\"][0])\n",
    "\n",
    "    # Compute new RMSE\n",
    "    train_pred = train[[\"id\"]].assign(y_hat=0)\n",
    "            \n",
    "    temp = model_dnn.predict(input_fn=lambda: input_fn(train))\n",
    "    # .predict() returns an iterator; convert to an array\n",
    "    y_hat = np.array(list(itertools.islice(temp, 0, None)))\n",
    "    train_pred[\"y_hat\"] = y_hat\n",
    "\n",
    "    # Use median value by id\n",
    "    y_hat_med = train_pred.groupby(\"id\").median()[\"y_hat\"].to_dict()\n",
    "\n",
    "    new_RMSE = np.sqrt(mean_squared_error(train_pred[\"id\"].replace(y_hat_med), train[\"y\"]))\n",
    "    print(\"Pruning {0} RMSE: {1}\".format(count, new_RMSE))\n",
    "\n",
    "    if (abs(new_RMSE - RMSE) > best_parameters[\"gain_threshold\"][0]):\n",
    "        RMSE = new_RMSE\n",
    "    else:\n",
    "        RMSE_decreasing = False\n",
    "        \n",
    "# Bagging of RNN\n",
    "\n",
    "# Bootstrap 1\n",
    "train_1 = train\n",
    "model_dnn_1 = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                            hidden_units=[best_parameters[\"nb_neurons_1\"][0]])\n",
    "model_dnn_1.fit(input_fn=lambda: input_fn(train_1), steps=best_parameters[\"steps\"][0])\n",
    "\n",
    "# Bootstrap 2\n",
    "train_2 = resample(train, random_state=random_seed).sort_values(by=[\"id\"]).reset_index(drop=True)\n",
    "model_dnn_2 = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                            hidden_units=[best_parameters[\"nb_neurons_1\"][0]])\n",
    "model_dnn_2.fit(input_fn=lambda: input_fn(train_2), steps=best_parameters[\"steps\"][0])\n",
    "\n",
    "# Bootstrap 3\n",
    "train_3 = resample(train, random_state=(random_seed+1)).sort_values(by=[\"id\"]).reset_index(drop=True)\n",
    "model_dnn_3 = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                            hidden_units=[best_parameters[\"nb_neurons_1\"][0]])\n",
    "model_dnn_3.fit(input_fn=lambda: input_fn(train_3), steps=best_parameters[\"steps\"][0])\n",
    "\n",
    "# Bootstrap 4\n",
    "train_4 = resample(train, random_state=random_seed+2).sort_values(by=[\"id\"]).reset_index(drop=True)\n",
    "model_dnn_4 = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                            hidden_units=[best_parameters[\"nb_neurons_1\"][0]])\n",
    "model_dnn_4.fit(input_fn=lambda: input_fn(train_4), steps=best_parameters[\"steps\"][0])\n",
    "\n",
    "# Bootstrap 5\n",
    "train_5 = resample(train, random_state=random_seed+3).sort_values(by=[\"id\"]).reset_index(drop=True)\n",
    "model_dnn_5 = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                            hidden_units=[best_parameters[\"nb_neurons_1\"][0]])\n",
    "model_dnn_5.fit(input_fn=lambda: input_fn(train_5), steps=best_parameters[\"steps\"][0])\n",
    "    \n",
    "models = {\"dnn_1\": model_dnn_1, \"dnn_2\": model_dnn_2, \"dnn_3\": model_dnn_3,\n",
    "          \"dnn_4\": model_dnn_4, \"dnn_5\": model_dnn_5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_pred = test[[\"id\"]].assign(y_hat=0).reset_index(drop=True)\n",
    "for i, m in models.items():\n",
    "    temp = m.predict(input_fn=lambda: input_fn(test))\n",
    "    # .predict() returns an iterator; convert to an array\n",
    "    y_hat = np.array(list(itertools.islice(temp, 0, None)))\n",
    "    test_pred[\"y_hat\"] += models_weights[i] * y_hat\n",
    "\n",
    "# Use median value by id\n",
    "y_hat_med = test_pred.groupby(\"id\").median()[\"y_hat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#RMSE = np.sqrt(mean_squared_error(test_pred[\"id\"].replace(y_hat_med).values, test[\"y\"]))\n",
    "#RMSE\n",
    "#0.65725435012348465 for Pred 4\n",
    "#0.65362864377856866 for Pred 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "kaggle_pred = pd.DataFrame({\"Id\": y_hat_med.index, \"y\": y_hat_med.values})\n",
    "kaggle_pred.to_csv(\"Prediction_5.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Benchmark:\n",
    "* Submit 1 (ensemble of xgboost + 2 ridge with instances model)\n",
    "eta\teval_metric\tgamma\tlambda\tmax_depth\tmin_child_weight\tnthread\tobjective\tseed\tsilent\tsubsample\tscore\n",
    "0.91834 Public LB 300 trees 0.09\trmse\t0.2\t0.8\t4\t4.0\t-1\treg:linear\t22\t0\t0.7\t0.883339 (cross-val)\n",
    "    \n",
    "* Submit 2\n",
    "\n",
    "Pruning with linear regression\n",
    "then add contributions of aggregated xgboost + linear model\n",
    "\n",
    "0.78181 Public LB  0.779345 CV\n",
    "\n",
    "* Submit 3\n",
    "DNN pruning\n",
    "(wrong CV)\n",
    "0.73270 Public LB 0.663128 CV with DNN 10 neurons 900 steps gain_threshold = 0.01 outliers_threshold = 0.05\n",
    "\n",
    "* Prediction 4\n",
    "Ensemble of 5 DNN\n",
    "{'gain_threshold': 0.015, 'steps': 3800, 'nb_neurons_1': 10, 'outliers_threshold': 0.05} CV 0.701658836521\n",
    "using fist pruning DNN\n",
    "* Prediction 5\n",
    "Ensemble of 5 DNN\n",
    "{'gain_threshold': 0.01, 'steps': 2400, 'nb_neurons_1': 10, 'outliers_threshold': 0.05} CV 0.707300896236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Dropout\n",
    "Regression\n",
    "Validation set instead of cross val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
