{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from hyperopt import STATUS_OK, hp, fmin, tpe, Trials, space_eval\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "*Prediction 9: RMSE-validation: 0.72545.\n",
    "Optimal theta: 16, lambda: 1.1921e-07 Public LB: 0.67536 base_kp.^[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "def load_data():\n",
    "    full_data = pd.read_csv(\"X.csv\")\n",
    "    train_y = pd.read_csv(\"ytr.csv\")\n",
    "    # Rename columns to something more interpretable\n",
    "    columns = ([\"reflectance_\" + str(i) for i in range(7)]\n",
    "               + [\"solar_\" + str(i) for i in range(5)] + [\"id\"])\n",
    "    full_data.columns = columns\n",
    "    \n",
    "    # Move ID column to the beginning\n",
    "    id_column = full_data[\"id\"]\n",
    "    full_data.drop(labels=[\"id\"], axis=1, inplace = True)\n",
    "    full_data.insert(0, \"id\", id_column)\n",
    "    # Add y to the data frame\n",
    "    split = 98000\n",
    "    y_id_dict = train_y.set_index(\"Id\")[\"y\"].to_dict()\n",
    "    full_data.loc[:(split-1), \"y\"] = full_data.loc[:(split-1), \"id\"].map(y_id_dict)\n",
    "\n",
    "    train, test = full_data[:split], full_data[split:]\n",
    "    return (train, test)\n",
    "\n",
    "\n",
    "train, test = load_data()\n",
    "\n",
    "# Parameters\n",
    "n_threads = -1\n",
    "random_seed = 8888"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cols_excl = [\"id\", \"y\"]\n",
    "cols_orig = [c for c in train.columns if c not in cols_excl]\n",
    "\n",
    "# Standardise data for LR\n",
    "train[cols_orig] = scale(train[cols_orig])\n",
    "test[cols_orig] = scale(test[cols_orig])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Data generation for MATLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#full_data = full_data.fillna(0)\n",
    "\n",
    "#cols_excl = [\"id\", \"y\"]\n",
    "#cols_orig = [c for c in full_data.columns if c not in cols_excl]\n",
    "\n",
    "# Standardise data for LR\n",
    "#full_data[cols_orig] = scale(full_data[cols_orig])\n",
    "\n",
    "# I did standardise the data\n",
    "#full_data.to_csv(\"aerosol_full.csv\", encoding=\"utf-8\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Python mean embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# don't run\n",
    "def mean_embedding(X1, X2, kernel):\n",
    "    k = Kernel(kernel)\n",
    "    gram_mat = k.gram_matrix2(X1, X2)\n",
    "    # Number of instances in the bag\n",
    "    N = float(gram_mat.shape[0])\n",
    "    mu_X1_X2 = gram_mat.ravel().sum() / N**2\n",
    "    return (mu_X1_X2)\n",
    "\n",
    "nb_bag = 200#train[\"id\"].nunique()\n",
    "K_matrix = np.zeros((nb_bag, nb_bag))\n",
    "\n",
    "theta = 10**(-8)\n",
    "for i in range(nb_bag):\n",
    "    for j in range(nb_bag):\n",
    "        # Compute mean embedding\n",
    "        X1 = train.loc[train[\"id\"] == (i+1), cols_orig].values\n",
    "        X2 = train.loc[train[\"id\"] == (j+1), cols_orig].values\n",
    "        \n",
    "        K_matrix[i, j] = mean_embedding(X1, X2, {'name': 'invmquadr','c': theta})\n",
    "\n",
    "y_train = train[\"y\"].unique()[:200].reshape((-1, 1))\n",
    "l2_reg = 10**(-8)\n",
    "\n",
    "y_hat = []\n",
    "test_id_list = np.arange(980, 1100, dtype=int)\n",
    "\n",
    "for test_id in test_id_list:\n",
    "    K_test = np.zeros((1, nb_bag))\n",
    "\n",
    "    for j in range(nb_bag):\n",
    "        X1 = train.loc[train[\"id\"] == (j+1), cols_orig].values\n",
    "        X2 = test.loc[test[\"id\"] == test_id, cols_orig].values\n",
    "        K_test[0, j] = mean_embedding(X1, X2, {'name': 'invmquadr','c': theta})\n",
    "\n",
    "    # Ridge regression\n",
    "    ridge_mat = K_matrix + (l2_reg * nb_bag) * np.identity(nb_bag)\n",
    "    ridge_mat_inv = np.linalg.solve(ridge_mat, np.identity(nb_bag))\n",
    "    y_hat.append((K_test.dot(ridge_mat_inv)).dot(y_train)[0, 0])\n",
    "\n",
    "y_hat = np.array(y_hat)\n",
    "\n",
    "np.sqrt(mean_squared_error(y_hat, test[\"y\"].unique()[:120]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Class for ridge regression\n",
    "class RidgeRegression(object):\n",
    "    def __init__(self, l2_reg):\n",
    "        self.l2_reg = l2_reg\n",
    "\n",
    "    def fit(self, G, y):\n",
    "        # Train size\n",
    "        L_train = G.shape[0]\n",
    "        # Add the validation set later\n",
    "        ridge_mat = G + (self.l2_reg * L_train) * np.identity(L_train)\n",
    "        self.ridge_mat = ridge_mat\n",
    "        # Shape of y_train is (1, L_train)\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, G_test):\n",
    "        y_test_hat = self.y_train.dot(np.linalg.solve(self.ridge_mat, G_test))\n",
    "        return y_test_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Root mean squared error metric\n",
    "def RMSE(y, y_hat):\n",
    "    out = np.sqrt(mean_squared_error(y.reshape((-1,)), y_hat.reshape((-1,))))\n",
    "    return (out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_seed = 8\n",
    "n_folds = 5 # set folds for out-of-fold prediction\n",
    "# In KFold, random_state will only be used if shuffle is set to True\n",
    "kf = KFold(n_splits=n_folds, shuffle=False, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-of-fold predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# G_train and G_test are pandas dataframes\n",
    "# lr is a ridge regression\n",
    "def oof_prediction(lr, G_train, y_train, G_test):\n",
    "    n_train = G_train.shape[0]\n",
    "    n_test = G_test.shape[1]\n",
    "    oof_train = np.zeros((n_train,))\n",
    "    oof_test = np.zeros((n_test,))\n",
    "    oof_test_folds = np.zeros((n_folds, n_test))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(G_train)):\n",
    "        G_tr = G_train.loc[train_index, train_index].values\n",
    "        y_tr = y_train[train_index].reshape((1, -1))\n",
    "        G_te = G_train.loc[train_index, test_index].values\n",
    "\n",
    "        lr.fit(G_tr, y_tr)\n",
    "        oof_train[test_index] = lr.predict(G_te)\n",
    "        G_test_partial = G_test.loc[train_index, :]\n",
    "        oof_test_folds[i, :] = lr.predict(G_test_partial.values)\n",
    "\n",
    "    oof_test = oof_test_folds.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First base predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Cauchy__: theta: 16, lambda: 2**(-23)\n",
    "* __Matern3/2__: theta: 512, lambda: 2**(-33)\n",
    "* __Matern5/2__: theta: 64, lambda: 2**(-31)\n",
    "* __Rational quadratic__: theta: 512, lambda: 2**(-26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_bags_train = 980\n",
    "# Create a vector with the unique values of y for each ID.\n",
    "y_train = train.groupby(\"id\")[\"y\"].median().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_gram(csv_file, nb_bags_train):\n",
    "    # Import data\n",
    "    G = pd.read_csv(csv_file, header=None)\n",
    "    idx_train = nb_bags_train - 1\n",
    "    idx_test = nb_bags_train\n",
    "    G_train = G.loc[:idx_train, :idx_train]\n",
    "    G_test = G.loc[:idx_train, idx_test:]\n",
    "    return (G_train, G_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define models and import Gram matrices\n",
    "# Cauchy\n",
    "l2_reg_cauchy = 2**(-23)\n",
    "cauchy = RidgeRegression(l2_reg_cauchy)\n",
    "G_train_cauchy, G_test_cauchy = load_gram(\"Cauchy_16.csv\", nb_bags_train)\n",
    "\n",
    "# Matern 3/2 -> removed as it gave inferior results\n",
    "#l2_reg_matern_32 = 2**(-37)\n",
    "#matern_32 = RidgeRegression(l2_reg_matern_32)\n",
    "#G_train_matern_32, G_test_matern_32 = load_gram(\"Matern_32_1024.csv\", nb_bags_train)\n",
    "\n",
    "# Matern 5/2\n",
    "l2_reg_matern_52 = 2**(-36) # to change + csv name\n",
    "matern_52 = RidgeRegression(l2_reg_matern_52)\n",
    "G_train_matern_52, G_test_matern_52 = load_gram(\"Matern_52_128.csv\", nb_bags_train)\n",
    "\n",
    "# Rational quadratic\n",
    "l2_reg_rquadr = 2**(-28) # to change + csv name\n",
    "rquadr = RidgeRegression(l2_reg_rquadr)\n",
    "G_train_rquadr, G_test_rquadr = load_gram(\"rquadr_1024.csv\", nb_bags_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is finished.\n"
     ]
    }
   ],
   "source": [
    "# Create our OOF train and test predictions. These base results will be used as new features.\n",
    "# Cauchy\n",
    "cauchy_oof_train, cauchy_oof_test = oof_prediction(cauchy, G_train_cauchy, \n",
    "                                                   y_train, G_test_cauchy)\n",
    "# Matern 3/2\n",
    "#matern_32_oof_train, matern_32_oof_test = oof_prediction(matern_32, G_train_matern_32, \n",
    " #                                                        y_train, G_test_matern_32)\n",
    "# Matern 5/2\n",
    "matern_52_oof_train, matern_52_oof_test = oof_prediction(matern_52, G_train_matern_52, \n",
    "                                                         y_train, G_test_matern_52)\n",
    "# Rational quadratic\n",
    "rquadr_oof_train, rquadr_oof_test = oof_prediction(rquadr, G_train_rquadr, \n",
    "                                                   y_train, G_test_rquadr)\n",
    "print(\"Training is finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67685885815701352"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE(cauchy_oof_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#RMSE(matern_32_oof_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68275251697962624"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE(matern_52_oof_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67635136601886747"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE(rquadr_oof_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second level prediction with DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cauchy</th>\n",
       "      <th>matern_52</th>\n",
       "      <th>rquadr</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.607706</td>\n",
       "      <td>-3.492275</td>\n",
       "      <td>-3.534167</td>\n",
       "      <td>-3.998082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.315562</td>\n",
       "      <td>-4.342068</td>\n",
       "      <td>-4.355062</td>\n",
       "      <td>-4.137141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.688123</td>\n",
       "      <td>-2.675943</td>\n",
       "      <td>-2.657661</td>\n",
       "      <td>-2.694732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.377650</td>\n",
       "      <td>-3.449581</td>\n",
       "      <td>-3.443466</td>\n",
       "      <td>-3.296275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.717942</td>\n",
       "      <td>-3.701184</td>\n",
       "      <td>-3.693895</td>\n",
       "      <td>-3.181391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cauchy  matern_52    rquadr         y\n",
       "0 -3.607706  -3.492275 -3.534167 -3.998082\n",
       "1 -4.315562  -4.342068 -4.355062 -4.137141\n",
       "2 -2.688123  -2.675943 -2.657661 -2.694732\n",
       "3 -3.377650  -3.449581 -3.443466 -3.296275\n",
       "4 -3.717942  -3.701184 -3.693895 -3.181391"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_train = pd.DataFrame({'cauchy': cauchy_oof_train.ravel(),\n",
    "                             #'matern_32': matern_32_oof_train.ravel(),\n",
    "                             'matern_52': matern_52_oof_train.ravel(),\n",
    "                             'rquadr': rquadr_oof_train.ravel()})\n",
    "\n",
    "kernel_train[\"y\"] = y_train\n",
    "\n",
    "kernel_test = pd.DataFrame({'cauchy': cauchy_oof_test.ravel(),\n",
    "                            #'matern_32': matern_32_oof_test.ravel(),\n",
    "                            'matern_52': matern_52_oof_test.ravel(),\n",
    "                            'rquadr': rquadr_oof_test.ravel()})\n",
    "\n",
    "cols_excl_kernel = [\"y\"]\n",
    "cols_kernel = [c for c in kernel_train.columns if c not in cols_excl_kernel]\n",
    "\n",
    "kernel_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10eccb790>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcoAAAFoCAYAAADXSLs5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4ANBCQCADwQlAAA+/C8B2jsxzmVopwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10eaa2e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check predictions correlation\n",
    "corr_matrix = kernel_train.corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, linewidths=0.2, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation for MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scoring_function(parameters):\n",
    "    print(\"Training the model with parameters: \")\n",
    "    print(parameters)\n",
    "    average_RMSE = 0.0\n",
    "    n_splits = 5\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    nb_fold = 0\n",
    "    for train_index, validation_index in kf.split(kernel_train):\n",
    "        nb_fold += 1\n",
    "        train_fold, validation_fold = kernel_train.loc[train_index], kernel_train.loc[validation_index]\n",
    "\n",
    "        #MPL Regressor\n",
    "        model_dnn = MLPRegressor(hidden_layer_sizes=(parameters[\"nb_neurons\"],),\n",
    "                                 max_iter=parameters[\"steps\"],\n",
    "                                 alpha=parameters[\"MLP_l2_reg\"],\n",
    "                                 early_stopping=True,\n",
    "                                 random_state=random_seed)\n",
    "        model_dnn.fit(train_fold[cols_kernel], train_fold[\"y\"])\n",
    "        y_hat_train = model_dnn.predict(train_fold[cols_kernel])\n",
    "\n",
    "        RMSE_train = RMSE(y_hat_train, train_fold[\"y\"].values)\n",
    "        print(\"Training RMSE: {0}\".format(RMSE_train))\n",
    "\n",
    "        y_hat_test = model_dnn.predict(validation_fold[cols_kernel])\n",
    "\n",
    "        RMSE_test = RMSE(y_hat_test, validation_fold[\"y\"].values)\n",
    "        \n",
    "        average_RMSE += RMSE_test\n",
    "        print(\"Validation fold {0} RMSE: {1}\".format(nb_fold, RMSE_test))\n",
    "\n",
    "    average_RMSE /= n_splits\n",
    "\n",
    "    print(\"Cross-validation score: {0}\\n\".format(average_RMSE))\n",
    "    \n",
    "    return {\"loss\": average_RMSE, \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model with parameters: \n",
      "{'MLP_l2_reg': 0.00390625, 'steps': 1000, 'nb_neurons': 10}\n",
      "Training RMSE: 0.686387403693\n",
      "Validation fold 1 RMSE: 0.627589188736\n",
      "Training RMSE: 0.673979872265\n",
      "Validation fold 2 RMSE: 0.663013328256\n",
      "Training RMSE: 0.66515817709\n",
      "Validation fold 3 RMSE: 0.705848993376\n",
      "Training RMSE: 0.689029997789\n",
      "Validation fold 4 RMSE: 0.646774949387\n",
      "Training RMSE: 0.665400716024\n",
      "Validation fold 5 RMSE: 0.735286281633\n",
      "Cross-validation score: 0.675702548278\n",
      "\n",
      "Training the model with parameters: \n",
      "{'MLP_l2_reg': 0.001953125, 'steps': 1000, 'nb_neurons': 10}\n",
      "Training RMSE: 0.686015866456\n",
      "Validation fold 1 RMSE: 0.625964692048\n",
      "Training RMSE: 0.674055077929\n",
      "Validation fold 2 RMSE: 0.663578805735\n",
      "Training RMSE: 0.665150978438\n",
      "Validation fold 3 RMSE: 0.705870709249\n",
      "Training RMSE: 0.689053761664\n",
      "Validation fold 4 RMSE: 0.646775790196\n",
      "Training RMSE: 0.667385288618\n",
      "Validation fold 5 RMSE: 0.736884682983\n",
      "Cross-validation score: 0.675814936042\n",
      "\n",
      "Training the model with parameters: \n",
      "{'MLP_l2_reg': 0.001953125, 'steps': 1000, 'nb_neurons': 10}\n",
      "Training RMSE: 0.686015866456\n",
      "Validation fold 1 RMSE: 0.625964692048\n",
      "Training RMSE: 0.674055077929\n",
      "Validation fold 2 RMSE: 0.663578805735\n",
      "Training RMSE: 0.665150978438\n",
      "Validation fold 3 RMSE: 0.705870709249\n",
      "Training RMSE: 0.689053761664\n",
      "Validation fold 4 RMSE: 0.646775790196\n",
      "Training RMSE: 0.667385288618\n",
      "Validation fold 5 RMSE: 0.736884682983\n",
      "Cross-validation score: 0.675814936042\n",
      "\n",
      "Training the model with parameters: \n",
      "{'MLP_l2_reg': 0.0078125, 'steps': 1000, 'nb_neurons': 10}\n",
      "Training RMSE: 0.685729066792\n",
      "Validation fold 1 RMSE: 0.62612219687\n",
      "Training RMSE: 0.674771409568\n",
      "Validation fold 2 RMSE: 0.662895532253\n",
      "Training RMSE: 0.664522979505\n",
      "Validation fold 3 RMSE: 0.70522919445\n",
      "Training RMSE: 0.689064761126\n",
      "Validation fold 4 RMSE: 0.646808710986\n",
      "Training RMSE: 0.665382221757\n",
      "Validation fold 5 RMSE: 0.735238572947\n",
      "Cross-validation score: 0.675258841501\n",
      "\n",
      "Training the model with parameters: \n",
      "{'MLP_l2_reg': 0.00390625, 'steps': 1000, 'nb_neurons': 10}\n",
      "Training RMSE: 0.686387403693\n",
      "Validation fold 1 RMSE: 0.627589188736\n",
      "Training RMSE: 0.673979872265\n",
      "Validation fold 2 RMSE: 0.663013328256\n",
      "Training RMSE: 0.66515817709\n",
      "Validation fold 3 RMSE: 0.705848993376\n",
      "Training RMSE: 0.689029997789\n",
      "Validation fold 4 RMSE: 0.646774949387\n",
      "Training RMSE: 0.665400716024\n",
      "Validation fold 5 RMSE: 0.735286281633\n",
      "Cross-validation score: 0.675702548278\n",
      "\n",
      "Training the model with parameters: \n",
      "{'MLP_l2_reg': 0.00390625, 'steps': 1000, 'nb_neurons': 10}\n",
      "Training RMSE: 0.686387403693\n",
      "Validation fold 1 RMSE: 0.627589188736\n",
      "Training RMSE: 0.673979872265\n",
      "Validation fold 2 RMSE: 0.663013328256\n",
      "Training RMSE: 0.66515817709\n",
      "Validation fold 3 RMSE: 0.705848993376\n",
      "Training RMSE: 0.689029997789\n",
      "Validation fold 4 RMSE: 0.646774949387\n",
      "Training RMSE: 0.665400716024\n",
      "Validation fold 5 RMSE: 0.735286281633\n",
      "Cross-validation score: 0.675702548278\n",
      "\n",
      "Training the model with parameters: \n",
      "{'MLP_l2_reg': 0.015625, 'steps': 1000, 'nb_neurons': 10}\n",
      "Training RMSE: 0.686183849637\n",
      "Validation fold 1 RMSE: 0.627294732421\n",
      "Training RMSE: 0.675276041775\n",
      "Validation fold 2 RMSE: 0.664114644921\n",
      "Training RMSE: 0.665047036173\n",
      "Validation fold 3 RMSE: 0.705793361854\n",
      "Training RMSE: 0.688960965722\n",
      "Validation fold 4 RMSE: 0.646747302594\n",
      "Training RMSE: 0.660887577147\n",
      "Validation fold 5 RMSE: 0.726698868003\n",
      "Cross-validation score: 0.674129781958\n",
      "\n",
      "Training the model with parameters: \n",
      "{'MLP_l2_reg': 0.001953125, 'steps': 1000, 'nb_neurons': 10}\n",
      "Training RMSE: 0.686015866456\n",
      "Validation fold 1 RMSE: 0.625964692048\n",
      "Training RMSE: 0.674055077929\n",
      "Validation fold 2 RMSE: 0.663578805735\n",
      "Training RMSE: 0.665150978438\n",
      "Validation fold 3 RMSE: 0.705870709249\n",
      "Training RMSE: 0.689053761664\n",
      "Validation fold 4 RMSE: 0.646775790196\n",
      "Training RMSE: 0.667385288618\n",
      "Validation fold 5 RMSE: 0.736884682983\n",
      "Cross-validation score: 0.675814936042\n",
      "\n",
      "Training the model with parameters: \n",
      "{'MLP_l2_reg': 0.0078125, 'steps': 1000, 'nb_neurons': 10}\n",
      "Training RMSE: 0.685729066792\n",
      "Validation fold 1 RMSE: 0.62612219687\n",
      "Training RMSE: 0.674771409568\n",
      "Validation fold 2 RMSE: 0.662895532253\n",
      "Training RMSE: 0.664522979505\n",
      "Validation fold 3 RMSE: 0.70522919445\n",
      "Training RMSE: 0.689064761126\n",
      "Validation fold 4 RMSE: 0.646808710986\n",
      "Training RMSE: 0.665382221757\n",
      "Validation fold 5 RMSE: 0.735238572947\n",
      "Cross-validation score: 0.675258841501\n",
      "\n",
      "Training the model with parameters: \n",
      "{'MLP_l2_reg': 0.001953125, 'steps': 1000, 'nb_neurons': 10}\n",
      "Training RMSE: 0.686015866456\n",
      "Validation fold 1 RMSE: 0.625964692048\n",
      "Training RMSE: 0.674055077929\n",
      "Validation fold 2 RMSE: 0.663578805735\n",
      "Training RMSE: 0.665150978438\n",
      "Validation fold 3 RMSE: 0.705870709249\n",
      "Training RMSE: 0.689053761664\n",
      "Validation fold 4 RMSE: 0.646775790196\n",
      "Training RMSE: 0.667385288618\n",
      "Validation fold 5 RMSE: 0.736884682983\n",
      "Cross-validation score: 0.675814936042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grid to pick parameters from.\n",
    "parameters_grid = {\"steps\"             : hp.choice(\"steps\", np.arange(1000, 1100, 100, dtype=int)),\n",
    "                   \"nb_neurons\"      : hp.choice(\"nb_neurons\", np.arange(10, 11, 1, dtype=int)),\n",
    "                   \"MLP_l2_reg\": hp.choice(\"MLP_l2_reg\", np.power(2.0, np.arange(-9, -5)))\n",
    "                  }\n",
    "# Record the information about the cross-validation.\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(scoring_function, parameters_grid, algo=tpe.suggest, max_evals=10, \n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6739617355611843"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(trials.losses())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLP_l2_reg</th>\n",
       "      <th>nb_neurons</th>\n",
       "      <th>steps</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00941</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.673803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MLP_l2_reg  nb_neurons  steps     score\n",
       "0     0.00941          10   1000  0.673803"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the best parameters as a csv.\n",
    "best_parameters = pd.DataFrame({key: [value] for (key, value) in \n",
    "                                zip(space_eval(parameters_grid, best).keys(),\n",
    "                                    space_eval(parameters_grid, best).values())})\n",
    "# Add the corresponding score.\n",
    "best_parameters[\"score\"] = min(trials.losses())\n",
    "best_parameters.to_csv(\"best_parameters_10.csv\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.00941, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=10, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=8, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MPL Regressor\n",
    "best_parameters = pd.read_csv(\"best_parameters_10.csv\", encoding=\"utf-8\")\n",
    "\n",
    "model_dnn = MLPRegressor(hidden_layer_sizes=(best_parameters[\"nb_neurons\"][0]),\n",
    "                         max_iter=best_parameters[\"steps\"][0],\n",
    "                         alpha=best_parameters[\"MLP_l2_reg\"][0],\n",
    "                         early_stopping=True,\n",
    "                         random_state=random_seed)\n",
    "model_dnn.fit(kernel_train[cols_kernel], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67428005689905501"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training error\n",
    "RMSE(model_dnn.predict(kernel_train[cols_kernel]), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_hat_test = model_dnn.predict(kernel_test[cols_kernel])\n",
    "\n",
    "test_pred = test.groupby(\"id\")[[\"y\"]].mean().reset_index()\n",
    "test_pred[\"y\"] = y_hat_test\n",
    "test_pred.columns = [\"Id\", \"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save as a .csv\n",
    "test_pred.to_csv(\"Prediction_10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
