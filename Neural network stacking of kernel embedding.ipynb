{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from numpy import exp, sqrt, dot\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from hyperopt import STATUS_OK, hp, fmin, tpe, Trials, space_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    full_data = pd.read_csv(\"Data/X.csv\")\n",
    "    train_y = pd.read_csv(\"Data/y_train.csv\")\n",
    "    # Rename columns to something more interpretable\n",
    "    columns = ([\"reflectance_\" + str(i) for i in range(7)]\n",
    "               + [\"solar_\" + str(i) for i in range(5)] + [\"id\"])\n",
    "    full_data.columns = columns\n",
    "    \n",
    "    # Move ID column to the beginning\n",
    "    id_column = full_data[\"id\"]\n",
    "    full_data.drop(labels=[\"id\"], axis=1, inplace = True)\n",
    "    full_data.insert(0, \"id\", id_column)\n",
    "    \n",
    "    # Add the target value column to the training part\n",
    "    # in full_data\n",
    "    split = 98000\n",
    "    y_id_dict = train_y.set_index(\"id\")[\"y\"].to_dict()\n",
    "    full_data.loc[:(split-1), \"y\"] = full_data.loc[:(split-1), \"id\"].map(y_id_dict)\n",
    "    \n",
    "    # Split into training and testing data\n",
    "    train, test = full_data[:split], full_data[split:]\n",
    "    return (train, test)\n",
    "\n",
    "train, test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "random_seed = 9\n",
    "# Set folds for out-of-fold prediction\n",
    "n_folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cols_excl = [\"id\", \"y\"]\n",
    "cols_orig = [c for c in train.columns if c not in cols_excl]\n",
    "\n",
    "# Standardise data\n",
    "train[cols_orig] = scale(train[cols_orig])\n",
    "test[cols_orig] = scale(test[cols_orig])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Data generation for MATLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#full_data = full_data.fillna(0)\n",
    "\n",
    "#cols_excl = [\"id\", \"y\"]\n",
    "#cols_orig = [c for c in full_data.columns if c not in cols_excl]\n",
    "\n",
    "# Standardise data for LR\n",
    "#full_data[cols_orig] = scale(full_data[cols_orig])\n",
    "\n",
    "# I did standardise the data\n",
    "#full_data.to_csv(\"aerosol_full.csv\", encoding=\"utf-8\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Python mean embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Kernel(object):\n",
    "    \"\"\" Kernel class from Zoltan Szabo\"\"\"\n",
    "\n",
    "    def __init__(self, par=None):\n",
    "        \"\"\" Initialization.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        par : dictionary, optional\n",
    "              Name of the kernel and its parameters (default is\n",
    "              {\"name\": \"RBF\", \"sigma\": 1}). The name of the kernel comes\n",
    "              from \"RBF\", \"exponential\", \"Cauchy\", \"student\", \"Matern3p2\",\n",
    "              \"Matern5p2\", \"polynomial\", \"ratquadr\" (rational quadratic),\n",
    "              \"invmquadr\" (inverse multiquadr).\n",
    "        \"\"\"\n",
    "        if par is None:\n",
    "            par = {\"name\": \"RBF\", \"sigma\": 1}\n",
    "\n",
    "        name = par[\"name\"]\n",
    "        self.name = name\n",
    "\n",
    "        # other attributes:\n",
    "        if name == \"RBF\" or name == \"exponential\" or name == \"Cauchy\":\n",
    "            self.sigma = par[\"sigma\"]\n",
    "        elif name == \"student\":\n",
    "            self.d = par[\"d\"]\n",
    "        elif name == \"Matern3p2\" or name == \"Matern5p2\":\n",
    "            self.l = par[\"l\"]\n",
    "        elif name == \"polynomial\":\n",
    "            self.c = par[\"c\"]\n",
    "            self.exponent = par[\"exponent\"]\n",
    "        elif name == \"ratquadr\" or name == \"invmquadr\":\n",
    "            self.c = par[\"c\"]\n",
    "        else:\n",
    "            raise Exception(\"kernel=?\")\n",
    "\n",
    "    def gram_matrix(self, y1, y2):\n",
    "        \"\"\"  Compute the Gram matrix = [k(y1[i,:], y2[j,:])]; i, j: running.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y1 : (number of samples1, dimension)-ndarray\n",
    "             One row of y1 corresponds to one sample.\n",
    "        y2 : (number of samples2, dimension)-ndarray\n",
    "             One row of y2 corresponds to one sample.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        g : ndarray.\n",
    "            Gram matrix of y1 and y2.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.name == \"RBF\":\n",
    "            sigma = self.sigma\n",
    "            g = cdist(y1, y2)\n",
    "            g = exp(-g ** 2 / (2 * sigma ** 2))\n",
    "        elif self.name == \"exponential\":\n",
    "            sigma = self.sigma\n",
    "            g = cdist(y1, y2)\n",
    "            g = exp(-g / (2 * sigma ** 2))\n",
    "        elif self.name == \"Cauchy\":\n",
    "            sigma = self.sigma\n",
    "            g = cdist(y1, y2)\n",
    "            g = 1 / (1 + g ** 2 / sigma ** 2)\n",
    "        elif self.name == \"student\":\n",
    "            d = self.d\n",
    "            g = cdist(y1, y2)\n",
    "            g = 1 / (1 + g ** d)\n",
    "        elif self.name == \"Matern3p2\":\n",
    "            l = self.l\n",
    "            g = cdist(y1, y2) \n",
    "            g = (1 + sqrt(3) * g / l) * exp(-sqrt(3) * g / l)\n",
    "        elif self.name == \"Matern5p2\":\n",
    "            l = self.l\n",
    "            g = cdist(y1, y2)\n",
    "            g = (1 + sqrt(5) * g / l + 5 * g ** 2 / (3 * l ** 2)) * \\\n",
    "                exp(-sqrt(5) * g / l)\n",
    "        elif self.name == \"polynomial\":\n",
    "            c = self.c\n",
    "            exponent = self.exponent\n",
    "            g = (dot(y1, y2.T) + c) ** exponent\n",
    "        elif self.name == \"ratquadr\":\n",
    "            c = self.c\n",
    "            g = cdist(y1, y2) ** 2\n",
    "            g = 1 - g / (g + c)\n",
    "        elif self.name == \"invmquadr\":\n",
    "            c = self.c\n",
    "            g = cdist(y1, y2)\n",
    "            g = 1 / sqrt(g ** 2 + c ** 2)\n",
    "        else:\n",
    "            raise Exception(\"kernel=?\")\n",
    "\n",
    "        return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def symmetrise(A):\n",
    "    return(A + A.T - np.diag(A.diagonal()))\n",
    "\n",
    "# Compute the linear kernel product of the mean embedding \n",
    "# of X1 and X2\n",
    "def mean_embedding(X1, X2, kernel):\n",
    "    k = Kernel(kernel)\n",
    "    gram_mat = k.gram_matrix(X1, X2)\n",
    "    # Number of instances in the bag\n",
    "    N = float(gram_mat.shape[0])\n",
    "    mu_X1_X2 = gram_mat.ravel().sum() / N**2\n",
    "    return (mu_X1_X2)\n",
    "\n",
    "# More than 25 minutes to compute\n",
    "def compute_gram(df, kernel, theta):\n",
    "    nb_bag = df[\"id\"].nunique()\n",
    "    K_matrix = np.zeros((nb_bag, nb_bag))\n",
    "    print(\"Computing {0} Gram matrix for theta={1}:\".format(kernel, theta))\n",
    "    for i in range(nb_bag):\n",
    "        if (i%50 == 0):\n",
    "            print(\"Bag number: {0}\". format(i))\n",
    "        \n",
    "        for j in range(i+1):\n",
    "            # Compute mean embedding\n",
    "            X1 = df.loc[train[\"id\"] == (i+1), cols_orig].values\n",
    "            X2 = df.loc[train[\"id\"] == (j+1), cols_orig].values\n",
    "\n",
    "            K_matrix[i, j] = mean_embedding(X1, X2, {'name': kernel, 'sigma': theta})\n",
    "            \n",
    "    return symmetrise(K_matrix)\n",
    "        \n",
    "K_cauchy = compute_gram(train, \"Cauchy\", 2**4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>970</th>\n",
       "      <th>971</th>\n",
       "      <th>972</th>\n",
       "      <th>973</th>\n",
       "      <th>974</th>\n",
       "      <th>975</th>\n",
       "      <th>976</th>\n",
       "      <th>977</th>\n",
       "      <th>978</th>\n",
       "      <th>979</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991154</td>\n",
       "      <td>0.955328</td>\n",
       "      <td>0.969529</td>\n",
       "      <td>0.973129</td>\n",
       "      <td>0.908920</td>\n",
       "      <td>0.886188</td>\n",
       "      <td>0.902115</td>\n",
       "      <td>0.971101</td>\n",
       "      <td>0.908059</td>\n",
       "      <td>0.878027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972241</td>\n",
       "      <td>0.927735</td>\n",
       "      <td>0.954305</td>\n",
       "      <td>0.843801</td>\n",
       "      <td>0.962973</td>\n",
       "      <td>0.922967</td>\n",
       "      <td>0.941377</td>\n",
       "      <td>0.924171</td>\n",
       "      <td>0.976959</td>\n",
       "      <td>0.940458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.955328</td>\n",
       "      <td>0.994694</td>\n",
       "      <td>0.962074</td>\n",
       "      <td>0.943584</td>\n",
       "      <td>0.958195</td>\n",
       "      <td>0.889848</td>\n",
       "      <td>0.914993</td>\n",
       "      <td>0.932280</td>\n",
       "      <td>0.959820</td>\n",
       "      <td>0.889961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938020</td>\n",
       "      <td>0.950168</td>\n",
       "      <td>0.927305</td>\n",
       "      <td>0.853174</td>\n",
       "      <td>0.940251</td>\n",
       "      <td>0.934127</td>\n",
       "      <td>0.947320</td>\n",
       "      <td>0.892866</td>\n",
       "      <td>0.959238</td>\n",
       "      <td>0.885163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.969529</td>\n",
       "      <td>0.962074</td>\n",
       "      <td>0.996145</td>\n",
       "      <td>0.966989</td>\n",
       "      <td>0.945786</td>\n",
       "      <td>0.903766</td>\n",
       "      <td>0.927357</td>\n",
       "      <td>0.942365</td>\n",
       "      <td>0.929251</td>\n",
       "      <td>0.898904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946472</td>\n",
       "      <td>0.933018</td>\n",
       "      <td>0.948638</td>\n",
       "      <td>0.863751</td>\n",
       "      <td>0.957597</td>\n",
       "      <td>0.935604</td>\n",
       "      <td>0.940549</td>\n",
       "      <td>0.928179</td>\n",
       "      <td>0.990887</td>\n",
       "      <td>0.890669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.973129</td>\n",
       "      <td>0.943584</td>\n",
       "      <td>0.966989</td>\n",
       "      <td>0.979929</td>\n",
       "      <td>0.891627</td>\n",
       "      <td>0.852030</td>\n",
       "      <td>0.873517</td>\n",
       "      <td>0.975832</td>\n",
       "      <td>0.881278</td>\n",
       "      <td>0.842075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952955</td>\n",
       "      <td>0.898075</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.806302</td>\n",
       "      <td>0.940919</td>\n",
       "      <td>0.898540</td>\n",
       "      <td>0.935617</td>\n",
       "      <td>0.900440</td>\n",
       "      <td>0.974549</td>\n",
       "      <td>0.932908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.908920</td>\n",
       "      <td>0.958195</td>\n",
       "      <td>0.945786</td>\n",
       "      <td>0.891627</td>\n",
       "      <td>0.995676</td>\n",
       "      <td>0.936040</td>\n",
       "      <td>0.948124</td>\n",
       "      <td>0.855386</td>\n",
       "      <td>0.977856</td>\n",
       "      <td>0.941444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905598</td>\n",
       "      <td>0.969282</td>\n",
       "      <td>0.920321</td>\n",
       "      <td>0.917565</td>\n",
       "      <td>0.928897</td>\n",
       "      <td>0.963797</td>\n",
       "      <td>0.934863</td>\n",
       "      <td>0.925191</td>\n",
       "      <td>0.938168</td>\n",
       "      <td>0.835651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.886188</td>\n",
       "      <td>0.889848</td>\n",
       "      <td>0.903766</td>\n",
       "      <td>0.852030</td>\n",
       "      <td>0.936040</td>\n",
       "      <td>0.960130</td>\n",
       "      <td>0.939654</td>\n",
       "      <td>0.824101</td>\n",
       "      <td>0.925268</td>\n",
       "      <td>0.954629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.911080</td>\n",
       "      <td>0.951053</td>\n",
       "      <td>0.924238</td>\n",
       "      <td>0.942606</td>\n",
       "      <td>0.930581</td>\n",
       "      <td>0.939656</td>\n",
       "      <td>0.871768</td>\n",
       "      <td>0.932048</td>\n",
       "      <td>0.908084</td>\n",
       "      <td>0.818047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.902115</td>\n",
       "      <td>0.914993</td>\n",
       "      <td>0.927357</td>\n",
       "      <td>0.873517</td>\n",
       "      <td>0.948124</td>\n",
       "      <td>0.939654</td>\n",
       "      <td>0.965021</td>\n",
       "      <td>0.838032</td>\n",
       "      <td>0.950094</td>\n",
       "      <td>0.963026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897594</td>\n",
       "      <td>0.936528</td>\n",
       "      <td>0.912866</td>\n",
       "      <td>0.932247</td>\n",
       "      <td>0.919966</td>\n",
       "      <td>0.915281</td>\n",
       "      <td>0.883521</td>\n",
       "      <td>0.913542</td>\n",
       "      <td>0.915810</td>\n",
       "      <td>0.809028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.971101</td>\n",
       "      <td>0.932280</td>\n",
       "      <td>0.942365</td>\n",
       "      <td>0.975832</td>\n",
       "      <td>0.855386</td>\n",
       "      <td>0.824101</td>\n",
       "      <td>0.838032</td>\n",
       "      <td>0.993016</td>\n",
       "      <td>0.852189</td>\n",
       "      <td>0.806896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957698</td>\n",
       "      <td>0.879065</td>\n",
       "      <td>0.916256</td>\n",
       "      <td>0.770735</td>\n",
       "      <td>0.932238</td>\n",
       "      <td>0.874546</td>\n",
       "      <td>0.916482</td>\n",
       "      <td>0.872618</td>\n",
       "      <td>0.958389</td>\n",
       "      <td>0.946369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.908059</td>\n",
       "      <td>0.959820</td>\n",
       "      <td>0.929251</td>\n",
       "      <td>0.881278</td>\n",
       "      <td>0.977856</td>\n",
       "      <td>0.925268</td>\n",
       "      <td>0.950094</td>\n",
       "      <td>0.852189</td>\n",
       "      <td>0.983049</td>\n",
       "      <td>0.942466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899163</td>\n",
       "      <td>0.959648</td>\n",
       "      <td>0.909830</td>\n",
       "      <td>0.911446</td>\n",
       "      <td>0.918235</td>\n",
       "      <td>0.936235</td>\n",
       "      <td>0.917106</td>\n",
       "      <td>0.898656</td>\n",
       "      <td>0.917874</td>\n",
       "      <td>0.824724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.878027</td>\n",
       "      <td>0.889961</td>\n",
       "      <td>0.898904</td>\n",
       "      <td>0.842075</td>\n",
       "      <td>0.941444</td>\n",
       "      <td>0.954629</td>\n",
       "      <td>0.963026</td>\n",
       "      <td>0.806896</td>\n",
       "      <td>0.942466</td>\n",
       "      <td>0.976619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888975</td>\n",
       "      <td>0.940674</td>\n",
       "      <td>0.905340</td>\n",
       "      <td>0.953461</td>\n",
       "      <td>0.912494</td>\n",
       "      <td>0.917370</td>\n",
       "      <td>0.865355</td>\n",
       "      <td>0.918008</td>\n",
       "      <td>0.892406</td>\n",
       "      <td>0.794167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.932913</td>\n",
       "      <td>0.930461</td>\n",
       "      <td>0.946364</td>\n",
       "      <td>0.902258</td>\n",
       "      <td>0.957704</td>\n",
       "      <td>0.968984</td>\n",
       "      <td>0.959153</td>\n",
       "      <td>0.877766</td>\n",
       "      <td>0.947985</td>\n",
       "      <td>0.964576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.953458</td>\n",
       "      <td>0.975262</td>\n",
       "      <td>0.954010</td>\n",
       "      <td>0.939409</td>\n",
       "      <td>0.967069</td>\n",
       "      <td>0.960547</td>\n",
       "      <td>0.910909</td>\n",
       "      <td>0.956006</td>\n",
       "      <td>0.950851</td>\n",
       "      <td>0.865514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.985865</td>\n",
       "      <td>0.946161</td>\n",
       "      <td>0.966077</td>\n",
       "      <td>0.977887</td>\n",
       "      <td>0.902707</td>\n",
       "      <td>0.880130</td>\n",
       "      <td>0.889276</td>\n",
       "      <td>0.976504</td>\n",
       "      <td>0.894367</td>\n",
       "      <td>0.866683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978629</td>\n",
       "      <td>0.926117</td>\n",
       "      <td>0.949582</td>\n",
       "      <td>0.832985</td>\n",
       "      <td>0.963914</td>\n",
       "      <td>0.923901</td>\n",
       "      <td>0.948800</td>\n",
       "      <td>0.930583</td>\n",
       "      <td>0.978419</td>\n",
       "      <td>0.960626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.976466</td>\n",
       "      <td>0.938235</td>\n",
       "      <td>0.954351</td>\n",
       "      <td>0.982315</td>\n",
       "      <td>0.873039</td>\n",
       "      <td>0.843893</td>\n",
       "      <td>0.853097</td>\n",
       "      <td>0.993157</td>\n",
       "      <td>0.863824</td>\n",
       "      <td>0.824574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970268</td>\n",
       "      <td>0.896412</td>\n",
       "      <td>0.930145</td>\n",
       "      <td>0.790311</td>\n",
       "      <td>0.947001</td>\n",
       "      <td>0.895346</td>\n",
       "      <td>0.929149</td>\n",
       "      <td>0.894889</td>\n",
       "      <td>0.972651</td>\n",
       "      <td>0.954359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.962246</td>\n",
       "      <td>0.904897</td>\n",
       "      <td>0.913526</td>\n",
       "      <td>0.951546</td>\n",
       "      <td>0.843031</td>\n",
       "      <td>0.840801</td>\n",
       "      <td>0.830964</td>\n",
       "      <td>0.974184</td>\n",
       "      <td>0.838208</td>\n",
       "      <td>0.814235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976820</td>\n",
       "      <td>0.893189</td>\n",
       "      <td>0.925773</td>\n",
       "      <td>0.786275</td>\n",
       "      <td>0.942489</td>\n",
       "      <td>0.889590</td>\n",
       "      <td>0.910069</td>\n",
       "      <td>0.895964</td>\n",
       "      <td>0.942437</td>\n",
       "      <td>0.974427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.953118</td>\n",
       "      <td>0.930633</td>\n",
       "      <td>0.915262</td>\n",
       "      <td>0.950245</td>\n",
       "      <td>0.863614</td>\n",
       "      <td>0.825328</td>\n",
       "      <td>0.818732</td>\n",
       "      <td>0.969987</td>\n",
       "      <td>0.854279</td>\n",
       "      <td>0.797013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956799</td>\n",
       "      <td>0.903798</td>\n",
       "      <td>0.913091</td>\n",
       "      <td>0.770728</td>\n",
       "      <td>0.928258</td>\n",
       "      <td>0.905931</td>\n",
       "      <td>0.936230</td>\n",
       "      <td>0.880593</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.975128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.869851</td>\n",
       "      <td>0.907701</td>\n",
       "      <td>0.911232</td>\n",
       "      <td>0.854549</td>\n",
       "      <td>0.975573</td>\n",
       "      <td>0.927261</td>\n",
       "      <td>0.921390</td>\n",
       "      <td>0.811331</td>\n",
       "      <td>0.939638</td>\n",
       "      <td>0.925209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875115</td>\n",
       "      <td>0.945929</td>\n",
       "      <td>0.898746</td>\n",
       "      <td>0.919700</td>\n",
       "      <td>0.901165</td>\n",
       "      <td>0.960022</td>\n",
       "      <td>0.912899</td>\n",
       "      <td>0.930269</td>\n",
       "      <td>0.910111</td>\n",
       "      <td>0.813374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.973693</td>\n",
       "      <td>0.932908</td>\n",
       "      <td>0.963640</td>\n",
       "      <td>0.974128</td>\n",
       "      <td>0.891768</td>\n",
       "      <td>0.858154</td>\n",
       "      <td>0.871551</td>\n",
       "      <td>0.967645</td>\n",
       "      <td>0.877283</td>\n",
       "      <td>0.844489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955329</td>\n",
       "      <td>0.904882</td>\n",
       "      <td>0.933772</td>\n",
       "      <td>0.810890</td>\n",
       "      <td>0.945955</td>\n",
       "      <td>0.911269</td>\n",
       "      <td>0.946471</td>\n",
       "      <td>0.919284</td>\n",
       "      <td>0.971792</td>\n",
       "      <td>0.952012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.958112</td>\n",
       "      <td>0.969233</td>\n",
       "      <td>0.946355</td>\n",
       "      <td>0.965931</td>\n",
       "      <td>0.903844</td>\n",
       "      <td>0.831681</td>\n",
       "      <td>0.850125</td>\n",
       "      <td>0.969318</td>\n",
       "      <td>0.895478</td>\n",
       "      <td>0.818786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939296</td>\n",
       "      <td>0.907093</td>\n",
       "      <td>0.908175</td>\n",
       "      <td>0.785366</td>\n",
       "      <td>0.923160</td>\n",
       "      <td>0.905411</td>\n",
       "      <td>0.954886</td>\n",
       "      <td>0.875754</td>\n",
       "      <td>0.955742</td>\n",
       "      <td>0.935618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.978273</td>\n",
       "      <td>0.941665</td>\n",
       "      <td>0.964612</td>\n",
       "      <td>0.980292</td>\n",
       "      <td>0.891069</td>\n",
       "      <td>0.857574</td>\n",
       "      <td>0.873291</td>\n",
       "      <td>0.978669</td>\n",
       "      <td>0.880638</td>\n",
       "      <td>0.844924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962732</td>\n",
       "      <td>0.905639</td>\n",
       "      <td>0.934241</td>\n",
       "      <td>0.809873</td>\n",
       "      <td>0.948394</td>\n",
       "      <td>0.906312</td>\n",
       "      <td>0.942056</td>\n",
       "      <td>0.911178</td>\n",
       "      <td>0.974880</td>\n",
       "      <td>0.949851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.963793</td>\n",
       "      <td>0.931491</td>\n",
       "      <td>0.957415</td>\n",
       "      <td>0.937322</td>\n",
       "      <td>0.936734</td>\n",
       "      <td>0.938309</td>\n",
       "      <td>0.929152</td>\n",
       "      <td>0.919387</td>\n",
       "      <td>0.922082</td>\n",
       "      <td>0.925405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973158</td>\n",
       "      <td>0.962376</td>\n",
       "      <td>0.964833</td>\n",
       "      <td>0.901677</td>\n",
       "      <td>0.974952</td>\n",
       "      <td>0.962683</td>\n",
       "      <td>0.943228</td>\n",
       "      <td>0.972053</td>\n",
       "      <td>0.967819</td>\n",
       "      <td>0.929746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.819522</td>\n",
       "      <td>0.842104</td>\n",
       "      <td>0.850309</td>\n",
       "      <td>0.787570</td>\n",
       "      <td>0.906177</td>\n",
       "      <td>0.916703</td>\n",
       "      <td>0.933910</td>\n",
       "      <td>0.747245</td>\n",
       "      <td>0.908218</td>\n",
       "      <td>0.948757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.825593</td>\n",
       "      <td>0.889156</td>\n",
       "      <td>0.851879</td>\n",
       "      <td>0.932591</td>\n",
       "      <td>0.854516</td>\n",
       "      <td>0.866418</td>\n",
       "      <td>0.812370</td>\n",
       "      <td>0.866340</td>\n",
       "      <td>0.839132</td>\n",
       "      <td>0.727434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.969448</td>\n",
       "      <td>0.926535</td>\n",
       "      <td>0.954228</td>\n",
       "      <td>0.976976</td>\n",
       "      <td>0.868070</td>\n",
       "      <td>0.832934</td>\n",
       "      <td>0.842737</td>\n",
       "      <td>0.981884</td>\n",
       "      <td>0.853538</td>\n",
       "      <td>0.812396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952219</td>\n",
       "      <td>0.885217</td>\n",
       "      <td>0.923585</td>\n",
       "      <td>0.779106</td>\n",
       "      <td>0.936728</td>\n",
       "      <td>0.893195</td>\n",
       "      <td>0.932541</td>\n",
       "      <td>0.894736</td>\n",
       "      <td>0.967744</td>\n",
       "      <td>0.952988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.829641</td>\n",
       "      <td>0.875146</td>\n",
       "      <td>0.856958</td>\n",
       "      <td>0.796473</td>\n",
       "      <td>0.949298</td>\n",
       "      <td>0.940855</td>\n",
       "      <td>0.935598</td>\n",
       "      <td>0.759703</td>\n",
       "      <td>0.943159</td>\n",
       "      <td>0.959162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851558</td>\n",
       "      <td>0.944906</td>\n",
       "      <td>0.868684</td>\n",
       "      <td>0.947326</td>\n",
       "      <td>0.876979</td>\n",
       "      <td>0.922021</td>\n",
       "      <td>0.853429</td>\n",
       "      <td>0.892596</td>\n",
       "      <td>0.853077</td>\n",
       "      <td>0.763078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.905424</td>\n",
       "      <td>0.946218</td>\n",
       "      <td>0.915197</td>\n",
       "      <td>0.870080</td>\n",
       "      <td>0.968741</td>\n",
       "      <td>0.949708</td>\n",
       "      <td>0.949722</td>\n",
       "      <td>0.848076</td>\n",
       "      <td>0.973892</td>\n",
       "      <td>0.955133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919768</td>\n",
       "      <td>0.979894</td>\n",
       "      <td>0.923351</td>\n",
       "      <td>0.931391</td>\n",
       "      <td>0.933795</td>\n",
       "      <td>0.951944</td>\n",
       "      <td>0.902796</td>\n",
       "      <td>0.911375</td>\n",
       "      <td>0.915018</td>\n",
       "      <td>0.832671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.923922</td>\n",
       "      <td>0.955135</td>\n",
       "      <td>0.927075</td>\n",
       "      <td>0.892074</td>\n",
       "      <td>0.968724</td>\n",
       "      <td>0.948902</td>\n",
       "      <td>0.944139</td>\n",
       "      <td>0.874161</td>\n",
       "      <td>0.969078</td>\n",
       "      <td>0.947950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.943798</td>\n",
       "      <td>0.989984</td>\n",
       "      <td>0.935475</td>\n",
       "      <td>0.922154</td>\n",
       "      <td>0.950399</td>\n",
       "      <td>0.964863</td>\n",
       "      <td>0.923125</td>\n",
       "      <td>0.927498</td>\n",
       "      <td>0.932307</td>\n",
       "      <td>0.868723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.956135</td>\n",
       "      <td>0.990904</td>\n",
       "      <td>0.954685</td>\n",
       "      <td>0.937158</td>\n",
       "      <td>0.956187</td>\n",
       "      <td>0.905905</td>\n",
       "      <td>0.919644</td>\n",
       "      <td>0.931253</td>\n",
       "      <td>0.960819</td>\n",
       "      <td>0.901472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.953687</td>\n",
       "      <td>0.965691</td>\n",
       "      <td>0.936725</td>\n",
       "      <td>0.866218</td>\n",
       "      <td>0.952289</td>\n",
       "      <td>0.943440</td>\n",
       "      <td>0.939819</td>\n",
       "      <td>0.899923</td>\n",
       "      <td>0.957791</td>\n",
       "      <td>0.891455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.936600</td>\n",
       "      <td>0.977681</td>\n",
       "      <td>0.946497</td>\n",
       "      <td>0.912202</td>\n",
       "      <td>0.978923</td>\n",
       "      <td>0.931892</td>\n",
       "      <td>0.945264</td>\n",
       "      <td>0.891559</td>\n",
       "      <td>0.979854</td>\n",
       "      <td>0.936497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936631</td>\n",
       "      <td>0.977182</td>\n",
       "      <td>0.933725</td>\n",
       "      <td>0.906639</td>\n",
       "      <td>0.945485</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.938681</td>\n",
       "      <td>0.917949</td>\n",
       "      <td>0.945010</td>\n",
       "      <td>0.867324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.919286</td>\n",
       "      <td>0.942417</td>\n",
       "      <td>0.959116</td>\n",
       "      <td>0.903140</td>\n",
       "      <td>0.963247</td>\n",
       "      <td>0.936205</td>\n",
       "      <td>0.967940</td>\n",
       "      <td>0.867908</td>\n",
       "      <td>0.959406</td>\n",
       "      <td>0.954732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.911953</td>\n",
       "      <td>0.942893</td>\n",
       "      <td>0.921420</td>\n",
       "      <td>0.914833</td>\n",
       "      <td>0.934527</td>\n",
       "      <td>0.922173</td>\n",
       "      <td>0.897673</td>\n",
       "      <td>0.911693</td>\n",
       "      <td>0.945169</td>\n",
       "      <td>0.817390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.934691</td>\n",
       "      <td>0.921574</td>\n",
       "      <td>0.909318</td>\n",
       "      <td>0.949374</td>\n",
       "      <td>0.848200</td>\n",
       "      <td>0.775968</td>\n",
       "      <td>0.797328</td>\n",
       "      <td>0.957040</td>\n",
       "      <td>0.838822</td>\n",
       "      <td>0.763840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.904649</td>\n",
       "      <td>0.855741</td>\n",
       "      <td>0.869131</td>\n",
       "      <td>0.730730</td>\n",
       "      <td>0.882732</td>\n",
       "      <td>0.861284</td>\n",
       "      <td>0.941791</td>\n",
       "      <td>0.847517</td>\n",
       "      <td>0.918718</td>\n",
       "      <td>0.949725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.984844</td>\n",
       "      <td>0.944606</td>\n",
       "      <td>0.961807</td>\n",
       "      <td>0.979869</td>\n",
       "      <td>0.893634</td>\n",
       "      <td>0.869680</td>\n",
       "      <td>0.879807</td>\n",
       "      <td>0.982651</td>\n",
       "      <td>0.886543</td>\n",
       "      <td>0.855681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978137</td>\n",
       "      <td>0.918483</td>\n",
       "      <td>0.943930</td>\n",
       "      <td>0.820970</td>\n",
       "      <td>0.959649</td>\n",
       "      <td>0.914970</td>\n",
       "      <td>0.944474</td>\n",
       "      <td>0.920791</td>\n",
       "      <td>0.975852</td>\n",
       "      <td>0.962419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>0.967800</td>\n",
       "      <td>0.933603</td>\n",
       "      <td>0.937856</td>\n",
       "      <td>0.940380</td>\n",
       "      <td>0.896627</td>\n",
       "      <td>0.896964</td>\n",
       "      <td>0.898484</td>\n",
       "      <td>0.942770</td>\n",
       "      <td>0.900102</td>\n",
       "      <td>0.886137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.971950</td>\n",
       "      <td>0.931199</td>\n",
       "      <td>0.947390</td>\n",
       "      <td>0.857178</td>\n",
       "      <td>0.958175</td>\n",
       "      <td>0.918190</td>\n",
       "      <td>0.914659</td>\n",
       "      <td>0.918952</td>\n",
       "      <td>0.952488</td>\n",
       "      <td>0.923974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>0.967140</td>\n",
       "      <td>0.936673</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.952170</td>\n",
       "      <td>0.938316</td>\n",
       "      <td>0.921437</td>\n",
       "      <td>0.921052</td>\n",
       "      <td>0.929696</td>\n",
       "      <td>0.916468</td>\n",
       "      <td>0.908063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963678</td>\n",
       "      <td>0.949509</td>\n",
       "      <td>0.960455</td>\n",
       "      <td>0.882352</td>\n",
       "      <td>0.969223</td>\n",
       "      <td>0.958945</td>\n",
       "      <td>0.951901</td>\n",
       "      <td>0.966274</td>\n",
       "      <td>0.979823</td>\n",
       "      <td>0.928878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>0.963613</td>\n",
       "      <td>0.974446</td>\n",
       "      <td>0.957008</td>\n",
       "      <td>0.957620</td>\n",
       "      <td>0.941820</td>\n",
       "      <td>0.884406</td>\n",
       "      <td>0.891121</td>\n",
       "      <td>0.949992</td>\n",
       "      <td>0.929272</td>\n",
       "      <td>0.870966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959514</td>\n",
       "      <td>0.952006</td>\n",
       "      <td>0.936573</td>\n",
       "      <td>0.842276</td>\n",
       "      <td>0.950880</td>\n",
       "      <td>0.950162</td>\n",
       "      <td>0.970192</td>\n",
       "      <td>0.921156</td>\n",
       "      <td>0.967212</td>\n",
       "      <td>0.941751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>0.900504</td>\n",
       "      <td>0.954040</td>\n",
       "      <td>0.925524</td>\n",
       "      <td>0.870685</td>\n",
       "      <td>0.983776</td>\n",
       "      <td>0.940631</td>\n",
       "      <td>0.955483</td>\n",
       "      <td>0.840163</td>\n",
       "      <td>0.984983</td>\n",
       "      <td>0.953243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898092</td>\n",
       "      <td>0.966872</td>\n",
       "      <td>0.914926</td>\n",
       "      <td>0.928640</td>\n",
       "      <td>0.920835</td>\n",
       "      <td>0.946158</td>\n",
       "      <td>0.907563</td>\n",
       "      <td>0.903999</td>\n",
       "      <td>0.916698</td>\n",
       "      <td>0.811857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>0.924067</td>\n",
       "      <td>0.960100</td>\n",
       "      <td>0.955246</td>\n",
       "      <td>0.908885</td>\n",
       "      <td>0.989303</td>\n",
       "      <td>0.928431</td>\n",
       "      <td>0.934263</td>\n",
       "      <td>0.874492</td>\n",
       "      <td>0.964737</td>\n",
       "      <td>0.923960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915976</td>\n",
       "      <td>0.965720</td>\n",
       "      <td>0.932436</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.936145</td>\n",
       "      <td>0.973431</td>\n",
       "      <td>0.950148</td>\n",
       "      <td>0.937072</td>\n",
       "      <td>0.952101</td>\n",
       "      <td>0.860337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>0.979408</td>\n",
       "      <td>0.961254</td>\n",
       "      <td>0.989085</td>\n",
       "      <td>0.973498</td>\n",
       "      <td>0.942079</td>\n",
       "      <td>0.916668</td>\n",
       "      <td>0.923896</td>\n",
       "      <td>0.957730</td>\n",
       "      <td>0.924984</td>\n",
       "      <td>0.903087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976142</td>\n",
       "      <td>0.949486</td>\n",
       "      <td>0.963402</td>\n",
       "      <td>0.871838</td>\n",
       "      <td>0.976429</td>\n",
       "      <td>0.950281</td>\n",
       "      <td>0.948603</td>\n",
       "      <td>0.946643</td>\n",
       "      <td>0.996516</td>\n",
       "      <td>0.923238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>0.945540</td>\n",
       "      <td>0.931376</td>\n",
       "      <td>0.966541</td>\n",
       "      <td>0.927805</td>\n",
       "      <td>0.950281</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.946100</td>\n",
       "      <td>0.890384</td>\n",
       "      <td>0.935208</td>\n",
       "      <td>0.930792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924180</td>\n",
       "      <td>0.935676</td>\n",
       "      <td>0.937858</td>\n",
       "      <td>0.904511</td>\n",
       "      <td>0.940218</td>\n",
       "      <td>0.938632</td>\n",
       "      <td>0.935806</td>\n",
       "      <td>0.949743</td>\n",
       "      <td>0.957506</td>\n",
       "      <td>0.875337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>0.913046</td>\n",
       "      <td>0.941019</td>\n",
       "      <td>0.947244</td>\n",
       "      <td>0.900595</td>\n",
       "      <td>0.976094</td>\n",
       "      <td>0.922568</td>\n",
       "      <td>0.913057</td>\n",
       "      <td>0.867334</td>\n",
       "      <td>0.940026</td>\n",
       "      <td>0.905561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.911574</td>\n",
       "      <td>0.958077</td>\n",
       "      <td>0.931097</td>\n",
       "      <td>0.893726</td>\n",
       "      <td>0.933474</td>\n",
       "      <td>0.979477</td>\n",
       "      <td>0.940753</td>\n",
       "      <td>0.939417</td>\n",
       "      <td>0.950818</td>\n",
       "      <td>0.859893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>0.861036</td>\n",
       "      <td>0.876563</td>\n",
       "      <td>0.887611</td>\n",
       "      <td>0.829976</td>\n",
       "      <td>0.941654</td>\n",
       "      <td>0.959038</td>\n",
       "      <td>0.957731</td>\n",
       "      <td>0.792432</td>\n",
       "      <td>0.933610</td>\n",
       "      <td>0.978388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>0.941156</td>\n",
       "      <td>0.896047</td>\n",
       "      <td>0.959293</td>\n",
       "      <td>0.907171</td>\n",
       "      <td>0.919712</td>\n",
       "      <td>0.858289</td>\n",
       "      <td>0.922420</td>\n",
       "      <td>0.885719</td>\n",
       "      <td>0.785659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>0.961729</td>\n",
       "      <td>0.948990</td>\n",
       "      <td>0.933908</td>\n",
       "      <td>0.955506</td>\n",
       "      <td>0.892652</td>\n",
       "      <td>0.853375</td>\n",
       "      <td>0.845373</td>\n",
       "      <td>0.968084</td>\n",
       "      <td>0.881288</td>\n",
       "      <td>0.825264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967007</td>\n",
       "      <td>0.928329</td>\n",
       "      <td>0.930827</td>\n",
       "      <td>0.799465</td>\n",
       "      <td>0.945480</td>\n",
       "      <td>0.930222</td>\n",
       "      <td>0.947083</td>\n",
       "      <td>0.899426</td>\n",
       "      <td>0.956350</td>\n",
       "      <td>0.966689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>0.925875</td>\n",
       "      <td>0.951619</td>\n",
       "      <td>0.950568</td>\n",
       "      <td>0.908623</td>\n",
       "      <td>0.980308</td>\n",
       "      <td>0.926189</td>\n",
       "      <td>0.926581</td>\n",
       "      <td>0.876216</td>\n",
       "      <td>0.954436</td>\n",
       "      <td>0.918509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919965</td>\n",
       "      <td>0.965868</td>\n",
       "      <td>0.934310</td>\n",
       "      <td>0.901675</td>\n",
       "      <td>0.938291</td>\n",
       "      <td>0.976628</td>\n",
       "      <td>0.952847</td>\n",
       "      <td>0.943755</td>\n",
       "      <td>0.950355</td>\n",
       "      <td>0.874653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>0.900848</td>\n",
       "      <td>0.951599</td>\n",
       "      <td>0.925938</td>\n",
       "      <td>0.872509</td>\n",
       "      <td>0.985316</td>\n",
       "      <td>0.943956</td>\n",
       "      <td>0.954814</td>\n",
       "      <td>0.841566</td>\n",
       "      <td>0.982708</td>\n",
       "      <td>0.954862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903012</td>\n",
       "      <td>0.971552</td>\n",
       "      <td>0.916592</td>\n",
       "      <td>0.930429</td>\n",
       "      <td>0.924562</td>\n",
       "      <td>0.952384</td>\n",
       "      <td>0.912672</td>\n",
       "      <td>0.912118</td>\n",
       "      <td>0.919232</td>\n",
       "      <td>0.820138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>0.932495</td>\n",
       "      <td>0.885727</td>\n",
       "      <td>0.877915</td>\n",
       "      <td>0.924127</td>\n",
       "      <td>0.823207</td>\n",
       "      <td>0.799463</td>\n",
       "      <td>0.789771</td>\n",
       "      <td>0.946493</td>\n",
       "      <td>0.816179</td>\n",
       "      <td>0.772788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939742</td>\n",
       "      <td>0.876831</td>\n",
       "      <td>0.889269</td>\n",
       "      <td>0.748175</td>\n",
       "      <td>0.904361</td>\n",
       "      <td>0.879219</td>\n",
       "      <td>0.919056</td>\n",
       "      <td>0.872397</td>\n",
       "      <td>0.904701</td>\n",
       "      <td>0.991854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>0.917714</td>\n",
       "      <td>0.942829</td>\n",
       "      <td>0.946191</td>\n",
       "      <td>0.904459</td>\n",
       "      <td>0.975630</td>\n",
       "      <td>0.922451</td>\n",
       "      <td>0.915683</td>\n",
       "      <td>0.871721</td>\n",
       "      <td>0.942570</td>\n",
       "      <td>0.908682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916542</td>\n",
       "      <td>0.960537</td>\n",
       "      <td>0.931323</td>\n",
       "      <td>0.895778</td>\n",
       "      <td>0.934985</td>\n",
       "      <td>0.978308</td>\n",
       "      <td>0.947930</td>\n",
       "      <td>0.943520</td>\n",
       "      <td>0.949836</td>\n",
       "      <td>0.871042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>0.849302</td>\n",
       "      <td>0.884023</td>\n",
       "      <td>0.877784</td>\n",
       "      <td>0.824867</td>\n",
       "      <td>0.942408</td>\n",
       "      <td>0.900269</td>\n",
       "      <td>0.910943</td>\n",
       "      <td>0.784115</td>\n",
       "      <td>0.927823</td>\n",
       "      <td>0.914379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841397</td>\n",
       "      <td>0.913612</td>\n",
       "      <td>0.869499</td>\n",
       "      <td>0.906153</td>\n",
       "      <td>0.867334</td>\n",
       "      <td>0.914490</td>\n",
       "      <td>0.883737</td>\n",
       "      <td>0.892312</td>\n",
       "      <td>0.868649</td>\n",
       "      <td>0.787591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>0.955125</td>\n",
       "      <td>0.931689</td>\n",
       "      <td>0.920295</td>\n",
       "      <td>0.946027</td>\n",
       "      <td>0.878139</td>\n",
       "      <td>0.842774</td>\n",
       "      <td>0.834683</td>\n",
       "      <td>0.958170</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.816135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957950</td>\n",
       "      <td>0.917628</td>\n",
       "      <td>0.921958</td>\n",
       "      <td>0.791426</td>\n",
       "      <td>0.935100</td>\n",
       "      <td>0.921472</td>\n",
       "      <td>0.944621</td>\n",
       "      <td>0.898528</td>\n",
       "      <td>0.942441</td>\n",
       "      <td>0.975220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>0.906941</td>\n",
       "      <td>0.913539</td>\n",
       "      <td>0.913066</td>\n",
       "      <td>0.879185</td>\n",
       "      <td>0.950456</td>\n",
       "      <td>0.928856</td>\n",
       "      <td>0.913941</td>\n",
       "      <td>0.851070</td>\n",
       "      <td>0.929656</td>\n",
       "      <td>0.919576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917733</td>\n",
       "      <td>0.963355</td>\n",
       "      <td>0.925014</td>\n",
       "      <td>0.910420</td>\n",
       "      <td>0.929088</td>\n",
       "      <td>0.969681</td>\n",
       "      <td>0.931438</td>\n",
       "      <td>0.948490</td>\n",
       "      <td>0.920326</td>\n",
       "      <td>0.881234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>0.965903</td>\n",
       "      <td>0.920938</td>\n",
       "      <td>0.933978</td>\n",
       "      <td>0.973417</td>\n",
       "      <td>0.842266</td>\n",
       "      <td>0.808197</td>\n",
       "      <td>0.823842</td>\n",
       "      <td>0.990965</td>\n",
       "      <td>0.838009</td>\n",
       "      <td>0.791538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947608</td>\n",
       "      <td>0.865186</td>\n",
       "      <td>0.905676</td>\n",
       "      <td>0.755725</td>\n",
       "      <td>0.920838</td>\n",
       "      <td>0.863611</td>\n",
       "      <td>0.915393</td>\n",
       "      <td>0.866008</td>\n",
       "      <td>0.949619</td>\n",
       "      <td>0.951606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>0.982152</td>\n",
       "      <td>0.937690</td>\n",
       "      <td>0.952895</td>\n",
       "      <td>0.972655</td>\n",
       "      <td>0.882198</td>\n",
       "      <td>0.869477</td>\n",
       "      <td>0.865885</td>\n",
       "      <td>0.984662</td>\n",
       "      <td>0.874319</td>\n",
       "      <td>0.844744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985149</td>\n",
       "      <td>0.918035</td>\n",
       "      <td>0.949586</td>\n",
       "      <td>0.814289</td>\n",
       "      <td>0.964141</td>\n",
       "      <td>0.916617</td>\n",
       "      <td>0.931291</td>\n",
       "      <td>0.915480</td>\n",
       "      <td>0.973648</td>\n",
       "      <td>0.963097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>0.964074</td>\n",
       "      <td>0.968464</td>\n",
       "      <td>0.957901</td>\n",
       "      <td>0.958921</td>\n",
       "      <td>0.931479</td>\n",
       "      <td>0.874908</td>\n",
       "      <td>0.877442</td>\n",
       "      <td>0.953946</td>\n",
       "      <td>0.915484</td>\n",
       "      <td>0.855127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955516</td>\n",
       "      <td>0.942802</td>\n",
       "      <td>0.937816</td>\n",
       "      <td>0.828436</td>\n",
       "      <td>0.948950</td>\n",
       "      <td>0.948587</td>\n",
       "      <td>0.965666</td>\n",
       "      <td>0.916147</td>\n",
       "      <td>0.969263</td>\n",
       "      <td>0.943078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>0.972241</td>\n",
       "      <td>0.938020</td>\n",
       "      <td>0.946472</td>\n",
       "      <td>0.952955</td>\n",
       "      <td>0.905598</td>\n",
       "      <td>0.911080</td>\n",
       "      <td>0.897594</td>\n",
       "      <td>0.957698</td>\n",
       "      <td>0.899163</td>\n",
       "      <td>0.888975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997780</td>\n",
       "      <td>0.949775</td>\n",
       "      <td>0.959396</td>\n",
       "      <td>0.861076</td>\n",
       "      <td>0.978120</td>\n",
       "      <td>0.938425</td>\n",
       "      <td>0.928003</td>\n",
       "      <td>0.938801</td>\n",
       "      <td>0.969290</td>\n",
       "      <td>0.949512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0.927735</td>\n",
       "      <td>0.950168</td>\n",
       "      <td>0.933018</td>\n",
       "      <td>0.898075</td>\n",
       "      <td>0.969282</td>\n",
       "      <td>0.951053</td>\n",
       "      <td>0.936528</td>\n",
       "      <td>0.879065</td>\n",
       "      <td>0.959648</td>\n",
       "      <td>0.940674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949775</td>\n",
       "      <td>0.993511</td>\n",
       "      <td>0.943657</td>\n",
       "      <td>0.919905</td>\n",
       "      <td>0.957293</td>\n",
       "      <td>0.979018</td>\n",
       "      <td>0.933308</td>\n",
       "      <td>0.942675</td>\n",
       "      <td>0.941020</td>\n",
       "      <td>0.884880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>0.954305</td>\n",
       "      <td>0.927305</td>\n",
       "      <td>0.948638</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.920321</td>\n",
       "      <td>0.924238</td>\n",
       "      <td>0.912866</td>\n",
       "      <td>0.916256</td>\n",
       "      <td>0.909830</td>\n",
       "      <td>0.905340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959396</td>\n",
       "      <td>0.943657</td>\n",
       "      <td>0.959101</td>\n",
       "      <td>0.885708</td>\n",
       "      <td>0.962960</td>\n",
       "      <td>0.945617</td>\n",
       "      <td>0.916101</td>\n",
       "      <td>0.940697</td>\n",
       "      <td>0.960420</td>\n",
       "      <td>0.901334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0.843801</td>\n",
       "      <td>0.853174</td>\n",
       "      <td>0.863751</td>\n",
       "      <td>0.806302</td>\n",
       "      <td>0.917565</td>\n",
       "      <td>0.942606</td>\n",
       "      <td>0.932247</td>\n",
       "      <td>0.770735</td>\n",
       "      <td>0.911446</td>\n",
       "      <td>0.953461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861076</td>\n",
       "      <td>0.919905</td>\n",
       "      <td>0.885708</td>\n",
       "      <td>0.949398</td>\n",
       "      <td>0.885819</td>\n",
       "      <td>0.906678</td>\n",
       "      <td>0.839221</td>\n",
       "      <td>0.905676</td>\n",
       "      <td>0.861810</td>\n",
       "      <td>0.769923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>0.962973</td>\n",
       "      <td>0.940251</td>\n",
       "      <td>0.957597</td>\n",
       "      <td>0.940919</td>\n",
       "      <td>0.928897</td>\n",
       "      <td>0.930581</td>\n",
       "      <td>0.919966</td>\n",
       "      <td>0.932238</td>\n",
       "      <td>0.918235</td>\n",
       "      <td>0.912494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978120</td>\n",
       "      <td>0.957293</td>\n",
       "      <td>0.962960</td>\n",
       "      <td>0.885819</td>\n",
       "      <td>0.976429</td>\n",
       "      <td>0.951520</td>\n",
       "      <td>0.926388</td>\n",
       "      <td>0.946692</td>\n",
       "      <td>0.971720</td>\n",
       "      <td>0.916510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.922967</td>\n",
       "      <td>0.934127</td>\n",
       "      <td>0.935604</td>\n",
       "      <td>0.898540</td>\n",
       "      <td>0.963797</td>\n",
       "      <td>0.939656</td>\n",
       "      <td>0.915281</td>\n",
       "      <td>0.874546</td>\n",
       "      <td>0.936235</td>\n",
       "      <td>0.917370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938425</td>\n",
       "      <td>0.979018</td>\n",
       "      <td>0.945617</td>\n",
       "      <td>0.906678</td>\n",
       "      <td>0.951520</td>\n",
       "      <td>0.991183</td>\n",
       "      <td>0.939690</td>\n",
       "      <td>0.955403</td>\n",
       "      <td>0.947145</td>\n",
       "      <td>0.889972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.941377</td>\n",
       "      <td>0.947320</td>\n",
       "      <td>0.940549</td>\n",
       "      <td>0.935617</td>\n",
       "      <td>0.934863</td>\n",
       "      <td>0.871768</td>\n",
       "      <td>0.883521</td>\n",
       "      <td>0.916482</td>\n",
       "      <td>0.917106</td>\n",
       "      <td>0.865355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928003</td>\n",
       "      <td>0.933308</td>\n",
       "      <td>0.916101</td>\n",
       "      <td>0.839221</td>\n",
       "      <td>0.926388</td>\n",
       "      <td>0.939690</td>\n",
       "      <td>0.969113</td>\n",
       "      <td>0.922310</td>\n",
       "      <td>0.944993</td>\n",
       "      <td>0.929196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.924171</td>\n",
       "      <td>0.892866</td>\n",
       "      <td>0.928179</td>\n",
       "      <td>0.900440</td>\n",
       "      <td>0.925191</td>\n",
       "      <td>0.932048</td>\n",
       "      <td>0.913542</td>\n",
       "      <td>0.872618</td>\n",
       "      <td>0.898656</td>\n",
       "      <td>0.918008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938801</td>\n",
       "      <td>0.942675</td>\n",
       "      <td>0.940697</td>\n",
       "      <td>0.905676</td>\n",
       "      <td>0.946692</td>\n",
       "      <td>0.955403</td>\n",
       "      <td>0.922310</td>\n",
       "      <td>0.972152</td>\n",
       "      <td>0.940293</td>\n",
       "      <td>0.898569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.976959</td>\n",
       "      <td>0.959238</td>\n",
       "      <td>0.990887</td>\n",
       "      <td>0.974549</td>\n",
       "      <td>0.938168</td>\n",
       "      <td>0.908084</td>\n",
       "      <td>0.915810</td>\n",
       "      <td>0.958389</td>\n",
       "      <td>0.917874</td>\n",
       "      <td>0.892406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969290</td>\n",
       "      <td>0.941020</td>\n",
       "      <td>0.960420</td>\n",
       "      <td>0.861810</td>\n",
       "      <td>0.971720</td>\n",
       "      <td>0.947145</td>\n",
       "      <td>0.944993</td>\n",
       "      <td>0.940293</td>\n",
       "      <td>0.998532</td>\n",
       "      <td>0.917105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.940458</td>\n",
       "      <td>0.885163</td>\n",
       "      <td>0.890669</td>\n",
       "      <td>0.932908</td>\n",
       "      <td>0.835651</td>\n",
       "      <td>0.818047</td>\n",
       "      <td>0.809028</td>\n",
       "      <td>0.946369</td>\n",
       "      <td>0.824724</td>\n",
       "      <td>0.794167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949512</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>0.901334</td>\n",
       "      <td>0.769923</td>\n",
       "      <td>0.916510</td>\n",
       "      <td>0.889972</td>\n",
       "      <td>0.929196</td>\n",
       "      <td>0.898569</td>\n",
       "      <td>0.917105</td>\n",
       "      <td>0.996889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 980 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.991154  0.955328  0.969529  0.973129  0.908920  0.886188  0.902115   \n",
       "1    0.955328  0.994694  0.962074  0.943584  0.958195  0.889848  0.914993   \n",
       "2    0.969529  0.962074  0.996145  0.966989  0.945786  0.903766  0.927357   \n",
       "3    0.973129  0.943584  0.966989  0.979929  0.891627  0.852030  0.873517   \n",
       "4    0.908920  0.958195  0.945786  0.891627  0.995676  0.936040  0.948124   \n",
       "5    0.886188  0.889848  0.903766  0.852030  0.936040  0.960130  0.939654   \n",
       "6    0.902115  0.914993  0.927357  0.873517  0.948124  0.939654  0.965021   \n",
       "7    0.971101  0.932280  0.942365  0.975832  0.855386  0.824101  0.838032   \n",
       "8    0.908059  0.959820  0.929251  0.881278  0.977856  0.925268  0.950094   \n",
       "9    0.878027  0.889961  0.898904  0.842075  0.941444  0.954629  0.963026   \n",
       "10   0.932913  0.930461  0.946364  0.902258  0.957704  0.968984  0.959153   \n",
       "11   0.985865  0.946161  0.966077  0.977887  0.902707  0.880130  0.889276   \n",
       "12   0.976466  0.938235  0.954351  0.982315  0.873039  0.843893  0.853097   \n",
       "13   0.962246  0.904897  0.913526  0.951546  0.843031  0.840801  0.830964   \n",
       "14   0.953118  0.930633  0.915262  0.950245  0.863614  0.825328  0.818732   \n",
       "15   0.869851  0.907701  0.911232  0.854549  0.975573  0.927261  0.921390   \n",
       "16   0.973693  0.932908  0.963640  0.974128  0.891768  0.858154  0.871551   \n",
       "17   0.958112  0.969233  0.946355  0.965931  0.903844  0.831681  0.850125   \n",
       "18   0.978273  0.941665  0.964612  0.980292  0.891069  0.857574  0.873291   \n",
       "19   0.963793  0.931491  0.957415  0.937322  0.936734  0.938309  0.929152   \n",
       "20   0.819522  0.842104  0.850309  0.787570  0.906177  0.916703  0.933910   \n",
       "21   0.969448  0.926535  0.954228  0.976976  0.868070  0.832934  0.842737   \n",
       "22   0.829641  0.875146  0.856958  0.796473  0.949298  0.940855  0.935598   \n",
       "23   0.905424  0.946218  0.915197  0.870080  0.968741  0.949708  0.949722   \n",
       "24   0.923922  0.955135  0.927075  0.892074  0.968724  0.948902  0.944139   \n",
       "25   0.956135  0.990904  0.954685  0.937158  0.956187  0.905905  0.919644   \n",
       "26   0.936600  0.977681  0.946497  0.912202  0.978923  0.931892  0.945264   \n",
       "27   0.919286  0.942417  0.959116  0.903140  0.963247  0.936205  0.967940   \n",
       "28   0.934691  0.921574  0.909318  0.949374  0.848200  0.775968  0.797328   \n",
       "29   0.984844  0.944606  0.961807  0.979869  0.893634  0.869680  0.879807   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "950  0.967800  0.933603  0.937856  0.940380  0.896627  0.896964  0.898484   \n",
       "951  0.967140  0.936673  0.973077  0.952170  0.938316  0.921437  0.921052   \n",
       "952  0.963613  0.974446  0.957008  0.957620  0.941820  0.884406  0.891121   \n",
       "953  0.900504  0.954040  0.925524  0.870685  0.983776  0.940631  0.955483   \n",
       "954  0.924067  0.960100  0.955246  0.908885  0.989303  0.928431  0.934263   \n",
       "955  0.979408  0.961254  0.989085  0.973498  0.942079  0.916668  0.923896   \n",
       "956  0.945540  0.931376  0.966541  0.927805  0.950281  0.922078  0.946100   \n",
       "957  0.913046  0.941019  0.947244  0.900595  0.976094  0.922568  0.913057   \n",
       "958  0.861036  0.876563  0.887611  0.829976  0.941654  0.959038  0.957731   \n",
       "959  0.961729  0.948990  0.933908  0.955506  0.892652  0.853375  0.845373   \n",
       "960  0.925875  0.951619  0.950568  0.908623  0.980308  0.926189  0.926581   \n",
       "961  0.900848  0.951599  0.925938  0.872509  0.985316  0.943956  0.954814   \n",
       "962  0.932495  0.885727  0.877915  0.924127  0.823207  0.799463  0.789771   \n",
       "963  0.917714  0.942829  0.946191  0.904459  0.975630  0.922451  0.915683   \n",
       "964  0.849302  0.884023  0.877784  0.824867  0.942408  0.900269  0.910943   \n",
       "965  0.955125  0.931689  0.920295  0.946027  0.878139  0.842774  0.834683   \n",
       "966  0.906941  0.913539  0.913066  0.879185  0.950456  0.928856  0.913941   \n",
       "967  0.965903  0.920938  0.933978  0.973417  0.842266  0.808197  0.823842   \n",
       "968  0.982152  0.937690  0.952895  0.972655  0.882198  0.869477  0.865885   \n",
       "969  0.964074  0.968464  0.957901  0.958921  0.931479  0.874908  0.877442   \n",
       "970  0.972241  0.938020  0.946472  0.952955  0.905598  0.911080  0.897594   \n",
       "971  0.927735  0.950168  0.933018  0.898075  0.969282  0.951053  0.936528   \n",
       "972  0.954305  0.927305  0.948638  0.927536  0.920321  0.924238  0.912866   \n",
       "973  0.843801  0.853174  0.863751  0.806302  0.917565  0.942606  0.932247   \n",
       "974  0.962973  0.940251  0.957597  0.940919  0.928897  0.930581  0.919966   \n",
       "975  0.922967  0.934127  0.935604  0.898540  0.963797  0.939656  0.915281   \n",
       "976  0.941377  0.947320  0.940549  0.935617  0.934863  0.871768  0.883521   \n",
       "977  0.924171  0.892866  0.928179  0.900440  0.925191  0.932048  0.913542   \n",
       "978  0.976959  0.959238  0.990887  0.974549  0.938168  0.908084  0.915810   \n",
       "979  0.940458  0.885163  0.890669  0.932908  0.835651  0.818047  0.809028   \n",
       "\n",
       "          7         8         9      ...          970       971       972  \\\n",
       "0    0.971101  0.908059  0.878027    ...     0.972241  0.927735  0.954305   \n",
       "1    0.932280  0.959820  0.889961    ...     0.938020  0.950168  0.927305   \n",
       "2    0.942365  0.929251  0.898904    ...     0.946472  0.933018  0.948638   \n",
       "3    0.975832  0.881278  0.842075    ...     0.952955  0.898075  0.927536   \n",
       "4    0.855386  0.977856  0.941444    ...     0.905598  0.969282  0.920321   \n",
       "5    0.824101  0.925268  0.954629    ...     0.911080  0.951053  0.924238   \n",
       "6    0.838032  0.950094  0.963026    ...     0.897594  0.936528  0.912866   \n",
       "7    0.993016  0.852189  0.806896    ...     0.957698  0.879065  0.916256   \n",
       "8    0.852189  0.983049  0.942466    ...     0.899163  0.959648  0.909830   \n",
       "9    0.806896  0.942466  0.976619    ...     0.888975  0.940674  0.905340   \n",
       "10   0.877766  0.947985  0.964576    ...     0.953458  0.975262  0.954010   \n",
       "11   0.976504  0.894367  0.866683    ...     0.978629  0.926117  0.949582   \n",
       "12   0.993157  0.863824  0.824574    ...     0.970268  0.896412  0.930145   \n",
       "13   0.974184  0.838208  0.814235    ...     0.976820  0.893189  0.925773   \n",
       "14   0.969987  0.854279  0.797013    ...     0.956799  0.903798  0.913091   \n",
       "15   0.811331  0.939638  0.925209    ...     0.875115  0.945929  0.898746   \n",
       "16   0.967645  0.877283  0.844489    ...     0.955329  0.904882  0.933772   \n",
       "17   0.969318  0.895478  0.818786    ...     0.939296  0.907093  0.908175   \n",
       "18   0.978669  0.880638  0.844924    ...     0.962732  0.905639  0.934241   \n",
       "19   0.919387  0.922082  0.925405    ...     0.973158  0.962376  0.964833   \n",
       "20   0.747245  0.908218  0.948757    ...     0.825593  0.889156  0.851879   \n",
       "21   0.981884  0.853538  0.812396    ...     0.952219  0.885217  0.923585   \n",
       "22   0.759703  0.943159  0.959162    ...     0.851558  0.944906  0.868684   \n",
       "23   0.848076  0.973892  0.955133    ...     0.919768  0.979894  0.923351   \n",
       "24   0.874161  0.969078  0.947950    ...     0.943798  0.989984  0.935475   \n",
       "25   0.931253  0.960819  0.901472    ...     0.953687  0.965691  0.936725   \n",
       "26   0.891559  0.979854  0.936497    ...     0.936631  0.977182  0.933725   \n",
       "27   0.867908  0.959406  0.954732    ...     0.911953  0.942893  0.921420   \n",
       "28   0.957040  0.838822  0.763840    ...     0.904649  0.855741  0.869131   \n",
       "29   0.982651  0.886543  0.855681    ...     0.978137  0.918483  0.943930   \n",
       "..        ...       ...       ...    ...          ...       ...       ...   \n",
       "950  0.942770  0.900102  0.886137    ...     0.971950  0.931199  0.947390   \n",
       "951  0.929696  0.916468  0.908063    ...     0.963678  0.949509  0.960455   \n",
       "952  0.949992  0.929272  0.870966    ...     0.959514  0.952006  0.936573   \n",
       "953  0.840163  0.984983  0.953243    ...     0.898092  0.966872  0.914926   \n",
       "954  0.874492  0.964737  0.923960    ...     0.915976  0.965720  0.932436   \n",
       "955  0.957730  0.924984  0.903087    ...     0.976142  0.949486  0.963402   \n",
       "956  0.890384  0.935208  0.930792    ...     0.924180  0.935676  0.937858   \n",
       "957  0.867334  0.940026  0.905561    ...     0.911574  0.958077  0.931097   \n",
       "958  0.792432  0.933610  0.978388    ...     0.884848  0.941156  0.896047   \n",
       "959  0.968084  0.881288  0.825264    ...     0.967007  0.928329  0.930827   \n",
       "960  0.876216  0.954436  0.918509    ...     0.919965  0.965868  0.934310   \n",
       "961  0.841566  0.982708  0.954862    ...     0.903012  0.971552  0.916592   \n",
       "962  0.946493  0.816179  0.772788    ...     0.939742  0.876831  0.889269   \n",
       "963  0.871721  0.942570  0.908682    ...     0.916542  0.960537  0.931323   \n",
       "964  0.784115  0.927823  0.914379    ...     0.841397  0.913612  0.869499   \n",
       "965  0.958170  0.867470  0.816135    ...     0.957950  0.917628  0.921958   \n",
       "966  0.851070  0.929656  0.919576    ...     0.917733  0.963355  0.925014   \n",
       "967  0.990965  0.838009  0.791538    ...     0.947608  0.865186  0.905676   \n",
       "968  0.984662  0.874319  0.844744    ...     0.985149  0.918035  0.949586   \n",
       "969  0.953946  0.915484  0.855127    ...     0.955516  0.942802  0.937816   \n",
       "970  0.957698  0.899163  0.888975    ...     0.997780  0.949775  0.959396   \n",
       "971  0.879065  0.959648  0.940674    ...     0.949775  0.993511  0.943657   \n",
       "972  0.916256  0.909830  0.905340    ...     0.959396  0.943657  0.959101   \n",
       "973  0.770735  0.911446  0.953461    ...     0.861076  0.919905  0.885708   \n",
       "974  0.932238  0.918235  0.912494    ...     0.978120  0.957293  0.962960   \n",
       "975  0.874546  0.936235  0.917370    ...     0.938425  0.979018  0.945617   \n",
       "976  0.916482  0.917106  0.865355    ...     0.928003  0.933308  0.916101   \n",
       "977  0.872618  0.898656  0.918008    ...     0.938801  0.942675  0.940697   \n",
       "978  0.958389  0.917874  0.892406    ...     0.969290  0.941020  0.960420   \n",
       "979  0.946369  0.824724  0.794167    ...     0.949512  0.884880  0.901334   \n",
       "\n",
       "          973       974       975       976       977       978       979  \n",
       "0    0.843801  0.962973  0.922967  0.941377  0.924171  0.976959  0.940458  \n",
       "1    0.853174  0.940251  0.934127  0.947320  0.892866  0.959238  0.885163  \n",
       "2    0.863751  0.957597  0.935604  0.940549  0.928179  0.990887  0.890669  \n",
       "3    0.806302  0.940919  0.898540  0.935617  0.900440  0.974549  0.932908  \n",
       "4    0.917565  0.928897  0.963797  0.934863  0.925191  0.938168  0.835651  \n",
       "5    0.942606  0.930581  0.939656  0.871768  0.932048  0.908084  0.818047  \n",
       "6    0.932247  0.919966  0.915281  0.883521  0.913542  0.915810  0.809028  \n",
       "7    0.770735  0.932238  0.874546  0.916482  0.872618  0.958389  0.946369  \n",
       "8    0.911446  0.918235  0.936235  0.917106  0.898656  0.917874  0.824724  \n",
       "9    0.953461  0.912494  0.917370  0.865355  0.918008  0.892406  0.794167  \n",
       "10   0.939409  0.967069  0.960547  0.910909  0.956006  0.950851  0.865514  \n",
       "11   0.832985  0.963914  0.923901  0.948800  0.930583  0.978419  0.960626  \n",
       "12   0.790311  0.947001  0.895346  0.929149  0.894889  0.972651  0.954359  \n",
       "13   0.786275  0.942489  0.889590  0.910069  0.895964  0.942437  0.974427  \n",
       "14   0.770728  0.928258  0.905931  0.936230  0.880593  0.940000  0.975128  \n",
       "15   0.919700  0.901165  0.960022  0.912899  0.930269  0.910111  0.813374  \n",
       "16   0.810890  0.945955  0.911269  0.946471  0.919284  0.971792  0.952012  \n",
       "17   0.785366  0.923160  0.905411  0.954886  0.875754  0.955742  0.935618  \n",
       "18   0.809873  0.948394  0.906312  0.942056  0.911178  0.974880  0.949851  \n",
       "19   0.901677  0.974952  0.962683  0.943228  0.972053  0.967819  0.929746  \n",
       "20   0.932591  0.854516  0.866418  0.812370  0.866340  0.839132  0.727434  \n",
       "21   0.779106  0.936728  0.893195  0.932541  0.894736  0.967744  0.952988  \n",
       "22   0.947326  0.876979  0.922021  0.853429  0.892596  0.853077  0.763078  \n",
       "23   0.931391  0.933795  0.951944  0.902796  0.911375  0.915018  0.832671  \n",
       "24   0.922154  0.950399  0.964863  0.923125  0.927498  0.932307  0.868723  \n",
       "25   0.866218  0.952289  0.943440  0.939819  0.899923  0.957791  0.891455  \n",
       "26   0.906639  0.945485  0.956667  0.938681  0.917949  0.945010  0.867324  \n",
       "27   0.914833  0.934527  0.922173  0.897673  0.911693  0.945169  0.817390  \n",
       "28   0.730730  0.882732  0.861284  0.941791  0.847517  0.918718  0.949725  \n",
       "29   0.820970  0.959649  0.914970  0.944474  0.920791  0.975852  0.962419  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "950  0.857178  0.958175  0.918190  0.914659  0.918952  0.952488  0.923974  \n",
       "951  0.882352  0.969223  0.958945  0.951901  0.966274  0.979823  0.928878  \n",
       "952  0.842276  0.950880  0.950162  0.970192  0.921156  0.967212  0.941751  \n",
       "953  0.928640  0.920835  0.946158  0.907563  0.903999  0.916698  0.811857  \n",
       "954  0.906329  0.936145  0.973431  0.950148  0.937072  0.952101  0.860337  \n",
       "955  0.871838  0.976429  0.950281  0.948603  0.946643  0.996516  0.923238  \n",
       "956  0.904511  0.940218  0.938632  0.935806  0.949743  0.957506  0.875337  \n",
       "957  0.893726  0.933474  0.979477  0.940753  0.939417  0.950818  0.859893  \n",
       "958  0.959293  0.907171  0.919712  0.858289  0.922420  0.885719  0.785659  \n",
       "959  0.799465  0.945480  0.930222  0.947083  0.899426  0.956350  0.966689  \n",
       "960  0.901675  0.938291  0.976628  0.952847  0.943755  0.950355  0.874653  \n",
       "961  0.930429  0.924562  0.952384  0.912672  0.912118  0.919232  0.820138  \n",
       "962  0.748175  0.904361  0.879219  0.919056  0.872397  0.904701  0.991854  \n",
       "963  0.895778  0.934985  0.978308  0.947930  0.943520  0.949836  0.871042  \n",
       "964  0.906153  0.867334  0.914490  0.883737  0.892312  0.868649  0.787591  \n",
       "965  0.791426  0.935100  0.921472  0.944621  0.898528  0.942441  0.975220  \n",
       "966  0.910420  0.929088  0.969681  0.931438  0.948490  0.920326  0.881234  \n",
       "967  0.755725  0.920838  0.863611  0.915393  0.866008  0.949619  0.951606  \n",
       "968  0.814289  0.964141  0.916617  0.931291  0.915480  0.973648  0.963097  \n",
       "969  0.828436  0.948950  0.948587  0.965666  0.916147  0.969263  0.943078  \n",
       "970  0.861076  0.978120  0.938425  0.928003  0.938801  0.969290  0.949512  \n",
       "971  0.919905  0.957293  0.979018  0.933308  0.942675  0.941020  0.884880  \n",
       "972  0.885708  0.962960  0.945617  0.916101  0.940697  0.960420  0.901334  \n",
       "973  0.949398  0.885819  0.906678  0.839221  0.905676  0.861810  0.769923  \n",
       "974  0.885819  0.976429  0.951520  0.926388  0.946692  0.971720  0.916510  \n",
       "975  0.906678  0.951520  0.991183  0.939690  0.955403  0.947145  0.889972  \n",
       "976  0.839221  0.926388  0.939690  0.969113  0.922310  0.944993  0.929196  \n",
       "977  0.905676  0.946692  0.955403  0.922310  0.972152  0.940293  0.898569  \n",
       "978  0.861810  0.971720  0.947145  0.944993  0.940293  0.998532  0.917105  \n",
       "979  0.769923  0.916510  0.889972  0.929196  0.898569  0.917105  0.996889  \n",
       "\n",
       "[980 rows x 980 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_train_cauchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### First base predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Class for kernel ridge regression\n",
    "class RidgeRegression(object):\n",
    "    def __init__(self, l2_reg):\n",
    "        self.l2_reg = l2_reg\n",
    "\n",
    "    def fit(self, G, y):\n",
    "        # Train size\n",
    "        n_train = G.shape[0]\n",
    "        ridge_mat = G + (self.l2_reg * n_train) * np.identity(n_train)\n",
    "        self.ridge_mat = ridge_mat\n",
    "        # Shape of y_train is (1, n_train)\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, G_test):\n",
    "        y_test_hat = self.y_train.dot(np.linalg.solve(self.ridge_mat, G_test))\n",
    "        return y_test_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# G_train and G_test are pandas dataframes\n",
    "# krr is a kernel ridge regression\n",
    "def oof_prediction(krr, G_train, y_train, G_test, n_folds, random_seed):\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=random_seed)\n",
    "    n_train = G_train.shape[0]\n",
    "    n_test = G_test.shape[1]\n",
    "    oof_train = np.zeros(n_train)\n",
    "    oof_test = np.zeros(n_test)\n",
    "    oof_test_folds = np.zeros((n_test, n_folds))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(G_train)):\n",
    "        G_tr = G_train.loc[train_index, train_index].values\n",
    "        y_tr = y_train[train_index].reshape((1, -1))\n",
    "        G_te = G_train.loc[train_index, test_index].values\n",
    "\n",
    "        krr.fit(G_tr, y_tr)\n",
    "        oof_train[test_index] = krr.predict(G_te)\n",
    "        G_test_partial = G_test.loc[train_index, :]\n",
    "        oof_test_folds[:, i] = krr.predict(G_test_partial.values)\n",
    "\n",
    "    oof_test = oof_test_folds.mean(axis=1)\n",
    "    return oof_train, oof_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* __Cauchy__: theta: 16, lambda: 2**(-23)\n",
    "* __Matern3/2__: theta: 512, lambda: 2**(-33)\n",
    "* __Matern5/2__: theta: 64, lambda: 2**(-31)\n",
    "* __Rational quadratic__: theta: 512, lambda: 2**(-26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nb_bags_train = 980\n",
    "# Create a vector with the unique values of y for each ID.\n",
    "y_train = train.groupby(\"id\")[\"y\"].median().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load Gram matrices\n",
    "def load_gram(csv_file, nb_bags_train):\n",
    "    # Import data\n",
    "    G = pd.read_csv(csv_file, header=None)\n",
    "    idx_train = nb_bags_train - 1\n",
    "    idx_test = nb_bags_train\n",
    "    G_train = G.loc[:idx_train, :idx_train]\n",
    "    G_test = G.loc[:idx_train, idx_test:]\n",
    "    return (G_train, G_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define models and import Gram matrices\n",
    "# Cauchy\n",
    "l2_reg_cauchy = 2**(-23)\n",
    "cauchy = RidgeRegression(l2_reg_cauchy)\n",
    "G_train_cauchy, G_test_cauchy = load_gram(\"kernels_me/Cauchy_16.csv\", nb_bags_train)\n",
    "\n",
    "# Matern 3/2 -> removed as it gave inferior results\n",
    "l2_reg_matern_32 = 2**(-33)\n",
    "matern_32 = RidgeRegression(l2_reg_matern_32)\n",
    "G_train_matern_32, G_test_matern_32 = load_gram(\"kernels_me/Matern_32_512.csv\", nb_bags_train)\n",
    "\n",
    "# Matern 5/2\n",
    "l2_reg_matern_52 = 2**(-31)\n",
    "matern_52 = RidgeRegression(l2_reg_matern_52)\n",
    "G_train_matern_52, G_test_matern_52 = load_gram(\"kernels_me/Matern_52_64.csv\", nb_bags_train)\n",
    "\n",
    "# Rational quadratic\n",
    "l2_reg_rquadr = 2**(-26)\n",
    "rquadr = RidgeRegression(l2_reg_rquadr)\n",
    "G_train_rquadr, G_test_rquadr = load_gram(\"kernels_me/rquadr_512.csv\", nb_bags_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Root mean squared error metric\n",
    "def RMSE(y, y_hat):\n",
    "    out = np.sqrt(mean_squared_error(y.reshape((-1,)), y_hat.reshape((-1,))))\n",
    "    return (out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is finished.\n"
     ]
    }
   ],
   "source": [
    "# Create OOF train and test predictions\n",
    "# Cauchy\n",
    "cauchy_oof_train, cauchy_oof_test = oof_prediction(cauchy, G_train_cauchy, \n",
    "                                                   y_train, G_test_cauchy,\n",
    "                                                   n_folds, random_seed)\n",
    "#Matern 3/2\n",
    "matern_32_oof_train, matern_32_oof_test = oof_prediction(matern_32, G_train_matern_32, \n",
    "                                                         y_train, G_test_matern_32,\n",
    "                                                         n_folds, random_seed)\n",
    "# Matern 5/2\n",
    "matern_52_oof_train, matern_52_oof_test = oof_prediction(matern_52, G_train_matern_52, \n",
    "                                                         y_train, G_test_matern_52,\n",
    "                                                         n_folds, random_seed)\n",
    "# Rational quadratic\n",
    "rquadr_oof_train, rquadr_oof_test = oof_prediction(rquadr, G_train_rquadr, \n",
    "                                                   y_train, G_test_rquadr,\n",
    "                                                   n_folds, random_seed)\n",
    "print(\"Training is finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67899005155348324"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE(cauchy_oof_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69624680290255281"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE(matern_32_oof_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68417462783849581"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE(matern_52_oof_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67813589585443934"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE(rquadr_oof_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Second level prediction with DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cauchy</th>\n",
       "      <th>matern_32</th>\n",
       "      <th>matern_52</th>\n",
       "      <th>rquadr</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.682060</td>\n",
       "      <td>-3.609573</td>\n",
       "      <td>-3.602315</td>\n",
       "      <td>-3.658850</td>\n",
       "      <td>-3.998082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.281041</td>\n",
       "      <td>-4.398755</td>\n",
       "      <td>-4.306951</td>\n",
       "      <td>-4.295394</td>\n",
       "      <td>-4.137141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.664701</td>\n",
       "      <td>-2.792940</td>\n",
       "      <td>-2.704900</td>\n",
       "      <td>-2.647880</td>\n",
       "      <td>-2.694732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.664187</td>\n",
       "      <td>-3.659535</td>\n",
       "      <td>-3.720432</td>\n",
       "      <td>-3.657264</td>\n",
       "      <td>-3.296275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.749225</td>\n",
       "      <td>-3.813457</td>\n",
       "      <td>-3.762714</td>\n",
       "      <td>-3.722395</td>\n",
       "      <td>-3.181391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cauchy  matern_32  matern_52    rquadr         y\n",
       "0 -3.682060  -3.609573  -3.602315 -3.658850 -3.998082\n",
       "1 -4.281041  -4.398755  -4.306951 -4.295394 -4.137141\n",
       "2 -2.664701  -2.792940  -2.704900 -2.647880 -2.694732\n",
       "3 -3.664187  -3.659535  -3.720432 -3.657264 -3.296275\n",
       "4 -3.749225  -3.813457  -3.762714 -3.722395 -3.181391"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_train = pd.DataFrame({'cauchy': cauchy_oof_train,\n",
    "                             'matern_32': matern_32_oof_train,\n",
    "                             'matern_52': matern_52_oof_train,\n",
    "                             'rquadr': rquadr_oof_train})\n",
    "\n",
    "kernel_train[\"y\"] = y_train\n",
    "\n",
    "kernel_test = pd.DataFrame({'cauchy': cauchy_oof_test,\n",
    "                            'matern_32': matern_32_oof_test,\n",
    "                            'matern_52': matern_52_oof_test,\n",
    "                            'rquadr': rquadr_oof_test})\n",
    "\n",
    "cols_excl_kernel = [\"y\"]\n",
    "cols_kernel = [c for c in kernel_train.columns if c not in cols_excl_kernel]\n",
    "\n",
    "kernel_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Tuning neural network's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def scoring_function(parameters):\n",
    "    print(\"Training the model with parameters: \")\n",
    "    print(parameters)\n",
    "    average_RMSE = 0.0\n",
    "    n_splits = 5\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=15)\n",
    "    nb_fold = 0\n",
    "    for train_index, validation_index in kf.split(kernel_train):\n",
    "        nb_fold += 1\n",
    "        train_fold, validation_fold = kernel_train.loc[train_index], kernel_train.loc[validation_index]\n",
    "\n",
    "        #MPL Regressor\n",
    "        model_dnn = MLPRegressor(hidden_layer_sizes=(parameters[\"nb_neurons\"],),\n",
    "                                 max_iter=parameters[\"steps\"],\n",
    "                                 alpha=parameters[\"MLP_l2_reg\"],\n",
    "                                 early_stopping=True,\n",
    "                                 random_state=random_seed)\n",
    "        model_dnn.fit(train_fold[cols_kernel], train_fold[\"y\"])\n",
    "        y_hat_train = model_dnn.predict(train_fold[cols_kernel])\n",
    "\n",
    "        RMSE_train = RMSE(y_hat_train, train_fold[\"y\"].values)\n",
    "        print(\"Training RMSE: {0}\".format(RMSE_train))\n",
    "\n",
    "        y_hat_test = model_dnn.predict(validation_fold[cols_kernel])\n",
    "\n",
    "        RMSE_test = RMSE(y_hat_test, validation_fold[\"y\"].values)\n",
    "        \n",
    "        average_RMSE += RMSE_test\n",
    "        print(\"Validation fold {0} RMSE: {1}\".format(nb_fold, RMSE_test))\n",
    "        print(model_dnn.n_iter_)\n",
    "\n",
    "    average_RMSE /= n_splits\n",
    "\n",
    "    print(\"Cross-validation score: {0}\\n\".format(average_RMSE))\n",
    "    \n",
    "    return {\"loss\": average_RMSE, \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model with parameters: \n",
      "{'MLP_l2_reg': 0.015625, 'steps': 500, 'nb_neurons': 9}\n",
      "Training RMSE: 0.684718260041\n",
      "Validation fold 1 RMSE: 0.675408219075\n",
      "131\n",
      "Training RMSE: 0.676006751297\n",
      "Validation fold 2 RMSE: 0.706441987051\n",
      "138\n",
      "Training RMSE: 0.723449725065\n",
      "Validation fold 3 RMSE: 0.75997381004\n",
      "90\n",
      "Training RMSE: 0.685595306757\n",
      "Validation fold 4 RMSE: 0.674064150788\n",
      "128\n",
      "Training RMSE: 0.696162943076\n",
      "Validation fold 5 RMSE: 0.634931866164\n",
      "134\n",
      "Cross-validation score: 0.690164006624\n",
      "\n",
      "Training the model with parameters: \n",
      "{'MLP_l2_reg': 0.015625, 'steps': 500, 'nb_neurons': 9}\n",
      "Training RMSE: 0.684718260041\n",
      "Validation fold 1 RMSE: 0.675408219075\n",
      "131\n",
      "Training RMSE: 0.676006751297\n",
      "Validation fold 2 RMSE: 0.706441987051\n",
      "138\n",
      "Training RMSE: 0.723449725065\n",
      "Validation fold 3 RMSE: 0.75997381004\n",
      "90\n",
      "Training RMSE: 0.685595306757\n",
      "Validation fold 4 RMSE: 0.674064150788\n",
      "128\n",
      "Training RMSE: 0.696162943076\n",
      "Validation fold 5 RMSE: 0.634931866164\n",
      "134\n",
      "Cross-validation score: 0.690164006624\n",
      "\n",
      "Training the model with parameters: \n",
      "{'MLP_l2_reg': 0.03125, 'steps': 500, 'nb_neurons': 9}\n",
      "Training RMSE: 0.684369180217\n",
      "Validation fold 1 RMSE: 0.675207385474\n",
      "131\n",
      "Training RMSE: 0.67569223627\n",
      "Validation fold 2 RMSE: 0.706079991628\n",
      "138\n",
      "Training RMSE: 0.717388088416\n",
      "Validation fold 3 RMSE: 0.755363083935\n",
      "92\n",
      "Training RMSE: 0.685478425363\n",
      "Validation fold 4 RMSE: 0.673838505116\n",
      "128\n",
      "Training RMSE: 0.695399440642\n",
      "Validation fold 5 RMSE: 0.63362974322\n",
      "136\n",
      "Cross-validation score: 0.688823741875\n",
      "\n",
      "Training the model with parameters: \n",
      "{'MLP_l2_reg': 0.015625, 'steps': 500, 'nb_neurons': 9}\n",
      "Training RMSE: 0.684718260041\n",
      "Validation fold 1 RMSE: 0.675408219075\n",
      "131\n",
      "Training RMSE: 0.676006751297\n",
      "Validation fold 2 RMSE: 0.706441987051\n",
      "138\n",
      "Training RMSE: 0.723449725065\n",
      "Validation fold 3 RMSE: 0.75997381004\n",
      "90\n",
      "Training RMSE: 0.685595306757\n",
      "Validation fold 4 RMSE: 0.674064150788\n",
      "128\n",
      "Training RMSE: 0.696162943076\n",
      "Validation fold 5 RMSE: 0.634931866164\n",
      "134\n",
      "Cross-validation score: 0.690164006624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grid to pick parameters from.\n",
    "parameters_grid = {\"steps\"     : hp.choice(\"steps\", np.arange(500, 600, 100, dtype=int)),\n",
    "                   \"nb_neurons\": hp.choice(\"nb_neurons\", np.arange(9, 10, 1, dtype=int)),\n",
    "                   \"MLP_l2_reg\": hp.choice(\"MLP_l2_reg\", np.power(2.0, np.arange(-9, -1)))\n",
    "                  }\n",
    "# Record the information about the cross-validation.\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(scoring_function, parameters_grid, algo=tpe.suggest, max_evals=4, \n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6880125993100149"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(trials.losses())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLP_l2_reg</th>\n",
       "      <th>nb_neurons</th>\n",
       "      <th>steps</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015625</td>\n",
       "      <td>9</td>\n",
       "      <td>500</td>\n",
       "      <td>0.694888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MLP_l2_reg  nb_neurons  steps     score\n",
       "0    0.015625           9    500  0.694888"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the best parameters as a csv.\n",
    "best_parameters = pd.DataFrame({key: [value] for (key, value) in \n",
    "                                zip(space_eval(parameters_grid, best).keys(),\n",
    "                                    space_eval(parameters_grid, best).values())})\n",
    "# Add the corresponding score.\n",
    "best_parameters[\"score\"] = min(trials.losses())\n",
    "best_parameters.to_csv(\"best_parameters_12.csv\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLP_l2_reg</th>\n",
       "      <th>nb_neurons</th>\n",
       "      <th>steps</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015625</td>\n",
       "      <td>9</td>\n",
       "      <td>500</td>\n",
       "      <td>0.694888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MLP_l2_reg  nb_neurons  steps     score\n",
       "0    0.015625           9    500  0.694888"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters = pd.read_csv(\"best_parameters_12.csv\", encoding=\"utf-8\")\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.015625, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=9, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=8, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MPL Regressor\n",
    "model_dnn = MLPRegressor(hidden_layer_sizes=(best_parameters[\"nb_neurons\"][0]),\n",
    "                         max_iter=best_parameters[\"steps\"][0],\n",
    "                         alpha=best_parameters[\"MLP_l2_reg\"][0],\n",
    "                         early_stopping=True,\n",
    "                         random_state=random_seed)\n",
    "model_dnn.fit(kernel_train[cols_kernel], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69496031445585071"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training error\n",
    "RMSE(model_dnn.predict(kernel_train[cols_kernel]), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dnn.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_hat_test = model_dnn.predict(kernel_test[cols_kernel])\n",
    "\n",
    "test_pred = test.groupby(\"id\")[[\"y\"]].mean().reset_index()\n",
    "test_pred[\"y\"] = y_hat_test\n",
    "test_pred.columns = [\"Id\", \"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Save as a .csv\n",
    "test_pred.to_csv(\"Prediction_12.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>981</td>\n",
       "      <td>-3.722921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>982</td>\n",
       "      <td>-3.801966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>983</td>\n",
       "      <td>-3.367951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>984</td>\n",
       "      <td>-3.395750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>985</td>\n",
       "      <td>-3.461897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>986</td>\n",
       "      <td>-5.114391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>987</td>\n",
       "      <td>-4.286113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>988</td>\n",
       "      <td>-2.756088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>989</td>\n",
       "      <td>-3.851343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>990</td>\n",
       "      <td>-3.927609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>991</td>\n",
       "      <td>-5.061917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>992</td>\n",
       "      <td>-2.654624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>993</td>\n",
       "      <td>-4.009414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>994</td>\n",
       "      <td>-3.090732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>995</td>\n",
       "      <td>-3.232485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>996</td>\n",
       "      <td>-0.888609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>997</td>\n",
       "      <td>-3.828541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>998</td>\n",
       "      <td>-2.872347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>999</td>\n",
       "      <td>-1.655695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1000</td>\n",
       "      <td>-2.436320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1001</td>\n",
       "      <td>-5.352307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1002</td>\n",
       "      <td>-3.994378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1003</td>\n",
       "      <td>-5.145962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1004</td>\n",
       "      <td>-3.470793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1005</td>\n",
       "      <td>-2.469231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1006</td>\n",
       "      <td>-3.316008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1007</td>\n",
       "      <td>-4.169959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1008</td>\n",
       "      <td>-3.763208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1009</td>\n",
       "      <td>-3.050903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1010</td>\n",
       "      <td>-1.573520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1335</td>\n",
       "      <td>-3.853276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1336</td>\n",
       "      <td>-3.346224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>1337</td>\n",
       "      <td>-4.866696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>1338</td>\n",
       "      <td>-3.723786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>1339</td>\n",
       "      <td>-1.129067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>1340</td>\n",
       "      <td>-4.553853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>1341</td>\n",
       "      <td>-3.818362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>1342</td>\n",
       "      <td>-3.608644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>1343</td>\n",
       "      <td>-5.054839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>1344</td>\n",
       "      <td>-3.331094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>1345</td>\n",
       "      <td>-4.649207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>1346</td>\n",
       "      <td>-1.992524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>1347</td>\n",
       "      <td>-4.309604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>1348</td>\n",
       "      <td>-4.434010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>1349</td>\n",
       "      <td>-3.812591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>1350</td>\n",
       "      <td>-4.565477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1351</td>\n",
       "      <td>-2.652967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>1352</td>\n",
       "      <td>-3.819897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>1353</td>\n",
       "      <td>-3.505476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>1354</td>\n",
       "      <td>-3.638619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>1355</td>\n",
       "      <td>-4.316785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>1356</td>\n",
       "      <td>-4.015027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>1357</td>\n",
       "      <td>-2.667346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>1358</td>\n",
       "      <td>-3.610448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>1359</td>\n",
       "      <td>-4.650342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>1360</td>\n",
       "      <td>-3.534016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>1361</td>\n",
       "      <td>-2.174700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>1362</td>\n",
       "      <td>-2.123373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>1363</td>\n",
       "      <td>-4.905860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>1364</td>\n",
       "      <td>-0.357518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id         y\n",
       "0     981 -3.722921\n",
       "1     982 -3.801966\n",
       "2     983 -3.367951\n",
       "3     984 -3.395750\n",
       "4     985 -3.461897\n",
       "5     986 -5.114391\n",
       "6     987 -4.286113\n",
       "7     988 -2.756088\n",
       "8     989 -3.851343\n",
       "9     990 -3.927609\n",
       "10    991 -5.061917\n",
       "11    992 -2.654624\n",
       "12    993 -4.009414\n",
       "13    994 -3.090732\n",
       "14    995 -3.232485\n",
       "15    996 -0.888609\n",
       "16    997 -3.828541\n",
       "17    998 -2.872347\n",
       "18    999 -1.655695\n",
       "19   1000 -2.436320\n",
       "20   1001 -5.352307\n",
       "21   1002 -3.994378\n",
       "22   1003 -5.145962\n",
       "23   1004 -3.470793\n",
       "24   1005 -2.469231\n",
       "25   1006 -3.316008\n",
       "26   1007 -4.169959\n",
       "27   1008 -3.763208\n",
       "28   1009 -3.050903\n",
       "29   1010 -1.573520\n",
       "..    ...       ...\n",
       "354  1335 -3.853276\n",
       "355  1336 -3.346224\n",
       "356  1337 -4.866696\n",
       "357  1338 -3.723786\n",
       "358  1339 -1.129067\n",
       "359  1340 -4.553853\n",
       "360  1341 -3.818362\n",
       "361  1342 -3.608644\n",
       "362  1343 -5.054839\n",
       "363  1344 -3.331094\n",
       "364  1345 -4.649207\n",
       "365  1346 -1.992524\n",
       "366  1347 -4.309604\n",
       "367  1348 -4.434010\n",
       "368  1349 -3.812591\n",
       "369  1350 -4.565477\n",
       "370  1351 -2.652967\n",
       "371  1352 -3.819897\n",
       "372  1353 -3.505476\n",
       "373  1354 -3.638619\n",
       "374  1355 -4.316785\n",
       "375  1356 -4.015027\n",
       "376  1357 -2.667346\n",
       "377  1358 -3.610448\n",
       "378  1359 -4.650342\n",
       "379  1360 -3.534016\n",
       "380  1361 -2.174700\n",
       "381  1362 -2.123373\n",
       "382  1363 -4.905860\n",
       "383  1364 -0.357518\n",
       "\n",
       "[384 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Prediction 9: RMSE-validation: 0.72545.\n",
    "Optimal theta: 16, lambda: 1.1921e-07 Public LB: 0.67536 base_kp.^[2:4]\n",
    "* Prediction 10: cross-val RMSE: 0.673803 Public LB: 0.66464"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
